{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPS with DMRG - MNIST\n",
    "\n",
    "Based on this [paper](https://arxiv.org/abs/1605.05775)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import tensorkrowch as tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPS_DMRG(tk.MPSLayer):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 n_sites,\n",
    "                 d_phys,\n",
    "                 n_labels,\n",
    "                 d_bond,\n",
    "                 block_length=2,\n",
    "                 max_bond=10):\n",
    "        super().__init__(n_sites=n_sites,\n",
    "                         d_phys=d_phys,\n",
    "                         n_labels=n_labels,\n",
    "                         d_bond=d_bond,\n",
    "                         l_position=0)\n",
    "        \n",
    "        if block_length > self.n_sites:\n",
    "            raise ValueError('Cannot create a block with more nodes than'\n",
    "                             'existing nodes in the MPS')\n",
    "            \n",
    "        if self.n_sites < 3:\n",
    "            raise ValueError('``n_sites`` should be greater than 3, to have '\n",
    "                             'both left and right nodes, besides the output '\n",
    "                             'node')\n",
    "        \n",
    "        # Set data nodes before starting training to avoid\n",
    "        # problems of edge names when creating the training block\n",
    "        self.set_data_nodes()\n",
    "            \n",
    "        self.block_position = 0\n",
    "        self.block_length = block_length\n",
    "        self.max_bond = max_bond\n",
    "        \n",
    "        # Set input edge names that are easier to use,\n",
    "        # and de-parameterize nodes\n",
    "        for i in range(len(self.right_env)):\n",
    "            self.right_env.append(self.right_env.pop(0).parameterize(False))\n",
    "                \n",
    "        self.right_node = self.right_node.parameterize(False)\n",
    "        \n",
    "        # Create block that is to be trained\n",
    "        block = self.output_node\n",
    "        for i in range(block_length):\n",
    "            if self.right_env:\n",
    "                block = tk.contract_between_(block, self.right_env.pop(0))\n",
    "            else:\n",
    "                block = tk.contract_between_(block, self.right_node)\n",
    "                self.right_node = None\n",
    "            block.get_axis('input').name = f'input_({i})'\n",
    "            \n",
    "        self.training_block = block.parameterize(True)\n",
    "        self.training_block.name = 'training_block'\n",
    "        \n",
    "        # Reset MPS attributes to the corresponding roles in MPS_DMRG\n",
    "        self.output_node = self.training_block\n",
    "        self._l_position = self.block_position\n",
    "        self.lr_env_data = self.lr_env_data[self.block_length:]\n",
    "        self._d_bond = self._d_bond[self.block_length:]\n",
    "        \n",
    "    def move_block(self, side):\n",
    "        \"\"\"\n",
    "        Moves training block one site to either left or right, when possible.\n",
    "        \"\"\"\n",
    "        self.reset()\n",
    "        \n",
    "        if side == 'right':\n",
    "            if self.block_position + self.block_length == self.n_sites:\n",
    "                raise ValueError('Cannot move block to the right, block is'\n",
    "                                    ' the right-most node')\n",
    "                \n",
    "            node1_axes = (['left'] if self.left_node else []) + \\\n",
    "                         ['input_(0)']\n",
    "            node2_axes = [f'input_({i})' for i in range(1, self.block_length)] + \\\n",
    "                         ['output'] + \\\n",
    "                         (['right'] if self.right_node else [])\n",
    "            \n",
    "            node, block = tk.split_(self.training_block,\n",
    "                                    node1_axes,\n",
    "                                    node2_axes,\n",
    "                                    rank=self.max_bond)\n",
    "            \n",
    "            if self.right_env:\n",
    "                block = tk.contract_between_(block, self.right_env.pop(0))\n",
    "            else:\n",
    "                block = tk.contract_between_(block, self.right_node)\n",
    "                self.right_node = None\n",
    "                \n",
    "            node.get_axis('splitted').name = 'right'\n",
    "            node.get_axis('input_(0)').name = 'input'\n",
    "            \n",
    "            block.get_axis('splitted').name = 'left'\n",
    "            block.name = 'training_block'\n",
    "            \n",
    "            for i in range(self.block_length - 1):\n",
    "                block.get_axis(f'input_({i + 1})').name = f'input_({i})'\n",
    "            block.get_axis('input').name = f'input_({self.block_length - 1})'\n",
    "                \n",
    "            self.training_block = block.parameterize(True)\n",
    "                \n",
    "            if self.left_node:\n",
    "                node.name = f'left_env_node_({len(self.left_env)})'\n",
    "                self.left_env.append(node)\n",
    "                \n",
    "                self.lr_env_data = self.lr_env_data[:(self.block_position - 1)] + \\\n",
    "                    [node.neighbours('input')] + \\\n",
    "                    self.lr_env_data[self.block_position:]\n",
    "            else:\n",
    "                node.name = 'left_node'\n",
    "                self.left_node = node\n",
    "                self.lr_env_data = self.lr_env_data[1:]\n",
    "                \n",
    "            self._d_bond[self.block_position] = node['right'].size()\n",
    "                \n",
    "            self.block_position += 1\n",
    "            self._l_position += 1\n",
    "            \n",
    "        elif side == 'left':\n",
    "            if self.block_position == 0:\n",
    "                raise ValueError('Cannot move block to the left, block is'\n",
    "                                 ' the left-most node')\n",
    "                \n",
    "            node1_axes = (['left'] if self.left_node else []) + \\\n",
    "                         ['output'] + \\\n",
    "                         [f'input_({i})' for i in range(self.block_length - 1)]\n",
    "            node2_axes = [f'input_({self.block_length - 1})'] + \\\n",
    "                         (['right'] if self.right_node else [])\n",
    "            \n",
    "            block, node = tk.split_(self.training_block,\n",
    "                                    node1_axes,\n",
    "                                    node2_axes,\n",
    "                                    rank=self.max_bond)\n",
    "            \n",
    "            if self.left_env:\n",
    "                block = tk.contract_between_(self.left_env.pop(-1), block)\n",
    "            else:\n",
    "                block = tk.contract_between_(self.left_node, block)\n",
    "                self.left_node = None\n",
    "                \n",
    "            block.get_axis('splitted').name = 'right'\n",
    "            block.name = 'training_block'\n",
    "            \n",
    "            node.get_axis('splitted').name = 'left'\n",
    "            node.get_axis(f'input_({self.block_length - 1})').name = 'input'\n",
    "            \n",
    "            for i in range(self.block_length - 2, -1, -1):\n",
    "                block.get_axis(f'input_({i})').name = f'input_({i + 1})'\n",
    "            block.get_axis('input').name = f'input_(0)'\n",
    "                \n",
    "            self.training_block = block.parameterize(True)\n",
    "                \n",
    "            if self.right_node:\n",
    "                for i in range(len(self.right_env) - 1, -1, -1):\n",
    "                    self.right_env[i].name = f'right_env_node_({i + 1})'\n",
    "                node.name = 'right_env_node_(0)'\n",
    "                self.right_env = [node] + self.right_env\n",
    "                \n",
    "                self.lr_env_data = self.lr_env_data[:max(\n",
    "                                        0, (self.block_position - 2))] + \\\n",
    "                    [node.neighbours('input')] + \\\n",
    "                    self.lr_env_data[(self.block_position - 1):]\n",
    "            else:\n",
    "                node.name = 'right_node'\n",
    "                self.right_node = node\n",
    "                self.lr_env_data = self.lr_env_data[:- 1]\n",
    "                \n",
    "            self._d_bond[self.block_position - 1] = node['left'].size()\n",
    "            \n",
    "            self.block_position -= 1\n",
    "            self._l_position -= 1\n",
    "            \n",
    "        else:\n",
    "            raise ValueError('`side` can only be \"left\" or \"right\"')\n",
    "        \n",
    "        self.output_node = self.training_block\n",
    "        \n",
    "    def contract(self):\n",
    "        result = super().contract()\n",
    "        for i in range(self.block_length):\n",
    "            data = result.neighbours(f'input_({i})')\n",
    "            result = result @ data\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Miscellaneous initialization\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Training parameters\n",
    "num_train = 60000\n",
    "num_test = 10000\n",
    "batch_size = 500\n",
    "image_size = (28, 28)\n",
    "num_epochs = 10\n",
    "num_epochs_canonical = 3\n",
    "learn_rate = 1e-5\n",
    "l2_reg = 0.0\n",
    "d_phys = 3\n",
    "d_bond = 10\n",
    "block_length = 2\n",
    "max_bond = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/cuda/__init__.py:83: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484683044/work/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "mps = MPS_DMRG(n_sites=image_size[0] * image_size[1] + 1,\n",
    "               d_phys=d_phys,\n",
    "               n_labels=10,\n",
    "               d_bond=d_bond,\n",
    "               block_length=block_length,\n",
    "               max_bond=max_bond)\n",
    "\n",
    "for node in mps.leaf_nodes.values():\n",
    "    node.tensor = node.tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before starting training, set memory modes to True, and trace\n",
    "mps.automemory = True\n",
    "mps.auto_unbind = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set our loss function\n",
    "loss_fun = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding(image: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.stack([torch.ones_like(image), image, 1 - image], dim=1)\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize(image_size),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Lambda(embedding)])  # partial(tk.add_ones, dim=1)\n",
    "\n",
    "train_set = datasets.MNIST('./data', download=True, transform=transform)\n",
    "test_set = datasets.MNIST('./data', download=True, transform=transform,\n",
    "                          train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 60000 MNIST images \n",
      "(testing on 10000) for 10 epochs\n",
      "Using Adam w/ learning rate = 1.0e-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Put MNIST data into dataloaders\n",
    "samplers = {\n",
    "    \"train\": torch.utils.data.SubsetRandomSampler(range(num_train)),\n",
    "    \"test\": torch.utils.data.SubsetRandomSampler(range(num_test)),\n",
    "}\n",
    "loaders = {\n",
    "    name: torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=samplers[name], drop_last=True\n",
    "    )\n",
    "    for (name, dataset) in [(\"train\", train_set), (\"test\", test_set)]\n",
    "}\n",
    "num_batches = {\n",
    "    name: total_num // batch_size\n",
    "    for (name, total_num) in [(\"train\", num_train), (\"test\", num_test)]\n",
    "}\n",
    "\n",
    "print(\n",
    "    f\"Training on {num_train} MNIST images \\n\"\n",
    "    f\"(testing on {num_test}) for {num_epochs} epochs\"\n",
    ")\n",
    "print(f\"Using Adam w/ learning rate = {learn_rate:.1e}\")\n",
    "if l2_reg > 0: \n",
    "    print(f\" * L2 regularization = {l2_reg:.2e}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 1, Move 0/782: Train. Loss: 2.3026, Train. Acc.: 0.1074, Test Acc.: 0.1135\n",
      "* Epoch 1, Move 10/782: Train. Loss: 2.3020, Train. Acc.: 0.1106, Test Acc.: 0.1135\n",
      "* Epoch 1, Move 20/782: Train. Loss: 2.3015, Train. Acc.: 0.1106, Test Acc.: 0.1135\n",
      "* Epoch 1, Move 30/782: Train. Loss: 2.3016, Train. Acc.: 0.1093, Test Acc.: 0.1135\n",
      "* Epoch 1, Move 40/782: Train. Loss: 2.3010, Train. Acc.: 0.1127, Test Acc.: 0.1135\n",
      "* Epoch 1, Move 50/782: Train. Loss: 2.3011, Train. Acc.: 0.1110, Test Acc.: 0.1135\n",
      "* Epoch 1, Move 60/782: Train. Loss: 2.3011, Train. Acc.: 0.1127, Test Acc.: 0.1135\n",
      "* Epoch 1, Move 70/782: Train. Loss: 2.3010, Train. Acc.: 0.1139, Test Acc.: 0.1135\n",
      "* Epoch 1, Move 80/782: Train. Loss: 2.3020, Train. Acc.: 0.1082, Test Acc.: 0.1135\n",
      "* Epoch 1, Move 90/782: Train. Loss: 2.3017, Train. Acc.: 0.1105, Test Acc.: 0.1135\n",
      "* Epoch 1, Move 100/782: Train. Loss: 2.3003, Train. Acc.: 0.1117, Test Acc.: 0.1135\n",
      "* Epoch 1, Move 110/782: Train. Loss: 2.3007, Train. Acc.: 0.1130, Test Acc.: 0.1135\n",
      "* Epoch 1, Move 120/782: Train. Loss: 2.3007, Train. Acc.: 0.1131, Test Acc.: 0.1135\n",
      "* Epoch 1, Move 130/782: Train. Loss: 2.2997, Train. Acc.: 0.1095, Test Acc.: 0.1135\n",
      "* Epoch 1, Move 140/782: Train. Loss: 2.3001, Train. Acc.: 0.1093, Test Acc.: 0.1135\n",
      "* Epoch 1, Move 150/782: Train. Loss: 2.2988, Train. Acc.: 0.1137, Test Acc.: 0.1135\n",
      "* Epoch 1, Move 160/782: Train. Loss: 2.2983, Train. Acc.: 0.1135, Test Acc.: 0.1135\n",
      "* Epoch 1, Move 170/782: Train. Loss: 2.2979, Train. Acc.: 0.1159, Test Acc.: 0.1135\n",
      "* Epoch 1, Move 180/782: Train. Loss: 2.2964, Train. Acc.: 0.1136, Test Acc.: 0.1135\n",
      "* Epoch 1, Move 190/782: Train. Loss: 2.2967, Train. Acc.: 0.1088, Test Acc.: 0.1135\n",
      "* Epoch 1, Move 200/782: Train. Loss: 2.2961, Train. Acc.: 0.1164, Test Acc.: 0.1135\n",
      "* Epoch 1, Move 210/782: Train. Loss: 2.2947, Train. Acc.: 0.1082, Test Acc.: 0.1135\n",
      "* Epoch 1, Move 220/782: Train. Loss: 2.2934, Train. Acc.: 0.1144, Test Acc.: 0.1136\n",
      "* Epoch 1, Move 230/782: Train. Loss: 2.2929, Train. Acc.: 0.1121, Test Acc.: 0.1136\n",
      "* Epoch 1, Move 240/782: Train. Loss: 2.2913, Train. Acc.: 0.1135, Test Acc.: 0.1139\n",
      "* Epoch 1, Move 250/782: Train. Loss: 2.2898, Train. Acc.: 0.1144, Test Acc.: 0.1143\n",
      "* Epoch 1, Move 260/782: Train. Loss: 2.2883, Train. Acc.: 0.1165, Test Acc.: 0.1149\n",
      "* Epoch 1, Move 270/782: Train. Loss: 2.2848, Train. Acc.: 0.1154, Test Acc.: 0.1195\n",
      "* Epoch 1, Move 280/782: Train. Loss: 2.2835, Train. Acc.: 0.1257, Test Acc.: 0.1224\n",
      "* Epoch 1, Move 290/782: Train. Loss: 2.2813, Train. Acc.: 0.1267, Test Acc.: 0.1296\n",
      "* Epoch 1, Move 300/782: Train. Loss: 2.2773, Train. Acc.: 0.1397, Test Acc.: 0.1399\n",
      "* Epoch 1, Move 310/782: Train. Loss: 2.2773, Train. Acc.: 0.1470, Test Acc.: 0.1477\n",
      "* Epoch 1, Move 320/782: Train. Loss: 2.2717, Train. Acc.: 0.1594, Test Acc.: 0.1584\n",
      "* Epoch 1, Move 330/782: Train. Loss: 2.2691, Train. Acc.: 0.1707, Test Acc.: 0.1673\n",
      "* Epoch 1, Move 340/782: Train. Loss: 2.2690, Train. Acc.: 0.1703, Test Acc.: 0.1696\n",
      "* Epoch 1, Move 350/782: Train. Loss: 2.2612, Train. Acc.: 0.1902, Test Acc.: 0.1851\n",
      "* Epoch 1, Move 360/782: Train. Loss: 2.2604, Train. Acc.: 0.2026, Test Acc.: 0.2012\n",
      "* Epoch 1, Move 370/782: Train. Loss: 2.2580, Train. Acc.: 0.2009, Test Acc.: 0.1979\n",
      "* Epoch 1, Move 380/782: Train. Loss: 2.2520, Train. Acc.: 0.2101, Test Acc.: 0.2138\n",
      "* Epoch 1, Move 390/782: Train. Loss: 2.2517, Train. Acc.: 0.2193, Test Acc.: 0.2168\n",
      "* Epoch 1, Move 400/782: Train. Loss: 2.2473, Train. Acc.: 0.2190, Test Acc.: 0.2210\n",
      "* Epoch 1, Move 410/782: Train. Loss: 2.2440, Train. Acc.: 0.2275, Test Acc.: 0.2329\n",
      "* Epoch 1, Move 420/782: Train. Loss: 2.2412, Train. Acc.: 0.2365, Test Acc.: 0.2354\n",
      "* Epoch 1, Move 430/782: Train. Loss: 2.2384, Train. Acc.: 0.2354, Test Acc.: 0.2437\n",
      "* Epoch 1, Move 440/782: Train. Loss: 2.2323, Train. Acc.: 0.2446, Test Acc.: 0.2394\n",
      "* Epoch 1, Move 450/782: Train. Loss: 2.2322, Train. Acc.: 0.2475, Test Acc.: 0.2454\n",
      "* Epoch 1, Move 460/782: Train. Loss: 2.2279, Train. Acc.: 0.2550, Test Acc.: 0.2587\n",
      "* Epoch 1, Move 470/782: Train. Loss: 2.2271, Train. Acc.: 0.2471, Test Acc.: 0.2488\n",
      "* Epoch 1, Move 480/782: Train. Loss: 2.2259, Train. Acc.: 0.2525, Test Acc.: 0.2525\n",
      "* Epoch 1, Move 490/782: Train. Loss: 2.2218, Train. Acc.: 0.2564, Test Acc.: 0.2625\n",
      "* Epoch 1, Move 500/782: Train. Loss: 2.2192, Train. Acc.: 0.2600, Test Acc.: 0.2538\n",
      "* Epoch 1, Move 510/782: Train. Loss: 2.2165, Train. Acc.: 0.2588, Test Acc.: 0.2556\n",
      "* Epoch 1, Move 520/782: Train. Loss: 2.2139, Train. Acc.: 0.2537, Test Acc.: 0.2521\n",
      "* Epoch 1, Move 530/782: Train. Loss: 2.2133, Train. Acc.: 0.2548, Test Acc.: 0.2559\n",
      "* Epoch 1, Move 540/782: Train. Loss: 2.2098, Train. Acc.: 0.2586, Test Acc.: 0.2625\n",
      "* Epoch 1, Move 550/782: Train. Loss: 2.2083, Train. Acc.: 0.2639, Test Acc.: 0.2672\n",
      "* Epoch 1, Move 560/782: Train. Loss: 2.2062, Train. Acc.: 0.2637, Test Acc.: 0.2633\n",
      "* Epoch 1, Move 570/782: Train. Loss: 2.2019, Train. Acc.: 0.2699, Test Acc.: 0.2717\n",
      "* Epoch 1, Move 580/782: Train. Loss: 2.2009, Train. Acc.: 0.2665, Test Acc.: 0.2701\n",
      "* Epoch 1, Move 590/782: Train. Loss: 2.2003, Train. Acc.: 0.2616, Test Acc.: 0.2650\n",
      "* Epoch 1, Move 600/782: Train. Loss: 2.1981, Train. Acc.: 0.2711, Test Acc.: 0.2815\n",
      "* Epoch 1, Move 610/782: Train. Loss: 2.1948, Train. Acc.: 0.2722, Test Acc.: 0.2780\n",
      "* Epoch 1, Move 620/782: Train. Loss: 2.1927, Train. Acc.: 0.2806, Test Acc.: 0.2834\n",
      "* Epoch 1, Move 630/782: Train. Loss: 2.1897, Train. Acc.: 0.2838, Test Acc.: 0.2925\n",
      "* Epoch 1, Move 640/782: Train. Loss: 2.1888, Train. Acc.: 0.2767, Test Acc.: 0.2805\n",
      "* Epoch 1, Move 650/782: Train. Loss: 2.1872, Train. Acc.: 0.2802, Test Acc.: 0.2869\n",
      "* Epoch 1, Move 660/782: Train. Loss: 2.1837, Train. Acc.: 0.2885, Test Acc.: 0.2962\n",
      "* Epoch 1, Move 670/782: Train. Loss: 2.1802, Train. Acc.: 0.2809, Test Acc.: 0.2870\n",
      "* Epoch 1, Move 680/782: Train. Loss: 2.1780, Train. Acc.: 0.2849, Test Acc.: 0.2894\n",
      "* Epoch 1, Move 690/782: Train. Loss: 2.1740, Train. Acc.: 0.2942, Test Acc.: 0.2945\n",
      "* Epoch 1, Move 700/782: Train. Loss: 2.1757, Train. Acc.: 0.2852, Test Acc.: 0.2957\n",
      "* Epoch 1, Move 710/782: Train. Loss: 2.1684, Train. Acc.: 0.2986, Test Acc.: 0.3008\n",
      "* Epoch 1, Move 720/782: Train. Loss: 2.1676, Train. Acc.: 0.3029, Test Acc.: 0.3066\n",
      "* Epoch 1, Move 730/782: Train. Loss: 2.1647, Train. Acc.: 0.3024, Test Acc.: 0.3069\n",
      "* Epoch 1, Move 740/782: Train. Loss: 2.1621, Train. Acc.: 0.3023, Test Acc.: 0.3063\n",
      "* Epoch 1, Move 750/782: Train. Loss: 2.1593, Train. Acc.: 0.3056, Test Acc.: 0.3102\n",
      "* Epoch 1, Move 760/782: Train. Loss: 2.1567, Train. Acc.: 0.3079, Test Acc.: 0.3100\n",
      "* Epoch 1, Move 770/782: Train. Loss: 2.1507, Train. Acc.: 0.3075, Test Acc.: 0.3117\n",
      "* Epoch 1, Move 780/782: Train. Loss: 2.1473, Train. Acc.: 0.3124, Test Acc.: 0.3116\n",
      "* Epoch 1, Move 790/782: Train. Loss: 2.1206, Train. Acc.: 0.3151, Test Acc.: 0.3195\n",
      "* Epoch 1, Move 800/782: Train. Loss: 1.8818, Train. Acc.: 0.3729, Test Acc.: 0.3759\n",
      "* Epoch 1, Move 810/782: Train. Loss: 1.5419, Train. Acc.: 0.4263, Test Acc.: 0.4242\n",
      "* Epoch 1, Move 820/782: Train. Loss: 1.6147, Train. Acc.: 0.4188, Test Acc.: 0.4362\n",
      "* Epoch 1, Move 830/782: Train. Loss: 1.5731, Train. Acc.: 0.4241, Test Acc.: 0.4653\n",
      "* Epoch 1, Move 840/782: Train. Loss: 1.4790, Train. Acc.: 0.4532, Test Acc.: 0.4981\n",
      "* Epoch 1, Move 850/782: Train. Loss: 1.5718, Train. Acc.: 0.4634, Test Acc.: 0.5018\n",
      "* Epoch 1, Move 860/782: Train. Loss: 1.8852, Train. Acc.: 0.4622, Test Acc.: 0.5317\n",
      "* Epoch 1, Move 870/782: Train. Loss: 2.0618, Train. Acc.: 0.4427, Test Acc.: 0.5163\n",
      "* Epoch 1, Move 880/782: Train. Loss: 1.7859, Train. Acc.: 0.5181, Test Acc.: 0.5544\n",
      "* Epoch 1, Move 890/782: Train. Loss: 2.4730, Train. Acc.: 0.4567, Test Acc.: 0.5631\n",
      "* Epoch 1, Move 900/782: Train. Loss: 2.1808, Train. Acc.: 0.4802, Test Acc.: 0.5674\n",
      "* Epoch 1, Move 910/782: Train. Loss: 2.0909, Train. Acc.: 0.5537, Test Acc.: 0.6162\n",
      "* Epoch 1, Move 920/782: Train. Loss: 2.4267, Train. Acc.: 0.5211, Test Acc.: 0.6155\n",
      "* Epoch 1, Move 930/782: Train. Loss: 2.2734, Train. Acc.: 0.5459, Test Acc.: 0.6299\n",
      "* Epoch 1, Move 940/782: Train. Loss: 2.4616, Train. Acc.: 0.5696, Test Acc.: 0.6707\n",
      "* Epoch 1, Move 950/782: Train. Loss: 3.7486, Train. Acc.: 0.5158, Test Acc.: 0.5797\n",
      "* Epoch 1, Move 960/782: Train. Loss: 2.4387, Train. Acc.: 0.5712, Test Acc.: 0.6450\n",
      "* Epoch 1, Move 970/782: Train. Loss: 5.0107, Train. Acc.: 0.4950, Test Acc.: 0.5941\n",
      "* Epoch 1, Move 980/782: Train. Loss: 4.0709, Train. Acc.: 0.5214, Test Acc.: 0.5982\n",
      "* Epoch 1, Move 990/782: Train. Loss: 3.6391, Train. Acc.: 0.5583, Test Acc.: 0.6543\n",
      "* Epoch 1, Move 1000/782: Train. Loss: 4.4836, Train. Acc.: 0.5470, Test Acc.: 0.6099\n",
      "* Epoch 1, Move 1010/782: Train. Loss: 4.6228, Train. Acc.: 0.5563, Test Acc.: 0.6642\n",
      "* Epoch 1, Move 1020/782: Train. Loss: 3.6715, Train. Acc.: 0.6172, Test Acc.: 0.6938\n",
      "* Epoch 1, Move 1030/782: Train. Loss: 4.2366, Train. Acc.: 0.6138, Test Acc.: 0.6928\n",
      "* Epoch 1, Move 1040/782: Train. Loss: 5.0823, Train. Acc.: 0.5978, Test Acc.: 0.6574\n",
      "* Epoch 1, Move 1050/782: Train. Loss: 4.5465, Train. Acc.: 0.6306, Test Acc.: 0.6964\n",
      "* Epoch 1, Move 1060/782: Train. Loss: 5.0398, Train. Acc.: 0.6128, Test Acc.: 0.6863\n",
      "* Epoch 1, Move 1070/782: Train. Loss: 6.0122, Train. Acc.: 0.6079, Test Acc.: 0.6817\n",
      "* Epoch 1, Move 1080/782: Train. Loss: 6.8671, Train. Acc.: 0.6018, Test Acc.: 0.6944\n",
      "* Epoch 1, Move 1090/782: Train. Loss: 8.0319, Train. Acc.: 0.5860, Test Acc.: 0.6480\n",
      "* Epoch 1, Move 1100/782: Train. Loss: 6.3605, Train. Acc.: 0.6312, Test Acc.: 0.7048\n",
      "* Epoch 1, Move 1110/782: Train. Loss: 7.3987, Train. Acc.: 0.6126, Test Acc.: 0.6619\n",
      "* Epoch 1, Move 1120/782: Train. Loss: 8.0390, Train. Acc.: 0.5869, Test Acc.: 0.7174\n",
      "* Epoch 1, Move 1130/782: Train. Loss: 10.1116, Train. Acc.: 0.5817, Test Acc.: 0.6801\n",
      "* Epoch 1, Move 1140/782: Train. Loss: 9.0661, Train. Acc.: 0.6062, Test Acc.: 0.6943\n",
      "* Epoch 1, Move 1150/782: Train. Loss: 8.8096, Train. Acc.: 0.6145, Test Acc.: 0.6746\n",
      "* Epoch 1, Move 1160/782: Train. Loss: 8.1892, Train. Acc.: 0.6456, Test Acc.: 0.7329\n",
      "* Epoch 1, Move 1170/782: Train. Loss: 12.2658, Train. Acc.: 0.6095, Test Acc.: 0.7100\n",
      "* Epoch 1, Move 1180/782: Train. Loss: 9.3826, Train. Acc.: 0.6385, Test Acc.: 0.7178\n",
      "* Epoch 1, Move 1190/782: Train. Loss: 10.6238, Train. Acc.: 0.6455, Test Acc.: 0.7118\n",
      "* Epoch 1, Move 1200/782: Train. Loss: 8.9825, Train. Acc.: 0.6668, Test Acc.: 0.7116\n",
      "* Epoch 1, Move 1210/782: Train. Loss: 14.9045, Train. Acc.: 0.6085, Test Acc.: 0.7059\n",
      "* Epoch 1, Move 1220/782: Train. Loss: 10.6498, Train. Acc.: 0.6714, Test Acc.: 0.7281\n",
      "* Epoch 1, Move 1230/782: Train. Loss: 9.5558, Train. Acc.: 0.6667, Test Acc.: 0.7652\n",
      "* Epoch 1, Move 1240/782: Train. Loss: 9.3515, Train. Acc.: 0.6944, Test Acc.: 0.7678\n",
      "* Epoch 1, Move 1250/782: Train. Loss: 9.8274, Train. Acc.: 0.6699, Test Acc.: 0.7478\n",
      "* Epoch 1, Move 1260/782: Train. Loss: 12.5342, Train. Acc.: 0.6362, Test Acc.: 0.7352\n",
      "* Epoch 1, Move 1270/782: Train. Loss: 10.2359, Train. Acc.: 0.6871, Test Acc.: 0.7350\n",
      "* Epoch 1, Move 1280/782: Train. Loss: 12.0288, Train. Acc.: 0.6639, Test Acc.: 0.7119\n",
      "* Epoch 1, Move 1290/782: Train. Loss: 11.9458, Train. Acc.: 0.6614, Test Acc.: 0.7212\n",
      "* Epoch 1, Move 1300/782: Train. Loss: 12.1004, Train. Acc.: 0.6619, Test Acc.: 0.7413\n",
      "* Epoch 1, Move 1310/782: Train. Loss: 13.4440, Train. Acc.: 0.6651, Test Acc.: 0.7522\n",
      "* Epoch 1, Move 1320/782: Train. Loss: 13.3506, Train. Acc.: 0.6703, Test Acc.: 0.7382\n",
      "* Epoch 1, Move 1330/782: Train. Loss: 14.0485, Train. Acc.: 0.6644, Test Acc.: 0.7340\n",
      "* Epoch 1, Move 1340/782: Train. Loss: 13.2673, Train. Acc.: 0.6709, Test Acc.: 0.7404\n",
      "* Epoch 1, Move 1350/782: Train. Loss: 13.5306, Train. Acc.: 0.6768, Test Acc.: 0.7431\n",
      "* Epoch 1, Move 1360/782: Train. Loss: 12.7220, Train. Acc.: 0.6726, Test Acc.: 0.7242\n",
      "* Epoch 1, Move 1370/782: Train. Loss: 20.5368, Train. Acc.: 0.5954, Test Acc.: 0.6716\n",
      "* Epoch 1, Move 1380/782: Train. Loss: 17.9295, Train. Acc.: 0.6554, Test Acc.: 0.7346\n",
      "* Epoch 1, Move 1390/782: Train. Loss: 16.4633, Train. Acc.: 0.6375, Test Acc.: 0.7071\n",
      "* Epoch 1, Move 1400/782: Train. Loss: 15.8053, Train. Acc.: 0.6440, Test Acc.: 0.7143\n",
      "* Epoch 1, Move 1410/782: Train. Loss: 19.3889, Train. Acc.: 0.6427, Test Acc.: 0.6959\n",
      "* Epoch 1, Move 1420/782: Train. Loss: 16.9564, Train. Acc.: 0.6485, Test Acc.: 0.6982\n",
      "* Epoch 1, Move 1430/782: Train. Loss: 22.2287, Train. Acc.: 0.6278, Test Acc.: 0.6680\n",
      "* Epoch 1, Move 1440/782: Train. Loss: 19.9801, Train. Acc.: 0.6311, Test Acc.: 0.6991\n",
      "* Epoch 1, Move 1450/782: Train. Loss: 25.4877, Train. Acc.: 0.6027, Test Acc.: 0.6545\n",
      "* Epoch 1, Move 1460/782: Train. Loss: 18.8830, Train. Acc.: 0.6385, Test Acc.: 0.7049\n",
      "* Epoch 1, Move 1470/782: Train. Loss: 19.6843, Train. Acc.: 0.6334, Test Acc.: 0.6932\n",
      "* Epoch 1, Move 1480/782: Train. Loss: 20.6718, Train. Acc.: 0.6179, Test Acc.: 0.6766\n",
      "* Epoch 1, Move 1490/782: Train. Loss: 19.1026, Train. Acc.: 0.6303, Test Acc.: 0.6891\n",
      "* Epoch 1, Move 1500/782: Train. Loss: 18.6133, Train. Acc.: 0.6272, Test Acc.: 0.6898\n",
      "* Epoch 1, Move 1510/782: Train. Loss: 36.6882, Train. Acc.: 0.5717, Test Acc.: 0.6086\n",
      "* Epoch 1, Move 1520/782: Train. Loss: 19.3429, Train. Acc.: 0.6503, Test Acc.: 0.7005\n",
      "* Epoch 1, Move 1530/782: Train. Loss: 16.5058, Train. Acc.: 0.6554, Test Acc.: 0.7144\n",
      "* Epoch 1, Move 1540/782: Train. Loss: 21.6581, Train. Acc.: 0.6174, Test Acc.: 0.7110\n",
      "* Epoch 1, Move 1550/782: Train. Loss: 20.7331, Train. Acc.: 0.6226, Test Acc.: 0.7023\n",
      "* Epoch 1, Move 1560/782: Train. Loss: 18.8876, Train. Acc.: 0.6295, Test Acc.: 0.7126\n",
      "* Epoch 1, Move 1563/782: Train. Loss: 13.9634, Train. Acc.: 0.6740, Test Acc.: 0.7230\n",
      "* Epoch 2, Move 0/782: Train. Loss: 9.6638, Train. Acc.: 0.7195, Test Acc.: 0.7337\n",
      "* Epoch 2, Move 10/782: Train. Loss: 22.9136, Train. Acc.: 0.6090, Test Acc.: 0.6995\n",
      "* Epoch 2, Move 20/782: Train. Loss: 18.4346, Train. Acc.: 0.6647, Test Acc.: 0.7271\n",
      "* Epoch 2, Move 30/782: Train. Loss: 23.3772, Train. Acc.: 0.6231, Test Acc.: 0.7008\n",
      "* Epoch 2, Move 40/782: Train. Loss: 19.5840, Train. Acc.: 0.6364, Test Acc.: 0.6893\n",
      "* Epoch 2, Move 50/782: Train. Loss: 25.6252, Train. Acc.: 0.5990, Test Acc.: 0.6941\n",
      "* Epoch 2, Move 60/782: Train. Loss: 20.0118, Train. Acc.: 0.6259, Test Acc.: 0.7219\n",
      "* Epoch 2, Move 70/782: Train. Loss: 23.1366, Train. Acc.: 0.6173, Test Acc.: 0.7037\n",
      "* Epoch 2, Move 80/782: Train. Loss: 20.9154, Train. Acc.: 0.6221, Test Acc.: 0.6988\n",
      "* Epoch 2, Move 90/782: Train. Loss: 22.1244, Train. Acc.: 0.6121, Test Acc.: 0.6828\n",
      "* Epoch 2, Move 100/782: Train. Loss: 24.6257, Train. Acc.: 0.6156, Test Acc.: 0.6344\n",
      "* Epoch 2, Move 110/782: Train. Loss: 22.8663, Train. Acc.: 0.6184, Test Acc.: 0.6888\n",
      "* Epoch 2, Move 120/782: Train. Loss: 23.1857, Train. Acc.: 0.6110, Test Acc.: 0.7160\n",
      "* Epoch 2, Move 130/782: Train. Loss: 30.4125, Train. Acc.: 0.5610, Test Acc.: 0.6389\n",
      "* Epoch 2, Move 140/782: Train. Loss: 20.6656, Train. Acc.: 0.6218, Test Acc.: 0.6603\n",
      "* Epoch 2, Move 150/782: Train. Loss: 25.5000, Train. Acc.: 0.6077, Test Acc.: 0.6843\n",
      "* Epoch 2, Move 160/782: Train. Loss: 26.6340, Train. Acc.: 0.6198, Test Acc.: 0.6383\n",
      "* Epoch 2, Move 170/782: Train. Loss: 40.8497, Train. Acc.: 0.5547, Test Acc.: 0.6196\n",
      "* Epoch 2, Move 180/782: Train. Loss: 31.9411, Train. Acc.: 0.6104, Test Acc.: 0.6685\n",
      "* Epoch 2, Move 190/782: Train. Loss: 33.9331, Train. Acc.: 0.6085, Test Acc.: 0.6555\n",
      "* Epoch 2, Move 200/782: Train. Loss: 34.5931, Train. Acc.: 0.5997, Test Acc.: 0.6635\n",
      "* Epoch 2, Move 210/782: Train. Loss: 30.9375, Train. Acc.: 0.6372, Test Acc.: 0.6827\n",
      "* Epoch 2, Move 220/782: Train. Loss: 35.0182, Train. Acc.: 0.6072, Test Acc.: 0.6463\n",
      "* Epoch 2, Move 230/782: Train. Loss: 32.9510, Train. Acc.: 0.6134, Test Acc.: 0.6654\n",
      "* Epoch 2, Move 240/782: Train. Loss: 36.2202, Train. Acc.: 0.6145, Test Acc.: 0.6418\n",
      "* Epoch 2, Move 250/782: Train. Loss: 40.3352, Train. Acc.: 0.5816, Test Acc.: 0.6175\n",
      "* Epoch 2, Move 260/782: Train. Loss: 35.8399, Train. Acc.: 0.6143, Test Acc.: 0.6603\n",
      "* Epoch 2, Move 270/782: Train. Loss: 50.4191, Train. Acc.: 0.5536, Test Acc.: 0.5966\n",
      "* Epoch 2, Move 280/782: Train. Loss: 50.9939, Train. Acc.: 0.5331, Test Acc.: 0.5557\n",
      "* Epoch 2, Move 290/782: Train. Loss: 43.4714, Train. Acc.: 0.5784, Test Acc.: 0.5799\n",
      "* Epoch 2, Move 300/782: Train. Loss: 52.4362, Train. Acc.: 0.5583, Test Acc.: 0.5803\n",
      "* Epoch 2, Move 310/782: Train. Loss: 52.9788, Train. Acc.: 0.5488, Test Acc.: 0.5747\n",
      "* Epoch 2, Move 320/782: Train. Loss: 48.3021, Train. Acc.: 0.5902, Test Acc.: 0.6023\n",
      "* Epoch 2, Move 330/782: Train. Loss: 60.8245, Train. Acc.: 0.5556, Test Acc.: 0.5863\n",
      "* Epoch 2, Move 340/782: Train. Loss: 52.6617, Train. Acc.: 0.5857, Test Acc.: 0.6061\n",
      "* Epoch 2, Move 350/782: Train. Loss: 49.2803, Train. Acc.: 0.6302, Test Acc.: 0.6499\n",
      "* Epoch 2, Move 360/782: Train. Loss: 60.8026, Train. Acc.: 0.5744, Test Acc.: 0.5759\n",
      "* Epoch 2, Move 370/782: Train. Loss: 55.9292, Train. Acc.: 0.5901, Test Acc.: 0.6101\n",
      "* Epoch 2, Move 380/782: Train. Loss: 60.2631, Train. Acc.: 0.6018, Test Acc.: 0.6180\n",
      "* Epoch 2, Move 390/782: Train. Loss: 65.4258, Train. Acc.: 0.5674, Test Acc.: 0.5864\n",
      "* Epoch 2, Move 400/782: Train. Loss: 52.7663, Train. Acc.: 0.6315, Test Acc.: 0.6625\n",
      "* Epoch 2, Move 410/782: Train. Loss: 65.8085, Train. Acc.: 0.5632, Test Acc.: 0.5861\n",
      "* Epoch 2, Move 420/782: Train. Loss: 67.1935, Train. Acc.: 0.5457, Test Acc.: 0.5753\n",
      "* Epoch 2, Move 430/782: Train. Loss: 53.6434, Train. Acc.: 0.6223, Test Acc.: 0.6342\n",
      "* Epoch 2, Move 440/782: Train. Loss: 66.4489, Train. Acc.: 0.5299, Test Acc.: 0.5368\n",
      "* Epoch 2, Move 450/782: Train. Loss: 62.7299, Train. Acc.: 0.5306, Test Acc.: 0.5412\n",
      "* Epoch 2, Move 460/782: Train. Loss: 57.3425, Train. Acc.: 0.5472, Test Acc.: 0.5720\n",
      "* Epoch 2, Move 470/782: Train. Loss: 53.5092, Train. Acc.: 0.5254, Test Acc.: 0.5333\n",
      "* Epoch 2, Move 480/782: Train. Loss: 48.1464, Train. Acc.: 0.5436, Test Acc.: 0.5456\n",
      "* Epoch 2, Move 490/782: Train. Loss: 44.7993, Train. Acc.: 0.5481, Test Acc.: 0.5398\n",
      "* Epoch 2, Move 500/782: Train. Loss: 45.3515, Train. Acc.: 0.5262, Test Acc.: 0.5383\n",
      "* Epoch 2, Move 510/782: Train. Loss: 39.1463, Train. Acc.: 0.5678, Test Acc.: 0.5565\n",
      "* Epoch 2, Move 520/782: Train. Loss: 40.8712, Train. Acc.: 0.5408, Test Acc.: 0.5351\n",
      "* Epoch 2, Move 530/782: Train. Loss: 37.2625, Train. Acc.: 0.5565, Test Acc.: 0.5576\n",
      "* Epoch 2, Move 540/782: Train. Loss: 34.4921, Train. Acc.: 0.5715, Test Acc.: 0.5685\n",
      "* Epoch 2, Move 550/782: Train. Loss: 32.8607, Train. Acc.: 0.5577, Test Acc.: 0.5674\n",
      "* Epoch 2, Move 560/782: Train. Loss: 31.9596, Train. Acc.: 0.5431, Test Acc.: 0.5554\n",
      "* Epoch 2, Move 570/782: Train. Loss: 31.6785, Train. Acc.: 0.5369, Test Acc.: 0.5558\n",
      "* Epoch 2, Move 580/782: Train. Loss: 35.7952, Train. Acc.: 0.5079, Test Acc.: 0.5218\n",
      "* Epoch 2, Move 590/782: Train. Loss: 35.4555, Train. Acc.: 0.4983, Test Acc.: 0.5126\n",
      "* Epoch 2, Move 600/782: Train. Loss: 34.4581, Train. Acc.: 0.5002, Test Acc.: 0.5213\n",
      "* Epoch 2, Move 610/782: Train. Loss: 30.8157, Train. Acc.: 0.5027, Test Acc.: 0.5240\n",
      "* Epoch 2, Move 620/782: Train. Loss: 25.8776, Train. Acc.: 0.5326, Test Acc.: 0.5501\n",
      "* Epoch 2, Move 630/782: Train. Loss: 25.8634, Train. Acc.: 0.5209, Test Acc.: 0.5506\n",
      "* Epoch 2, Move 640/782: Train. Loss: 24.0364, Train. Acc.: 0.5227, Test Acc.: 0.5320\n",
      "* Epoch 2, Move 650/782: Train. Loss: 21.1938, Train. Acc.: 0.5376, Test Acc.: 0.5443\n",
      "* Epoch 2, Move 660/782: Train. Loss: 19.4710, Train. Acc.: 0.5247, Test Acc.: 0.5211\n",
      "* Epoch 2, Move 670/782: Train. Loss: 19.5372, Train. Acc.: 0.5093, Test Acc.: 0.4957\n",
      "* Epoch 2, Move 680/782: Train. Loss: 16.3485, Train. Acc.: 0.5298, Test Acc.: 0.5443\n",
      "* Epoch 2, Move 690/782: Train. Loss: 14.6872, Train. Acc.: 0.5154, Test Acc.: 0.5326\n",
      "* Epoch 2, Move 700/782: Train. Loss: 12.2822, Train. Acc.: 0.5177, Test Acc.: 0.5252\n",
      "* Epoch 2, Move 710/782: Train. Loss: 11.6515, Train. Acc.: 0.5084, Test Acc.: 0.5325\n",
      "* Epoch 2, Move 720/782: Train. Loss: 9.9835, Train. Acc.: 0.4796, Test Acc.: 0.5045\n",
      "* Epoch 2, Move 730/782: Train. Loss: 8.2320, Train. Acc.: 0.4581, Test Acc.: 0.4702\n",
      "* Epoch 2, Move 740/782: Train. Loss: 16.3362, Train. Acc.: 0.3526, Test Acc.: 0.4768\n",
      "* Epoch 2, Move 750/782: Train. Loss: 47.0301, Train. Acc.: 0.1230, Test Acc.: 0.1758\n",
      "* Epoch 2, Move 760/782: Train. Loss: 18.9287, Train. Acc.: 0.1726, Test Acc.: 0.2919\n",
      "* Epoch 2, Move 770/782: Train. Loss: 30.5966, Train. Acc.: 0.0974, Test Acc.: 0.0980\n",
      "* Epoch 2, Move 780/782: Train. Loss: 35.1089, Train. Acc.: 0.0966, Test Acc.: 0.0980\n",
      "* Epoch 2, Move 790/782: Train. Loss: 25.1461, Train. Acc.: 0.0959, Test Acc.: 0.0980\n",
      "* Epoch 2, Move 800/782: Train. Loss: 2.0550, Train. Acc.: 0.2948, Test Acc.: 0.3530\n",
      "* Epoch 2, Move 810/782: Train. Loss: 1.7306, Train. Acc.: 0.4304, Test Acc.: 0.4484\n",
      "* Epoch 2, Move 820/782: Train. Loss: 1.5582, Train. Acc.: 0.4799, Test Acc.: 0.5101\n",
      "* Epoch 2, Move 830/782: Train. Loss: 1.5002, Train. Acc.: 0.5146, Test Acc.: 0.5123\n",
      "* Epoch 2, Move 840/782: Train. Loss: 1.4338, Train. Acc.: 0.5373, Test Acc.: 0.5383\n",
      "* Epoch 2, Move 850/782: Train. Loss: 1.3255, Train. Acc.: 0.5651, Test Acc.: 0.5882\n",
      "* Epoch 2, Move 860/782: Train. Loss: 1.3041, Train. Acc.: 0.5813, Test Acc.: 0.5808\n",
      "* Epoch 2, Move 870/782: Train. Loss: 1.2596, Train. Acc.: 0.5978, Test Acc.: 0.6055\n",
      "* Epoch 2, Move 880/782: Train. Loss: 1.1589, Train. Acc.: 0.6225, Test Acc.: 0.6245\n",
      "* Epoch 2, Move 890/782: Train. Loss: 1.1993, Train. Acc.: 0.6095, Test Acc.: 0.6160\n",
      "* Epoch 2, Move 900/782: Train. Loss: 1.1336, Train. Acc.: 0.6397, Test Acc.: 0.6421\n",
      "* Epoch 2, Move 910/782: Train. Loss: 1.0489, Train. Acc.: 0.6616, Test Acc.: 0.6711\n",
      "* Epoch 2, Move 920/782: Train. Loss: 1.0453, Train. Acc.: 0.6701, Test Acc.: 0.6726\n",
      "* Epoch 2, Move 930/782: Train. Loss: 1.0014, Train. Acc.: 0.6836, Test Acc.: 0.6831\n",
      "* Epoch 2, Move 940/782: Train. Loss: 0.9722, Train. Acc.: 0.6843, Test Acc.: 0.6972\n",
      "* Epoch 2, Move 950/782: Train. Loss: 0.9831, Train. Acc.: 0.6861, Test Acc.: 0.6742\n",
      "* Epoch 2, Move 960/782: Train. Loss: 0.9599, Train. Acc.: 0.6928, Test Acc.: 0.6928\n",
      "* Epoch 2, Move 970/782: Train. Loss: 0.9097, Train. Acc.: 0.7032, Test Acc.: 0.7139\n",
      "* Epoch 2, Move 980/782: Train. Loss: 0.9353, Train. Acc.: 0.7032, Test Acc.: 0.7085\n",
      "* Epoch 2, Move 990/782: Train. Loss: 0.9149, Train. Acc.: 0.7089, Test Acc.: 0.7140\n",
      "* Epoch 2, Move 1000/782: Train. Loss: 0.8526, Train. Acc.: 0.7272, Test Acc.: 0.7363\n",
      "* Epoch 2, Move 1010/782: Train. Loss: 0.8494, Train. Acc.: 0.7313, Test Acc.: 0.7372\n",
      "* Epoch 2, Move 1020/782: Train. Loss: 0.8088, Train. Acc.: 0.7430, Test Acc.: 0.7494\n",
      "* Epoch 2, Move 1030/782: Train. Loss: 0.8201, Train. Acc.: 0.7306, Test Acc.: 0.7412\n",
      "* Epoch 2, Move 1040/782: Train. Loss: 0.7890, Train. Acc.: 0.7434, Test Acc.: 0.7485\n",
      "* Epoch 2, Move 1050/782: Train. Loss: 0.7146, Train. Acc.: 0.7740, Test Acc.: 0.7624\n",
      "* Epoch 2, Move 1060/782: Train. Loss: 0.8042, Train. Acc.: 0.7379, Test Acc.: 0.7470\n",
      "* Epoch 2, Move 1070/782: Train. Loss: 0.7665, Train. Acc.: 0.7516, Test Acc.: 0.7580\n",
      "* Epoch 2, Move 1080/782: Train. Loss: 0.7285, Train. Acc.: 0.7714, Test Acc.: 0.7745\n",
      "* Epoch 2, Move 1090/782: Train. Loss: 0.7634, Train. Acc.: 0.7549, Test Acc.: 0.7614\n",
      "* Epoch 2, Move 1100/782: Train. Loss: 0.7072, Train. Acc.: 0.7698, Test Acc.: 0.7762\n",
      "* Epoch 2, Move 1110/782: Train. Loss: 0.7447, Train. Acc.: 0.7606, Test Acc.: 0.7747\n",
      "* Epoch 2, Move 1120/782: Train. Loss: 0.7578, Train. Acc.: 0.7513, Test Acc.: 0.7753\n",
      "* Epoch 2, Move 1130/782: Train. Loss: 0.6987, Train. Acc.: 0.7764, Test Acc.: 0.7862\n",
      "* Epoch 2, Move 1140/782: Train. Loss: 0.7581, Train. Acc.: 0.7569, Test Acc.: 0.7703\n",
      "* Epoch 2, Move 1150/782: Train. Loss: 0.7419, Train. Acc.: 0.7636, Test Acc.: 0.7652\n",
      "* Epoch 2, Move 1160/782: Train. Loss: 0.7248, Train. Acc.: 0.7659, Test Acc.: 0.7801\n",
      "* Epoch 2, Move 1170/782: Train. Loss: 0.7794, Train. Acc.: 0.7472, Test Acc.: 0.7623\n",
      "* Epoch 2, Move 1180/782: Train. Loss: 0.7463, Train. Acc.: 0.7622, Test Acc.: 0.7755\n",
      "* Epoch 2, Move 1190/782: Train. Loss: 0.7214, Train. Acc.: 0.7675, Test Acc.: 0.7824\n",
      "* Epoch 2, Move 1200/782: Train. Loss: 0.7802, Train. Acc.: 0.7481, Test Acc.: 0.7645\n",
      "* Epoch 2, Move 1210/782: Train. Loss: 0.7369, Train. Acc.: 0.7639, Test Acc.: 0.7817\n",
      "* Epoch 2, Move 1220/782: Train. Loss: 0.7564, Train. Acc.: 0.7521, Test Acc.: 0.7695\n",
      "* Epoch 2, Move 1230/782: Train. Loss: 0.7709, Train. Acc.: 0.7496, Test Acc.: 0.7521\n",
      "* Epoch 2, Move 1240/782: Train. Loss: 0.7589, Train. Acc.: 0.7576, Test Acc.: 0.7678\n",
      "* Epoch 2, Move 1250/782: Train. Loss: 0.7950, Train. Acc.: 0.7428, Test Acc.: 0.7491\n",
      "* Epoch 2, Move 1260/782: Train. Loss: 0.7824, Train. Acc.: 0.7459, Test Acc.: 0.7613\n",
      "* Epoch 2, Move 1270/782: Train. Loss: 0.7886, Train. Acc.: 0.7442, Test Acc.: 0.7615\n",
      "* Epoch 2, Move 1280/782: Train. Loss: 0.8337, Train. Acc.: 0.7303, Test Acc.: 0.7473\n",
      "* Epoch 2, Move 1290/782: Train. Loss: 0.7860, Train. Acc.: 0.7455, Test Acc.: 0.7596\n",
      "* Epoch 2, Move 1300/782: Train. Loss: 0.7994, Train. Acc.: 0.7385, Test Acc.: 0.7563\n",
      "* Epoch 2, Move 1310/782: Train. Loss: 0.8568, Train. Acc.: 0.7244, Test Acc.: 0.7337\n",
      "* Epoch 2, Move 1320/782: Train. Loss: 0.8072, Train. Acc.: 0.7378, Test Acc.: 0.7456\n",
      "* Epoch 2, Move 1330/782: Train. Loss: 0.8456, Train. Acc.: 0.7264, Test Acc.: 0.7409\n",
      "* Epoch 2, Move 1340/782: Train. Loss: 0.9018, Train. Acc.: 0.7101, Test Acc.: 0.7221\n",
      "* Epoch 2, Move 1350/782: Train. Loss: 0.8501, Train. Acc.: 0.7322, Test Acc.: 0.7465\n",
      "* Epoch 2, Move 1360/782: Train. Loss: 0.8828, Train. Acc.: 0.7166, Test Acc.: 0.7338\n",
      "* Epoch 2, Move 1370/782: Train. Loss: 0.8904, Train. Acc.: 0.7169, Test Acc.: 0.7298\n",
      "* Epoch 2, Move 1380/782: Train. Loss: 0.8126, Train. Acc.: 0.7407, Test Acc.: 0.7577\n",
      "* Epoch 2, Move 1390/782: Train. Loss: 0.8884, Train. Acc.: 0.7127, Test Acc.: 0.7306\n",
      "* Epoch 2, Move 1400/782: Train. Loss: 0.8567, Train. Acc.: 0.7235, Test Acc.: 0.7241\n",
      "* Epoch 2, Move 1410/782: Train. Loss: 0.8531, Train. Acc.: 0.7251, Test Acc.: 0.7451\n",
      "* Epoch 2, Move 1420/782: Train. Loss: 0.8793, Train. Acc.: 0.7157, Test Acc.: 0.7332\n",
      "* Epoch 2, Move 1430/782: Train. Loss: 0.8594, Train. Acc.: 0.7251, Test Acc.: 0.7347\n",
      "* Epoch 2, Move 1440/782: Train. Loss: 0.8434, Train. Acc.: 0.7295, Test Acc.: 0.7459\n",
      "* Epoch 2, Move 1450/782: Train. Loss: 0.8806, Train. Acc.: 0.7115, Test Acc.: 0.7345\n",
      "* Epoch 2, Move 1460/782: Train. Loss: 0.8535, Train. Acc.: 0.7228, Test Acc.: 0.7321\n",
      "* Epoch 2, Move 1470/782: Train. Loss: 0.8484, Train. Acc.: 0.7229, Test Acc.: 0.7368\n",
      "* Epoch 2, Move 1480/782: Train. Loss: 0.8650, Train. Acc.: 0.7194, Test Acc.: 0.7407\n",
      "* Epoch 2, Move 1490/782: Train. Loss: 0.8163, Train. Acc.: 0.7325, Test Acc.: 0.7465\n",
      "* Epoch 2, Move 1500/782: Train. Loss: 0.8434, Train. Acc.: 0.7264, Test Acc.: 0.7376\n",
      "* Epoch 2, Move 1510/782: Train. Loss: 0.8492, Train. Acc.: 0.7215, Test Acc.: 0.7425\n",
      "* Epoch 2, Move 1520/782: Train. Loss: 0.8481, Train. Acc.: 0.7277, Test Acc.: 0.7450\n",
      "* Epoch 2, Move 1530/782: Train. Loss: 0.8144, Train. Acc.: 0.7329, Test Acc.: 0.7470\n",
      "* Epoch 2, Move 1540/782: Train. Loss: 0.8549, Train. Acc.: 0.7194, Test Acc.: 0.7358\n",
      "* Epoch 2, Move 1550/782: Train. Loss: 0.8345, Train. Acc.: 0.7329, Test Acc.: 0.7435\n",
      "* Epoch 2, Move 1560/782: Train. Loss: 0.8507, Train. Acc.: 0.7210, Test Acc.: 0.7423\n",
      "* Epoch 2, Move 1563/782: Train. Loss: 0.8090, Train. Acc.: 0.7372, Test Acc.: 0.7509\n",
      "* Epoch 3, Move 0/782: Train. Loss: 0.7988, Train. Acc.: 0.7384, Test Acc.: 0.7501\n",
      "* Epoch 3, Move 10/782: Train. Loss: 0.8389, Train. Acc.: 0.7251, Test Acc.: 0.7445\n",
      "* Epoch 3, Move 20/782: Train. Loss: 0.8194, Train. Acc.: 0.7349, Test Acc.: 0.7449\n",
      "* Epoch 3, Move 30/782: Train. Loss: 0.8430, Train. Acc.: 0.7279, Test Acc.: 0.7483\n",
      "* Epoch 3, Move 40/782: Train. Loss: 0.8483, Train. Acc.: 0.7236, Test Acc.: 0.7496\n",
      "* Epoch 3, Move 50/782: Train. Loss: 0.8232, Train. Acc.: 0.7305, Test Acc.: 0.7498\n",
      "* Epoch 3, Move 60/782: Train. Loss: 0.8259, Train. Acc.: 0.7357, Test Acc.: 0.7561\n",
      "* Epoch 3, Move 70/782: Train. Loss: 0.8019, Train. Acc.: 0.7419, Test Acc.: 0.7478\n",
      "* Epoch 3, Move 80/782: Train. Loss: 0.8431, Train. Acc.: 0.7198, Test Acc.: 0.7389\n",
      "* Epoch 3, Move 90/782: Train. Loss: 0.8424, Train. Acc.: 0.7192, Test Acc.: 0.7493\n",
      "* Epoch 3, Move 100/782: Train. Loss: 0.8468, Train. Acc.: 0.7237, Test Acc.: 0.7399\n",
      "* Epoch 3, Move 110/782: Train. Loss: 0.9802, Train. Acc.: 0.6778, Test Acc.: 0.7086\n",
      "* Epoch 3, Move 120/782: Train. Loss: 0.9439, Train. Acc.: 0.6916, Test Acc.: 0.7108\n",
      "* Epoch 3, Move 130/782: Train. Loss: 1.0043, Train. Acc.: 0.6774, Test Acc.: 0.6918\n",
      "* Epoch 3, Move 140/782: Train. Loss: 1.0488, Train. Acc.: 0.6637, Test Acc.: 0.6802\n",
      "* Epoch 3, Move 150/782: Train. Loss: 0.9671, Train. Acc.: 0.6891, Test Acc.: 0.7095\n",
      "* Epoch 3, Move 160/782: Train. Loss: 1.1152, Train. Acc.: 0.6471, Test Acc.: 0.6741\n",
      "* Epoch 3, Move 170/782: Train. Loss: 1.1184, Train. Acc.: 0.6550, Test Acc.: 0.6679\n",
      "* Epoch 3, Move 180/782: Train. Loss: 1.0184, Train. Acc.: 0.6838, Test Acc.: 0.7037\n",
      "* Epoch 3, Move 190/782: Train. Loss: 1.1133, Train. Acc.: 0.6601, Test Acc.: 0.6774\n",
      "* Epoch 3, Move 200/782: Train. Loss: 1.1532, Train. Acc.: 0.6619, Test Acc.: 0.6789\n",
      "* Epoch 3, Move 210/782: Train. Loss: 1.1043, Train. Acc.: 0.6800, Test Acc.: 0.6984\n",
      "* Epoch 3, Move 220/782: Train. Loss: 1.3143, Train. Acc.: 0.6452, Test Acc.: 0.6799\n",
      "* Epoch 3, Move 230/782: Train. Loss: 1.2027, Train. Acc.: 0.6655, Test Acc.: 0.6911\n",
      "* Epoch 3, Move 240/782: Train. Loss: 1.2462, Train. Acc.: 0.6768, Test Acc.: 0.6989\n",
      "* Epoch 3, Move 250/782: Train. Loss: 1.4403, Train. Acc.: 0.6483, Test Acc.: 0.6803\n",
      "* Epoch 3, Move 260/782: Train. Loss: 1.2344, Train. Acc.: 0.6828, Test Acc.: 0.7095\n",
      "* Epoch 3, Move 270/782: Train. Loss: 1.1933, Train. Acc.: 0.6943, Test Acc.: 0.7183\n",
      "* Epoch 3, Move 280/782: Train. Loss: 1.2876, Train. Acc.: 0.6734, Test Acc.: 0.6939\n",
      "* Epoch 3, Move 290/782: Train. Loss: 1.2672, Train. Acc.: 0.6789, Test Acc.: 0.7089\n",
      "* Epoch 3, Move 300/782: Train. Loss: 1.2695, Train. Acc.: 0.6819, Test Acc.: 0.6960\n",
      "* Epoch 3, Move 310/782: Train. Loss: 1.2316, Train. Acc.: 0.6797, Test Acc.: 0.6975\n",
      "* Epoch 3, Move 320/782: Train. Loss: 1.0720, Train. Acc.: 0.7207, Test Acc.: 0.7395\n",
      "* Epoch 3, Move 330/782: Train. Loss: 1.1628, Train. Acc.: 0.6917, Test Acc.: 0.7191\n",
      "* Epoch 3, Move 340/782: Train. Loss: 1.1181, Train. Acc.: 0.7018, Test Acc.: 0.7281\n",
      "* Epoch 3, Move 350/782: Train. Loss: 1.0402, Train. Acc.: 0.7222, Test Acc.: 0.7348\n",
      "* Epoch 3, Move 360/782: Train. Loss: 1.1964, Train. Acc.: 0.6778, Test Acc.: 0.7075\n",
      "* Epoch 3, Move 370/782: Train. Loss: 1.0905, Train. Acc.: 0.7027, Test Acc.: 0.7225\n",
      "* Epoch 3, Move 380/782: Train. Loss: 1.1087, Train. Acc.: 0.7019, Test Acc.: 0.7220\n",
      "* Epoch 3, Move 390/782: Train. Loss: 1.1397, Train. Acc.: 0.6907, Test Acc.: 0.7115\n",
      "* Epoch 3, Move 400/782: Train. Loss: 1.0578, Train. Acc.: 0.7131, Test Acc.: 0.7238\n",
      "* Epoch 3, Move 410/782: Train. Loss: 1.1017, Train. Acc.: 0.6912, Test Acc.: 0.6975\n",
      "* Epoch 3, Move 420/782: Train. Loss: 1.0954, Train. Acc.: 0.6935, Test Acc.: 0.7052\n",
      "* Epoch 3, Move 430/782: Train. Loss: 0.9999, Train. Acc.: 0.7207, Test Acc.: 0.7364\n",
      "* Epoch 3, Move 440/782: Train. Loss: 1.0528, Train. Acc.: 0.7123, Test Acc.: 0.7245\n",
      "* Epoch 3, Move 450/782: Train. Loss: 1.0304, Train. Acc.: 0.7106, Test Acc.: 0.7207\n",
      "* Epoch 3, Move 460/782: Train. Loss: 0.9813, Train. Acc.: 0.7241, Test Acc.: 0.7390\n",
      "* Epoch 3, Move 470/782: Train. Loss: 0.9799, Train. Acc.: 0.7168, Test Acc.: 0.7277\n",
      "* Epoch 3, Move 480/782: Train. Loss: 0.9555, Train. Acc.: 0.7274, Test Acc.: 0.7362\n",
      "* Epoch 3, Move 490/782: Train. Loss: 0.9265, Train. Acc.: 0.7277, Test Acc.: 0.7383\n",
      "* Epoch 3, Move 500/782: Train. Loss: 0.9704, Train. Acc.: 0.7111, Test Acc.: 0.7288\n",
      "* Epoch 3, Move 510/782: Train. Loss: 0.9200, Train. Acc.: 0.7285, Test Acc.: 0.7443\n",
      "* Epoch 3, Move 520/782: Train. Loss: 0.9343, Train. Acc.: 0.7149, Test Acc.: 0.7284\n",
      "* Epoch 3, Move 530/782: Train. Loss: 0.9198, Train. Acc.: 0.7131, Test Acc.: 0.7256\n",
      "* Epoch 3, Move 540/782: Train. Loss: 0.8762, Train. Acc.: 0.7281, Test Acc.: 0.7447\n",
      "* Epoch 3, Move 550/782: Train. Loss: 0.9286, Train. Acc.: 0.7118, Test Acc.: 0.7234\n",
      "* Epoch 3, Move 560/782: Train. Loss: 0.9193, Train. Acc.: 0.7080, Test Acc.: 0.7235\n",
      "* Epoch 3, Move 570/782: Train. Loss: 0.8666, Train. Acc.: 0.7330, Test Acc.: 0.7440\n",
      "* Epoch 3, Move 580/782: Train. Loss: 0.9513, Train. Acc.: 0.6986, Test Acc.: 0.7195\n",
      "* Epoch 3, Move 590/782: Train. Loss: 0.9292, Train. Acc.: 0.6973, Test Acc.: 0.7117\n",
      "* Epoch 3, Move 600/782: Train. Loss: 0.9189, Train. Acc.: 0.7064, Test Acc.: 0.7287\n",
      "* Epoch 3, Move 610/782: Train. Loss: 0.9484, Train. Acc.: 0.6981, Test Acc.: 0.7144\n",
      "* Epoch 3, Move 620/782: Train. Loss: 0.9558, Train. Acc.: 0.6890, Test Acc.: 0.6960\n",
      "* Epoch 3, Move 630/782: Train. Loss: 0.9502, Train. Acc.: 0.6948, Test Acc.: 0.7177\n",
      "* Epoch 3, Move 640/782: Train. Loss: 0.9325, Train. Acc.: 0.7044, Test Acc.: 0.7101\n",
      "* Epoch 3, Move 650/782: Train. Loss: 0.9052, Train. Acc.: 0.7050, Test Acc.: 0.7221\n",
      "* Epoch 3, Move 660/782: Train. Loss: 0.9493, Train. Acc.: 0.6916, Test Acc.: 0.7090\n",
      "* Epoch 3, Move 670/782: Train. Loss: 0.9649, Train. Acc.: 0.6842, Test Acc.: 0.6904\n",
      "* Epoch 3, Move 680/782: Train. Loss: 0.9558, Train. Acc.: 0.6906, Test Acc.: 0.7023\n",
      "* Epoch 3, Move 690/782: Train. Loss: 0.9708, Train. Acc.: 0.6842, Test Acc.: 0.6964\n",
      "* Epoch 3, Move 700/782: Train. Loss: 0.9607, Train. Acc.: 0.6871, Test Acc.: 0.6974\n",
      "* Epoch 3, Move 710/782: Train. Loss: 0.9619, Train. Acc.: 0.6915, Test Acc.: 0.6956\n",
      "* Epoch 3, Move 720/782: Train. Loss: 0.9686, Train. Acc.: 0.6864, Test Acc.: 0.6933\n",
      "* Epoch 3, Move 730/782: Train. Loss: 0.9837, Train. Acc.: 0.6821, Test Acc.: 0.6952\n",
      "* Epoch 3, Move 740/782: Train. Loss: 0.9828, Train. Acc.: 0.6796, Test Acc.: 0.6961\n",
      "* Epoch 3, Move 750/782: Train. Loss: 1.0143, Train. Acc.: 0.6718, Test Acc.: 0.6882\n",
      "* Epoch 3, Move 760/782: Train. Loss: 1.0424, Train. Acc.: 0.6655, Test Acc.: 0.6994\n",
      "* Epoch 3, Move 770/782: Train. Loss: 3.0724, Train. Acc.: 0.2413, Test Acc.: 0.3411\n",
      "* Epoch 3, Move 780/782: Train. Loss: 24.0977, Train. Acc.: 0.1033, Test Acc.: 0.0980\n",
      "* Epoch 3, Move 790/782: Train. Loss: 20.6549, Train. Acc.: 0.0960, Test Acc.: 0.0980\n",
      "* Epoch 3, Move 800/782: Train. Loss: 1.6164, Train. Acc.: 0.5016, Test Acc.: 0.5585\n",
      "* Epoch 3, Move 810/782: Train. Loss: 1.4135, Train. Acc.: 0.5765, Test Acc.: 0.5966\n",
      "* Epoch 3, Move 820/782: Train. Loss: 1.3201, Train. Acc.: 0.6019, Test Acc.: 0.6336\n",
      "* Epoch 3, Move 830/782: Train. Loss: 1.2399, Train. Acc.: 0.6235, Test Acc.: 0.6488\n",
      "* Epoch 3, Move 840/782: Train. Loss: 1.1771, Train. Acc.: 0.6384, Test Acc.: 0.6381\n",
      "* Epoch 3, Move 850/782: Train. Loss: 1.1453, Train. Acc.: 0.6407, Test Acc.: 0.6639\n",
      "* Epoch 3, Move 860/782: Train. Loss: 1.1472, Train. Acc.: 0.6452, Test Acc.: 0.6739\n",
      "* Epoch 3, Move 870/782: Train. Loss: 1.1164, Train. Acc.: 0.6552, Test Acc.: 0.6752\n",
      "* Epoch 3, Move 880/782: Train. Loss: 1.0560, Train. Acc.: 0.6747, Test Acc.: 0.6834\n",
      "* Epoch 3, Move 890/782: Train. Loss: 1.0848, Train. Acc.: 0.6610, Test Acc.: 0.6796\n",
      "* Epoch 3, Move 900/782: Train. Loss: 1.0428, Train. Acc.: 0.6799, Test Acc.: 0.6915\n",
      "* Epoch 3, Move 910/782: Train. Loss: 0.9860, Train. Acc.: 0.6931, Test Acc.: 0.6963\n",
      "* Epoch 3, Move 920/782: Train. Loss: 1.0136, Train. Acc.: 0.6879, Test Acc.: 0.6923\n",
      "* Epoch 3, Move 930/782: Train. Loss: 0.9878, Train. Acc.: 0.7014, Test Acc.: 0.7082\n",
      "* Epoch 3, Move 940/782: Train. Loss: 0.9681, Train. Acc.: 0.7009, Test Acc.: 0.7143\n",
      "* Epoch 3, Move 950/782: Train. Loss: 1.0226, Train. Acc.: 0.6855, Test Acc.: 0.6997\n",
      "* Epoch 3, Move 960/782: Train. Loss: 0.9880, Train. Acc.: 0.6977, Test Acc.: 0.7105\n",
      "* Epoch 3, Move 970/782: Train. Loss: 0.9376, Train. Acc.: 0.7159, Test Acc.: 0.7194\n",
      "* Epoch 3, Move 980/782: Train. Loss: 0.9742, Train. Acc.: 0.7001, Test Acc.: 0.7092\n",
      "* Epoch 3, Move 990/782: Train. Loss: 0.9628, Train. Acc.: 0.7048, Test Acc.: 0.7184\n",
      "* Epoch 3, Move 1000/782: Train. Loss: 0.9609, Train. Acc.: 0.7018, Test Acc.: 0.7050\n",
      "* Epoch 3, Move 1010/782: Train. Loss: 0.9724, Train. Acc.: 0.6933, Test Acc.: 0.7161\n",
      "* Epoch 3, Move 1020/782: Train. Loss: 0.9339, Train. Acc.: 0.7089, Test Acc.: 0.7280\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mdata\n\u001b[1;32m     22\u001b[0m inputs, labels \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device), labels\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 24\u001b[0m scores \u001b[39m=\u001b[39m mps(inputs)\n\u001b[1;32m     25\u001b[0m _, preds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(scores, \u001b[39m1\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[39m# Compute the loss and accuracy, add them to the running totals\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/VSCodeProjects/tensorkrowch/tensorkrowch/components.py:4543\u001b[0m, in \u001b[0;36mTensorNetwork.forward\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4541\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   4542\u001b[0m     \u001b[39mfor\u001b[39;00m op \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_seq_ops:\n\u001b[0;32m-> 4543\u001b[0m         output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moperations[op[\u001b[39m0\u001b[39;49m]](\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mop[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m   4545\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(output, Node):\n\u001b[1;32m   4546\u001b[0m         \u001b[39mif\u001b[39;00m (op[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39munbind\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m (\u001b[39mlen\u001b[39m(output) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m):\n",
      "File \u001b[0;32m~/VSCodeProjects/tensorkrowch/tensorkrowch/operations.py:100\u001b[0m, in \u001b[0;36mOperation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m     args \u001b[39m=\u001b[39m [successor] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(args)\n\u001b[0;32m--> 100\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc2(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/VSCodeProjects/tensorkrowch/tensorkrowch/operations.py:2604\u001b[0m, in \u001b[0;36m_stack_next\u001b[0;34m(successor, nodes)\u001b[0m\n\u001b[1;32m   2600\u001b[0m \u001b[39mif\u001b[39;00m successor\u001b[39m.\u001b[39mhints[\u001b[39m'\u001b[39m\u001b[39mall_same_ref\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mor\u001b[39;00m \\\n\u001b[1;32m   2601\u001b[0m     (successor\u001b[39m.\u001b[39mhints[\u001b[39m'\u001b[39m\u001b[39mall_leaf\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mand\u001b[39;00m successor\u001b[39m.\u001b[39mhints[\u001b[39m'\u001b[39m\u001b[39mautomemory\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[1;32m   2602\u001b[0m     \u001b[39mreturn\u001b[39;00m child\n\u001b[0;32m-> 2604\u001b[0m stack_tensor \u001b[39m=\u001b[39m stack_unequal_tensors([node\u001b[39m.\u001b[39;49mtensor \u001b[39mfor\u001b[39;49;00m node \u001b[39min\u001b[39;49;00m nodes])\n\u001b[1;32m   2605\u001b[0m child\u001b[39m.\u001b[39m_unrestricted_set_tensor(stack_tensor)\n\u001b[1;32m   2607\u001b[0m \u001b[39m# Record in inverse_memory while contracting\u001b[39;00m\n\u001b[1;32m   2608\u001b[0m \u001b[39m# (to delete memory if possible)\u001b[39;00m\n",
      "File \u001b[0;32m~/VSCodeProjects/tensorkrowch/tensorkrowch/utils.py:220\u001b[0m, in \u001b[0;36mstack_unequal_tensors\u001b[0;34m(lst_tensors)\u001b[0m\n\u001b[1;32m    218\u001b[0m             pad\u001b[39m.\u001b[39mreverse()\n\u001b[1;32m    219\u001b[0m             lst_tensors[idx] \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mpad(tensor, pad)\n\u001b[0;32m--> 220\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(lst_tensors)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_moves = image_size[0] * image_size[1] - block_length\n",
    "\n",
    "mps.trace(torch.zeros(image_size[0] * image_size[1], 1, d_phys).to(device))\n",
    "optimizer = torch.optim.Adam(mps.parameters(),\n",
    "                             lr=learn_rate,\n",
    "                             weight_decay=l2_reg)\n",
    "\n",
    "for epoch_num in range(1, num_epochs + 1):\n",
    "    \n",
    "    for move in range(2 * n_moves):\n",
    "        running_train_loss = 0.0\n",
    "        running_train_acc = 0.0\n",
    "        total_batches = 0\n",
    "    \n",
    "        for inputs, labels in loaders[\"train\"]:\n",
    "            if torch.rand(1).item() > 0.25:\n",
    "                continue\n",
    "            \n",
    "            inputs = inputs.view(\n",
    "                [batch_size, d_phys, image_size[0] * image_size[1]]).permute(2, 0, 1)\n",
    "            labels = labels.data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            scores = mps(inputs)\n",
    "            _, preds = torch.max(scores, 1)\n",
    "\n",
    "            # Compute the loss and accuracy, add them to the running totals\n",
    "            loss = loss_fun(scores, labels)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                accuracy = torch.sum(preds == labels).item() / batch_size\n",
    "                running_train_loss += loss\n",
    "                running_train_acc += accuracy\n",
    "                total_batches += 1\n",
    "\n",
    "            # Backpropagate and update parameters\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            running_test_acc = 0.0\n",
    "\n",
    "            for inputs, labels in loaders[\"test\"]:\n",
    "                inputs = inputs.view([\n",
    "                    batch_size, d_phys, image_size[0] * image_size[1]]).permute(2, 0, 1)\n",
    "                labels = labels.data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # Call our MPS to get logit scores and predictions\n",
    "                scores = mps(inputs)\n",
    "                _, preds = torch.max(scores, 1)\n",
    "                running_test_acc += torch.sum(preds == labels).item() / batch_size\n",
    "        \n",
    "        if move % 10 == 0:\n",
    "            print(f'* Epoch {epoch_num}, Move {move}/{n_moves}: '\n",
    "                f'Train. Loss: {running_train_loss / total_batches:.4f}, '\n",
    "                f'Train. Acc.: {running_train_acc / total_batches:.4f}, '\n",
    "                f'Test Acc.: {running_test_acc / num_batches[\"test\"]:.4f}')\n",
    "        \n",
    "        if move < n_moves:\n",
    "            mps.move_block('right')\n",
    "        else:\n",
    "            mps.move_block('left')\n",
    "            \n",
    "        mps.trace(torch.zeros(image_size[0] * image_size[1], 1, d_phys).to(device))\n",
    "        optimizer = torch.optim.Adam(mps.parameters(),\n",
    "                                     lr=learn_rate,\n",
    "                                     weight_decay=l2_reg)\n",
    "        \n",
    "    print(f'* Epoch {epoch_num}, Move {move}/{n_moves}: '\n",
    "          f'Train. Loss: {running_train_loss / total_batches:.4f}, '\n",
    "          f'Train. Acc.: {running_train_acc / total_batches:.4f}, '\n",
    "          f'Test Acc.: {running_test_acc / num_batches[\"test\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mps.state_dict(), 'mps_dmrg_+1020.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782 38.36317135549872\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m n_moves \u001b[39m=\u001b[39m image_size[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m image_size[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m block_length\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(n_moves, \u001b[39mlen\u001b[39m(loaders[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdataset) \u001b[39m/\u001b[39m (\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m n_moves))\n\u001b[0;32m----> 4\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(loaders[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdataset) \u001b[39m/\u001b[39m (\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m n_moves) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m batch_size\n\u001b[1;32m      6\u001b[0m mps\u001b[39m.\u001b[39mtrace(torch\u001b[39m.\u001b[39mzeros(image_size[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m image_size[\u001b[39m1\u001b[39m], \u001b[39m1\u001b[39m, d_phys)\u001b[39m.\u001b[39mto(device))\n\u001b[1;32m      7\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD(mps\u001b[39m.\u001b[39mparameters(),\n\u001b[1;32m      8\u001b[0m                              lr\u001b[39m=\u001b[39mlearn_rate,\n\u001b[1;32m      9\u001b[0m                              weight_decay\u001b[39m=\u001b[39ml2_reg)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_moves = image_size[0] * image_size[1] - block_length\n",
    "\n",
    "print(n_moves, len(loaders['train'].dataset) / (2 * n_moves))\n",
    "assert len(loaders['train'].dataset) / (2 * n_moves) >= batch_size\n",
    "\n",
    "mps.trace(torch.zeros(image_size[0] * image_size[1], 1, d_phys).to(device))\n",
    "optimizer = torch.optim.SGD(mps.parameters(),\n",
    "                             lr=learn_rate,\n",
    "                             weight_decay=l2_reg)\n",
    "\n",
    "for epoch_num in range(1, num_epochs + 1):\n",
    "    move = 0\n",
    "\n",
    "    for inputs, labels in loaders[\"train\"]:\n",
    "        running_train_loss = 0.0\n",
    "        running_train_acc = 0.0\n",
    "        \n",
    "        inputs = inputs.view(\n",
    "            [batch_size, d_phys, image_size[0] * image_size[1]]).permute(2, 0, 1)\n",
    "        labels = labels.data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        scores = mps(inputs)\n",
    "        _, preds = torch.max(scores, 1)\n",
    "\n",
    "        # Compute the loss and accuracy, add them to the running totals\n",
    "        loss = loss_fun(scores, labels)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            accuracy = torch.sum(preds == labels).item() / batch_size\n",
    "            running_train_loss += loss\n",
    "            running_train_acc += accuracy\n",
    "\n",
    "        # Backpropagate and update parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if move % 100 == 0:\n",
    "            print(f'* Epoch {epoch_num}, Move {move}/{n_moves}: '\n",
    "                f'Train. Loss: {running_train_loss / num_batches[\"train\"]:.4f}, '\n",
    "                f'Train. Acc.: {running_train_acc / num_batches[\"train\"]:.4f}')\n",
    "        \n",
    "        if move < n_moves:\n",
    "            mps.move_block('right')\n",
    "        else:\n",
    "            mps.move_block('left')\n",
    "            \n",
    "        mps.trace(torch.zeros(image_size[0] * image_size[1], 1, d_phys).to(device))\n",
    "        optimizer = torch.optim.SGD(mps.parameters(),\n",
    "                                        lr=learn_rate,\n",
    "                                        weight_decay=l2_reg)\n",
    "        \n",
    "        move += 1\n",
    "        if move == (2 * n_moves):\n",
    "            break\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        running_test_acc = 0.0\n",
    "\n",
    "        for inputs, labels in loaders[\"test\"]:\n",
    "            inputs = inputs.view([\n",
    "                batch_size, d_phys, image_size[0] * image_size[1]]).permute(2, 0, 1)\n",
    "            labels = labels.data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Call our MPS to get logit scores and predictions\n",
    "            scores = mps(inputs)\n",
    "            _, preds = torch.max(scores, 1)\n",
    "            running_test_acc += torch.sum(preds == labels).item() / batch_size\n",
    "        \n",
    "    print(f'* Epoch {epoch_num}, Move {move}/{n_moves}: '\n",
    "          f'Train. Loss: {running_train_loss / num_batches[\"train\"]:.4f}, '\n",
    "          f'Train. Acc.: {running_train_acc / num_batches[\"train\"]:.4f}, '\n",
    "          f'Test Acc.: {running_test_acc / num_batches[\"test\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_moves = image_size[0] * image_size[1] - block_length\n",
    "\n",
    "mps.trace(torch.zeros(image_size[0] * image_size[1], 1, d_phys).to(device))\n",
    "optimizer = torch.optim.Adam(mps.parameters(),\n",
    "                             lr=learn_rate,\n",
    "                             weight_decay=l2_reg)\n",
    "\n",
    "for epoch_num in range(1, num_epochs + 1):\n",
    "    \n",
    "    for move in range(2 * n_moves):\n",
    "        running_train_loss = 0.0\n",
    "        running_train_acc = 0.0\n",
    "    \n",
    "        for inputs, labels in loaders[\"train\"]:\n",
    "            inputs = inputs.view(\n",
    "                [batch_size, d_phys, image_size[0] * image_size[1]]).permute(2, 0, 1)\n",
    "            labels = labels.data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            scores = mps(inputs)\n",
    "            _, preds = torch.max(scores, 1)\n",
    "\n",
    "            # Compute the loss and accuracy, add them to the running totals\n",
    "            loss = loss_fun(scores, labels)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                accuracy = torch.sum(preds == labels).item() / batch_size\n",
    "                running_train_loss += loss\n",
    "                running_train_acc += accuracy\n",
    "\n",
    "            # Backpropagate and update parameters\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            running_test_acc = 0.0\n",
    "\n",
    "            for inputs, labels in loaders[\"test\"]:\n",
    "                inputs = inputs.view([\n",
    "                    batch_size, d_phys, image_size[0] * image_size[1]]).permute(2, 0, 1)\n",
    "                labels = labels.data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # Call our MPS to get logit scores and predictions\n",
    "                scores = mps(inputs)\n",
    "                _, preds = torch.max(scores, 1)\n",
    "                running_test_acc += torch.sum(preds == labels).item() / batch_size\n",
    "        \n",
    "        if move % 10 == 0:\n",
    "            print(f'* Epoch {epoch_num}, Move {move}/{n_moves}: '\n",
    "                f'Train. Loss: {running_train_loss / num_batches[\"train\"]:.4f}, '\n",
    "                f'Train. Acc.: {running_train_acc / num_batches[\"train\"]:.4f}, '\n",
    "                f'Test Acc.: {running_test_acc / num_batches[\"test\"]:.4f}')\n",
    "        \n",
    "        if move < n_moves:\n",
    "            mps.move_block('right')\n",
    "        else:\n",
    "            mps.move_block('left')\n",
    "            \n",
    "        mps.trace(torch.zeros(image_size[0] * image_size[1], 1, d_phys).to(device))\n",
    "        optimizer = torch.optim.Adam(mps.parameters(),\n",
    "                                     lr=learn_rate,\n",
    "                                     weight_decay=l2_reg)\n",
    "        \n",
    "    print(f'* Epoch {epoch_num}, Move {move}/{n_moves}: '\n",
    "          f'Train. Loss: {running_train_loss / num_batches[\"train\"]:.4f}, '\n",
    "          f'Train. Acc.: {running_train_acc / num_batches[\"train\"]:.4f}, '\n",
    "          f'Test Acc.: {running_test_acc / num_batches[\"test\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N params:     900\n",
      "Memory module: 0.0034 MB\n"
     ]
    }
   ],
   "source": [
    "# Original number of parametrs\n",
    "n_params = 0\n",
    "memory = 0\n",
    "for p in mps.parameters():\n",
    "    n_params += p.nelement()\n",
    "    memory += p.nelement() * p.element_size()  # Bytes\n",
    "print(f'N params:     {n_params}')\n",
    "print(f'Memory module: {memory / 1024**2:.4f} MB')  # MegaBytes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98819ef66e0fd8e26166ef23b2736d781c80dc7aa950207c762e497c21afbd1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
