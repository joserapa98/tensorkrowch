
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>tensorkrowch.network_components &#8212; TensorKrowch 00.00.01 documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/tensorkrowch_logo_light.png" class="logo" alt="logo">
      
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Contents:
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../usage.html">
   Usage
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../api.html">
   API Reference
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../network_components.html">
     Tensor Network Components
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../node_operations.html">
     Operations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tn_models.html">
     Models
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1></h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <h1>Source code for tensorkrowch.network_components</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">This script contains:</span>

<span class="sd">    Classes for Nodes and Edges:</span>
<span class="sd">        *Axis</span>
<span class="sd">        *AbstractNode:</span>
<span class="sd">            +Node</span>
<span class="sd">            +ParamNode</span>
<span class="sd">        *AbstractEdge:</span>
<span class="sd">            +Edge</span>
<span class="sd">            +ParamEdge</span>

<span class="sd">    Classes for stacks:</span>
<span class="sd">        *StackNode</span>
<span class="sd">        *ParamStackNode</span>
<span class="sd">        *AbstractStackEdge:</span>
<span class="sd">            +StackEdge</span>
<span class="sd">            +ParamStackEdge</span>
<span class="sd">    </span>
<span class="sd">    Class for successors:        </span>
<span class="sd">        *Successor</span>

<span class="sd">    Class for Tensor Networks:</span>
<span class="sd">        *TensorNetwork</span>
<span class="sd">        </span>
<span class="sd">    Edge operations:</span>
<span class="sd">        *connect</span>
<span class="sd">        *connect_stack</span>
<span class="sd">        *disconnect</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">abstractmethod</span><span class="p">,</span> <span class="n">ABC</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="p">(</span><span class="n">overload</span><span class="p">,</span>
                    <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span>
                    <span class="n">Sequence</span><span class="p">,</span> <span class="n">Text</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Size</span><span class="p">,</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">Parameter</span>

<span class="kn">from</span> <span class="nn">tensorkrowch.utils</span> <span class="kn">import</span> <span class="p">(</span><span class="n">check_name_style</span><span class="p">,</span> <span class="n">enum_repeated_names</span><span class="p">,</span> <span class="n">erase_enum</span><span class="p">,</span>
                                <span class="n">print_list</span><span class="p">,</span> <span class="n">stack_unequal_tensors</span><span class="p">,</span> <span class="n">tab_string</span><span class="p">)</span>


<span class="c1">################################################</span>
<span class="c1">#                    AXIS                      #</span>
<span class="c1">################################################</span>
<div class="viewcode-block" id="Axis"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.Axis">[docs]</a><span class="k">class</span> <span class="nc">Axis</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The axes are the objects that stick edges to nodes. Every :class:`node &lt;AbstractNode&gt;`</span>
<span class="sd">    has a list of :math:`N` axes, each corresponding to one edge; and every axis</span>
<span class="sd">    stores information that helps accessing that edge, such as its :attr:`name`</span>
<span class="sd">    and :attr:`num` (index). Also, the axis keeps track of the :meth:`batch &lt;is_batch&gt;`</span>
<span class="sd">    and :meth:`node1 &lt;is_node1&gt;` attributes:</span>
<span class="sd">    </span>
<span class="sd">    * **batch**: If axis name containes the word &quot;`batch`&quot;, the edge attached</span>
<span class="sd">      to this axis will be a batch edge, that is, that edge will not be able to</span>
<span class="sd">      be connected to other nodes, but rather specify a dimension with which we</span>
<span class="sd">      can perform batch operations (e.g. batch contraction). If the name of the</span>
<span class="sd">      axis is changed and no longer contains the word &quot;`batch`&quot;, the corresponding</span>
<span class="sd">      edge will not be a batch edge any more. Also, :class:`StackNode` and</span>
<span class="sd">      :class:`ParamStackNode` instances always have an axis with name &quot;`stack`&quot;</span>
<span class="sd">      whose edge is a batch edge.</span>
<span class="sd">    </span>
<span class="sd">    * **node1**: When two dangling edges are connected the result is a new</span>
<span class="sd">      edge linking two nodes, say ``nodeA`` and ``nodeB``. If the</span>
<span class="sd">      connection is performed in the following order:</span>
<span class="sd">      ::</span>
<span class="sd">        new_edge = nodeA[edgeA] ^ nodeB[edgeB]</span>
<span class="sd">        </span>
<span class="sd">      Then ``nodeA`` will be the `node1` of ``new_edge`` and ``nodeB``, the `node2`.</span>
<span class="sd">      Hence, to access one of the nodes from ``new_edge`` one needs to know if it is</span>
<span class="sd">      `node1` or `node2`.</span>
<span class="sd">      </span>
<span class="sd">    Even though we can create Axis instances, that will not be usually the case,</span>
<span class="sd">    since axes are automatically created when instantiating a new :class:`node &lt;AbstractNode&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    num : int</span>
<span class="sd">        Index in the node&#39;s axes list.</span>
<span class="sd">    name : str</span>
<span class="sd">        Axis name, should not contain blank spaces or special characters since</span>
<span class="sd">        it is intended to be used as name of submodules.</span>
<span class="sd">    node : AbstractNode, optional</span>
<span class="sd">        Node to which the axis belongs</span>
<span class="sd">    node1 : bool</span>
<span class="sd">        Boolean indicating whether `node1` of the edge attached to this axis is</span>
<span class="sd">        the node that contains the axis (``True``). Otherwise, the node is `node2`</span>
<span class="sd">        of the edge (``False``).</span>
<span class="sd">        </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Although Axis will not be usually explicitly instantiated, it can be done</span>
<span class="sd">    like so:</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; axis = tk.Axis(0, &#39;left&#39;)</span>
<span class="sd">    &gt;&gt;&gt; axis</span>
<span class="sd">    Axis( left (0) )</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; axis.is_node1()</span>
<span class="sd">    True</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; axis.is_batch()</span>
<span class="sd">    False</span>
<span class="sd">    </span>
<span class="sd">    Since &quot;`batch`&quot; is not contained in &quot;`left`&quot;, ``axis`` does not correspond</span>
<span class="sd">    to a batch edge, but that can be changed:</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; axis.name = &#39;mybatch&#39;</span>
<span class="sd">    &gt;&gt;&gt; axis.is_batch()</span>
<span class="sd">    True</span>
<span class="sd">    </span>
<span class="sd">    Also, as explained before, knowing if a node is the `node1` or `node2` of an</span>
<span class="sd">    edge enables users to access that node from the edge:</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; nodeA = tk.Node(shape=(2, 3), axes_names=[&#39;left&#39;, &#39;right&#39;])</span>
<span class="sd">    &gt;&gt;&gt; nodeB = tk.Node(shape=(3, 4), axes_names=[&#39;left&#39;, &#39;right&#39;])</span>
<span class="sd">    &gt;&gt;&gt; new_edge = nodeA[&#39;right&#39;] ^ nodeB[&#39;left&#39;]</span>
<span class="sd">    &gt;&gt;&gt; nodeA == new_edge.nodes[1 - nodeA.get_axis(&#39;right&#39;).is_node1()]</span>
<span class="sd">    True</span>
<span class="sd">    </span>
<span class="sd">    &gt;&gt;&gt; nodeB == new_edge.nodes[nodeA.get_axis(&#39;right&#39;).is_node1()]</span>
<span class="sd">    True</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">num</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                 <span class="n">name</span><span class="p">:</span> <span class="n">Text</span><span class="p">,</span>
                 <span class="n">node</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s1">&#39;AbstractNode&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">node1</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

        <span class="c1"># Check types</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`num` should be int type&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`name` should be str type&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">check_name_style</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s1">&#39;axis&#39;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s1">&#39;`name` cannot contain blank spaces or special characters &#39;</span>
                <span class="s1">&#39;since it is intended to be used as name of submodules&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">node</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">AbstractNode</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`node` should be AbstractNode type&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">node1</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`node1` should be bool type&#39;</span><span class="p">)</span>

        <span class="c1"># Check name</span>
        <span class="k">if</span> <span class="s1">&#39;stack&#39;</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="p">(</span><span class="n">StackNode</span><span class="p">,</span> <span class="n">ParamStackNode</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Axis cannot be named `stack` if the node is &#39;</span>
                                 <span class="s1">&#39;not a StackNode or ParamStackNode&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">num</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Axis `stack` in node should have index 0&#39;</span><span class="p">)</span>

        <span class="c1"># Set attributes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_num</span> <span class="o">=</span> <span class="n">num</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_node</span> <span class="o">=</span> <span class="n">node</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_node1</span> <span class="o">=</span> <span class="n">node1</span>
        <span class="k">if</span> <span class="p">(</span><span class="s1">&#39;batch&#39;</span> <span class="ow">in</span> <span class="n">name</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="s1">&#39;stack&#39;</span> <span class="ow">in</span> <span class="n">name</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_batch</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_batch</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># properties</span>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">num</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Index in the node&#39;s axes list.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">name</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Text</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Axis name, used to access edges by name of the axis. It cannot contain</span>
<span class="sd">        blank spaces or special characters since it is intended to be used as</span>
<span class="sd">        name of submodules.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_name</span>

    <span class="nd">@name</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">name</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="n">Text</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set axis name. Should not contain blank spaces or special characters</span>
<span class="sd">        since it is intended to be used as name of submodules.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`name` should be str type&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">check_name_style</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s1">&#39;axis&#39;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s1">&#39;`name` cannot contain blank spaces or special characters &#39;</span>
                <span class="s1">&#39;since it is intended to be used as name of submodules&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_name</span> <span class="o">==</span> <span class="s1">&#39;stack&#39;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Name &quot;stack&quot; of stack edge cannot be changed&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="s1">&#39;stack&#39;</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s1">&#39;Name &quot;stack&quot; is reserved for stack edges of (Param)StackNodes&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch</span> <span class="ow">and</span> <span class="ow">not</span> <span class="p">(</span><span class="s1">&#39;batch&#39;</span> <span class="ow">in</span> <span class="n">name</span> <span class="ow">or</span> <span class="s1">&#39;stack&#39;</span> <span class="ow">in</span> <span class="n">name</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_batch</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch</span> <span class="ow">and</span> <span class="p">(</span><span class="s1">&#39;batch&#39;</span> <span class="ow">in</span> <span class="n">name</span> <span class="ow">or</span> <span class="s1">&#39;stack&#39;</span> <span class="ow">in</span> <span class="n">name</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_batch</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_node</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_node</span><span class="o">.</span><span class="n">_change_axis_name</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_name</span> <span class="o">=</span> <span class="n">name</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">node</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;AbstractNode&#39;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Node to which the axis belongs.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_node</span>

    <span class="c1"># methods</span>
<div class="viewcode-block" id="Axis.is_node1"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.Axis.is_node1">[docs]</a>    <span class="k">def</span> <span class="nf">is_node1</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns boolean indicating whether `node1` of the edge attached to this</span>
<span class="sd">        axis is the node that contains the axis. Otherwise, the node is `node2`</span>
<span class="sd">        of the edge.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_node1</span></div>

<div class="viewcode-block" id="Axis.is_batch"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.Axis.is_batch">[docs]</a>    <span class="k">def</span> <span class="nf">is_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns boolean indicating whether the edge in this axis is used as a</span>
<span class="sd">        batch edge.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch</span></div>

    <span class="k">def</span> <span class="fm">__int__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Text</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_name</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Text</span><span class="p">:</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1">( </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_name</span><span class="si">}</span><span class="s1"> (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_num</span><span class="si">}</span><span class="s1">) )&#39;</span></div>


<span class="c1">################################################</span>
<span class="c1">#                   NODES                      #</span>
<span class="c1">################################################</span>
<span class="n">Ax</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Text</span><span class="p">,</span> <span class="n">Axis</span><span class="p">]</span>
<span class="n">Shape</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">Size</span><span class="p">]</span>


<div class="viewcode-block" id="AbstractNode"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractNode">[docs]</a><span class="k">class</span> <span class="nc">AbstractNode</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstract class for all types of nodes. Defines what a node is and most of its</span>
<span class="sd">    properties and methods. Since it is an abstract class, cannot be instantiated.</span>
<span class="sd">    </span>
<span class="sd">    A node is the minimum element in a :class:`TensorNetwork`. At its most basic</span>
<span class="sd">    level, it is just a container for a tensor that stores information about its</span>
<span class="sd">    neighbours (with what other nodes it is connected), edges (names to access</span>
<span class="sd">    each of them, whether they are batch edges or not, etc.) or successors (nodes</span>
<span class="sd">    that result from operating the node). Besides, and what is more important,</span>
<span class="sd">    this information is useful to:</span>
<span class="sd">    </span>
<span class="sd">    * Perform tensor network :class:`Operations &lt;Operation&gt;` such as :func:`contraction</span>
<span class="sd">      &lt;contract_between&gt;` of two neighbouring nodes without having to worry about</span>
<span class="sd">      tensor&#39;s shapes, order of axes, etc.</span>
<span class="sd">      </span>
<span class="sd">    * Perform more advanced operations such as :func:`stack` or :func:`unbind`</span>
<span class="sd">      saving memory and time.</span>
<span class="sd">      </span>
<span class="sd">    * Keep track of operations in which a node has taken place, so that several</span>
<span class="sd">      steps can be skipped in further training iterations. See :meth:`TensorNetwork.trace`.</span>
<span class="sd">    </span>
<span class="sd">    Refer to the subclasses of ``AbstractNode`` to see how to instantiate nodes:</span>
<span class="sd">    </span>
<span class="sd">    * :class:`Node`</span>
<span class="sd">    </span>
<span class="sd">    * :class:`ParamNode`</span>
<span class="sd">    </span>
<span class="sd">    * :class:`StackNode`</span>
<span class="sd">    </span>
<span class="sd">    * :class:`ParamStackNode`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">shape</span><span class="p">:</span> <span class="n">Shape</span><span class="p">,</span>
                 <span class="n">axes_names</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">Text</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Text</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">network</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s1">&#39;TensorNetwork&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">leaf</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                 <span class="n">data</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                 <span class="n">virtual</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># check shape</span>
        <span class="k">if</span> <span class="n">shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">,</span> <span class="n">Size</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="s1">&#39;`shape` should be tuple[int, ...], list[int, ...] or &#39;</span>
                    <span class="s1">&#39;torch.Size type&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">shape</span><span class="p">:</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`shape` elements should be int type&#39;</span><span class="p">)</span>

        <span class="c1"># check axes_names</span>
        <span class="k">if</span> <span class="n">axes_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">axes</span> <span class="o">=</span> <span class="p">[</span><span class="n">Axis</span><span class="p">(</span><span class="n">num</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;axis_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">node</span><span class="o">=</span><span class="bp">self</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">shape</span><span class="p">)]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axes_names</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="s1">&#39;`axes_names` should be tuple[str, ...] or list[str, ...] type&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">axes_names</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s1">&#39;`axes_names` length should match `shape` length&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">axes_names</span> <span class="o">=</span> <span class="n">enum_repeated_names</span><span class="p">(</span><span class="n">axes_names</span><span class="p">)</span>
                <span class="n">axes</span> <span class="o">=</span> <span class="p">[</span><span class="n">Axis</span><span class="p">(</span><span class="n">num</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">node</span><span class="o">=</span><span class="bp">self</span><span class="p">)</span>
                        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axes_names</span><span class="p">)]</span>

        <span class="c1"># check name</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`name` should be str type&#39;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="n">check_name_style</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s1">&#39;node&#39;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Names cannot contain blank spaces&#39;</span><span class="p">)</span>

        <span class="c1"># check network</span>
        <span class="k">if</span> <span class="n">network</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">TensorNetwork</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`network` should be TensorNetwork type&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">network</span> <span class="o">=</span> <span class="n">TensorNetwork</span><span class="p">()</span>

        <span class="c1"># check leaf and data</span>
        <span class="k">if</span> <span class="n">data</span> <span class="ow">and</span> <span class="n">virtual</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s1">&#39;`data` and `virtual` arguments cannot be both True&#39;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">data</span> <span class="ow">or</span> <span class="n">virtual</span><span class="p">:</span>
            <span class="n">leaf</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># Set attributes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tensor_info</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_temp_tensor</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_axes</span> <span class="o">=</span> <span class="n">axes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_edges</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_network</span> <span class="o">=</span> <span class="n">network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_leaf</span> <span class="o">=</span> <span class="n">leaf</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="n">data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_virtual</span> <span class="o">=</span> <span class="n">virtual</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_successors</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

    <span class="c1"># ----------</span>
    <span class="c1"># Properties</span>
    <span class="c1"># ----------</span>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Node&#39;s tensor. It can be a ``torch.Tensor``, ``torch.nn.Parameter`` or</span>
<span class="sd">        None if the node is empty.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_temp_tensor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensor_info</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
            <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_temp_tensor</span>
            <span class="k">return</span> <span class="n">result</span>

        <span class="n">address</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;address&#39;</span><span class="p">]</span>
        <span class="n">node_ref</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;node_ref&#39;</span><span class="p">]</span>
        <span class="n">full</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;full&#39;</span><span class="p">]</span>
        <span class="n">index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;index&#39;</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">address</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">address</span> <span class="o">=</span> <span class="n">node_ref</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;address&#39;</span><span class="p">]</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="o">.</span><span class="n">_memory_nodes</span><span class="p">[</span><span class="n">address</span><span class="p">]</span>
        
        <span class="n">return_result</span> <span class="o">=</span> <span class="n">full</span> <span class="ow">or</span> <span class="p">(</span><span class="n">result</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="o">.</span><span class="n">_unbind_mode</span><span class="p">:</span>
            <span class="n">return_result</span> <span class="o">=</span> <span class="n">return_result</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;unbind&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">return_result</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">result</span>
        <span class="k">return</span> <span class="n">result</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

    <span class="nd">@tensor</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">tensor</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">unset_tensor</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_tensor</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">shape</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Size</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Shape of node&#39;s :attr:`tensor`. It is a ``torch.Size``.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">rank</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Length of node&#39;s :attr:`shape`, that is, number of edges of the node.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">dtype</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;``torch.dtype`` of node&#39;s :attr:`tensor`.&quot;&quot;&quot;</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor</span>
        <span class="k">if</span> <span class="n">tensor</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="k">return</span> <span class="n">tensor</span><span class="o">.</span><span class="n">dtype</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">axes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Axis</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;List of nodes&#39;s :class:`axes &lt;Axis&gt;`.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_axes</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">axes_names</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Text</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;List of names of node&#39;s axes.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">axis</span><span class="p">:</span> <span class="n">axis</span><span class="o">.</span><span class="n">_name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_axes</span><span class="p">))</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">edges</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="s1">&#39;AbstractEdge&#39;</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;List of node&#39;s :class:`edges &lt;AbstractEdge&gt;`.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edges</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">network</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;TensorNetwork&#39;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        :class:`TensorNetwork` where the node belongs. If the node is moved to</span>
<span class="sd">        another :class:`TensorNetwork`, the entire connected component of the</span>
<span class="sd">        graph where the node is will be moved.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_network</span>

    <span class="nd">@network</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">network</span><span class="p">:</span> <span class="s1">&#39;TensorNetwork&#39;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">move_to_network</span><span class="p">(</span><span class="n">network</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">successors</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Text</span><span class="p">,</span> <span class="s1">&#39;Successor&#39;</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Dictionary with :class:`Operations &lt;Operation&gt;`&#39; names as keys, and the</span>
<span class="sd">        list of :class:`Successors &lt;Successor&gt;` of the node as values.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_successors</span>
    
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">name</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Text</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Node&#39;s name, used to access the node from the :attr:`tensor network &lt;network&gt;`</span>
<span class="sd">        where it belongs. It cannot contain blank spaces.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_name</span>

    <span class="nd">@name</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">name</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="n">Text</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`name` should be str type&#39;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="n">check_name_style</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s1">&#39;node&#39;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;`name` cannot contain blank spaces&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="o">.</span><span class="n">_change_node_name</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>

    <span class="c1"># ----------------</span>
    <span class="c1"># Abstract methods</span>
    <span class="c1"># ----------------</span>
    <span class="nd">@staticmethod</span>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">_set_tensor_format</span><span class="p">(</span><span class="n">tensor</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">]:</span>
        <span class="k">pass</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">parameterize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">set_param</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;AbstractNode&#39;</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;AbstractNode&#39;</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="c1"># -------</span>
    <span class="c1"># Methods</span>
    <span class="c1"># -------</span>
<div class="viewcode-block" id="AbstractNode.is_leaf"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractNode.is_leaf">[docs]</a>    <span class="k">def</span> <span class="nf">is_leaf</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a boolean indicating if the node is a ``leaf`` node. These are</span>
<span class="sd">        the nodes that form the :class:`TensorNetwork`. Usually, these will be</span>
<span class="sd">        the `trainable` nodes.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_leaf</span></div>

<div class="viewcode-block" id="AbstractNode.is_data"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractNode.is_data">[docs]</a>    <span class="k">def</span> <span class="nf">is_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a boolean indicating if the node is a ``data`` node. These are</span>
<span class="sd">        the nodes where input data tensors will be put.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span></div>

<div class="viewcode-block" id="AbstractNode.is_virtual"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractNode.is_virtual">[docs]</a>    <span class="k">def</span> <span class="nf">is_virtual</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a boolean indicating if the node is a ``virtual`` node. These</span>
<span class="sd">        are a sort of `hidden` nodes that can be used, for instance, to store</span>
<span class="sd">        the information of other ``leaf`` or ``data`` nodes more efficiently</span>
<span class="sd">        (e.g. :class:`Uniform MPS &lt;UMPS&gt;` uses a unique ``virtual`` node to</span>
<span class="sd">        store the tensor used by all the nodes in the network).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_virtual</span></div>

<div class="viewcode-block" id="AbstractNode.is_non_leaf"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractNode.is_non_leaf">[docs]</a>    <span class="k">def</span> <span class="nf">is_non_leaf</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a boolean indicating if the node is a ``non_leaf`` node. These</span>
<span class="sd">        are the nodes that result from an operation on any type of nodes.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_leaf</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_virtual</span><span class="p">)</span></div>

<div class="viewcode-block" id="AbstractNode.size"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractNode.size">[docs]</a>    <span class="k">def</span> <span class="nf">size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Ax</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Size</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the size of the node&#39;s tensor. If ``axis`` is specified, returns</span>
<span class="sd">        the size of that axis; otherwise returns the shape of the node (same as</span>
<span class="sd">        :attr:`shape`).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        axis : int, str or Axis, optional</span>
<span class="sd">            Axis for which to retrieve the size.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int or torch.Size</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span>
        <span class="n">axis_num</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_axis_num</span><span class="p">(</span><span class="n">axis</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">[</span><span class="n">axis_num</span><span class="p">]</span></div>

<div class="viewcode-block" id="AbstractNode.dim"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractNode.dim">[docs]</a>    <span class="k">def</span> <span class="nf">dim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Ax</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Size</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the dimensions of the node&#39;s tensor. If ``axis`` is specified,</span>
<span class="sd">        returns the dimension of that edge; otherwise returns the dimensions of</span>
<span class="sd">        all edges.</span>
<span class="sd">        </span>
<span class="sd">        See also :meth:`Edge.dim` and :meth:`ParamEdge.dim`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        axis : int, str or Axis, optional</span>
<span class="sd">            Axis for which to retrieve the dimension.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int or torch.Size</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Size</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">edge</span><span class="p">:</span> <span class="n">edge</span><span class="o">.</span><span class="n">dim</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edges</span><span class="p">))</span>
        <span class="n">axis_num</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_axis_num</span><span class="p">(</span><span class="n">axis</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edges</span><span class="p">[</span><span class="n">axis_num</span><span class="p">]</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span></div>

<div class="viewcode-block" id="AbstractNode.is_node1"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractNode.is_node1">[docs]</a>    <span class="k">def</span> <span class="nf">is_node1</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Ax</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">bool</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns :meth:`node &lt;Axis.is_node1&gt;` attribute of axes of the node. If</span>
<span class="sd">        ``axis`` is specified, returns only the ``node`` of that axis; otherwise</span>
<span class="sd">        returns the ``node1`` of all axes of the node.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        axis : int, str or Axis, optional</span>
<span class="sd">            Axis for which to retrieve the ``node1``.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        bool or list[bool]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">ax</span><span class="p">:</span> <span class="n">ax</span><span class="o">.</span><span class="n">_node1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_axes</span><span class="p">))</span>
        <span class="n">axis_num</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_axis_num</span><span class="p">(</span><span class="n">axis</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_axes</span><span class="p">[</span><span class="n">axis_num</span><span class="p">]</span><span class="o">.</span><span class="n">_node1</span></div>

<div class="viewcode-block" id="AbstractNode.neighbours"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractNode.neighbours">[docs]</a>    <span class="k">def</span> <span class="nf">neighbours</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Ax</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="s1">&#39;AbstractNode&#39;</span><span class="p">],</span>
                                                             <span class="n">List</span><span class="p">[</span><span class="s1">&#39;AbstractNode&#39;</span><span class="p">]]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the neighbours of the node, the nodes to which it is connected.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        axis : int, str or Axis, optional</span>
<span class="sd">            Axis for which to retrieve the neighbour.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        AbstractNode or list[AbstractNode]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">node1_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_node1</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">node2</span> <span class="o">=</span> <span class="bp">self</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span><span class="o">.</span><span class="n">_nodes</span><span class="p">[</span><span class="n">node1_list</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">get_axis_num</span><span class="p">(</span><span class="n">axis</span><span class="p">)]]</span>
            <span class="k">return</span> <span class="n">node2</span>
        
        <span class="n">neighbours</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">edge</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_edges</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">edge</span><span class="o">.</span><span class="n">is_dangling</span><span class="p">():</span>
                <span class="n">node2</span> <span class="o">=</span> <span class="n">edge</span><span class="o">.</span><span class="n">_nodes</span><span class="p">[</span><span class="n">node1_list</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
                <span class="n">neighbours</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">node2</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">neighbours</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_change_axis_name</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="n">Axis</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="n">Text</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Changes the name of an axis. If an axis belongs to a node, we have to</span>
<span class="sd">        take care of repeated names. If the name that is going to be assigned</span>
<span class="sd">        to the axis is already set for another axis, we change  those names by</span>
<span class="sd">        an enumerated version of them.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        axis : Axis</span>
<span class="sd">            Axis whose name is going to be changed.</span>
<span class="sd">        name : str</span>
<span class="sd">            New name.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If ``axis`` does not belong to the node.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">axis</span><span class="o">.</span><span class="n">_node</span> <span class="o">!=</span> <span class="bp">self</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Cannot change the name of an axis that does &#39;</span>
                             <span class="s1">&#39;not belong to the node&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">name</span> <span class="o">!=</span> <span class="n">axis</span><span class="o">.</span><span class="n">_name</span><span class="p">:</span>
            <span class="n">axes_names</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">axes_names</span><span class="p">[:]</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">axis_name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axes_names</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">axis_name</span> <span class="o">==</span> <span class="n">axis</span><span class="o">.</span><span class="n">_name</span><span class="p">:</span>  <span class="c1"># Axes names are unique</span>
                    <span class="n">axes_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">name</span>
                    <span class="k">break</span>
            <span class="n">new_axes_names</span> <span class="o">=</span> <span class="n">enum_repeated_names</span><span class="p">(</span><span class="n">axes_names</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">axis</span><span class="p">,</span> <span class="n">axis_name</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_axes</span><span class="p">,</span> <span class="n">new_axes_names</span><span class="p">):</span>
                <span class="n">axis</span><span class="o">.</span><span class="n">_name</span> <span class="o">=</span> <span class="n">axis_name</span>

    <span class="k">def</span> <span class="nf">_change_axis_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="n">Ax</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Changes axis size, that is, changes size of node&#39;s tensor and corresponding</span>
<span class="sd">        edges at a certain axis.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        axis : int, str or Axis</span>
<span class="sd">            Axis where size is going to be changed.</span>
<span class="sd">        size : int</span>
<span class="sd">            New size.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If new size is not positive.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">size</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;New `size` should be greater than zero&#39;</span><span class="p">)</span>
        <span class="n">axis_num</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_axis_num</span><span class="p">(</span><span class="n">axis</span><span class="p">)</span>

        <span class="n">tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor</span>
        <span class="k">if</span> <span class="n">tensor</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">aux_shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">)</span>
            <span class="n">aux_shape</span><span class="p">[</span><span class="n">axis_num</span><span class="p">]</span> <span class="o">=</span> <span class="n">size</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">aux_shape</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">size</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">[</span><span class="n">axis_num</span><span class="p">]:</span>
                <span class="c1"># If new size is smaller than current, tensor is cropped</span>
                <span class="c1"># starting from the &quot;left&quot;, &quot;top&quot;, &quot;front&quot;, etc. in each dimension</span>
                <span class="n">index</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">axis_num</span><span class="p">:</span>
                        <span class="n">index</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="n">dim</span> <span class="o">-</span> <span class="n">size</span><span class="p">,</span> <span class="n">dim</span><span class="p">))</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">index</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim</span><span class="p">))</span>
                <span class="n">aux_shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">)</span>
                <span class="n">aux_shape</span><span class="p">[</span><span class="n">axis_num</span><span class="p">]</span> <span class="o">=</span> <span class="n">size</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">aux_shape</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tensor</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

            <span class="k">elif</span> <span class="n">size</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">[</span><span class="n">axis_num</span><span class="p">]:</span>
                <span class="c1"># If new size is greater than current, tensor is expanded with</span>
                <span class="c1"># zeros in the &quot;left&quot;, &quot;top&quot;, &quot;front&quot;, etc. dimension</span>
                <span class="n">pad</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">axis_num</span><span class="p">:</span>
                        <span class="n">pad</span> <span class="o">+=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">size</span> <span class="o">-</span> <span class="n">dim</span><span class="p">]</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">pad</span> <span class="o">+=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
                <span class="n">pad</span><span class="o">.</span><span class="n">reverse</span><span class="p">()</span>
                <span class="n">aux_shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">)</span>
                <span class="n">aux_shape</span><span class="p">[</span><span class="n">axis_num</span><span class="p">]</span> <span class="o">=</span> <span class="n">size</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">aux_shape</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">tensor</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">pad</span><span class="p">)</span>

<div class="viewcode-block" id="AbstractNode.get_axis"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractNode.get_axis">[docs]</a>    <span class="k">def</span> <span class="nf">get_axis</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="n">Ax</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;AbstractEdge&#39;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns :class:`Axis` given its ``name`` or ``num``.&quot;&quot;&quot;</span>
        <span class="n">axis_num</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_axis_num</span><span class="p">(</span><span class="n">axis</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_axes</span><span class="p">[</span><span class="n">axis_num</span><span class="p">]</span></div>
    
<div class="viewcode-block" id="AbstractNode.get_axis_num"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractNode.get_axis_num">[docs]</a>    <span class="k">def</span> <span class="nf">get_axis_num</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="n">Ax</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns axis&#39; ``num`` given the :class:`Axis` or its ``name``.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">axis</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">axis</span> <span class="o">=</span> <span class="n">axis</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span>  <span class="c1"># When indexing with -1, -2, ...</span>
            <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_axes</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">axis</span> <span class="o">==</span> <span class="n">ax</span><span class="o">.</span><span class="n">_num</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">ax</span><span class="o">.</span><span class="n">_num</span>
            <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Node </span><span class="si">{</span><span class="bp">self</span><span class="si">!s}</span><span class="s1"> has no axis with index </span><span class="si">{</span><span class="n">axis</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_axes</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">axis</span> <span class="o">==</span> <span class="n">ax</span><span class="o">.</span><span class="n">_name</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">ax</span><span class="o">.</span><span class="n">_num</span>
            <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Node </span><span class="si">{</span><span class="bp">self</span><span class="si">!s}</span><span class="s1"> has no axis with name </span><span class="si">{</span><span class="n">axis</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="n">Axis</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_axes</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">axis</span> <span class="o">==</span> <span class="n">ax</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">ax</span><span class="o">.</span><span class="n">_num</span>
            <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Node </span><span class="si">{</span><span class="bp">self</span><span class="si">!s}</span><span class="s1"> has no axis </span><span class="si">{</span><span class="n">axis</span><span class="si">!r}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`axis` should be int, str or Axis type&#39;</span><span class="p">)</span></div>
        
    <span class="k">def</span> <span class="nf">_add_edge</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                  <span class="n">edge</span><span class="p">:</span> <span class="s1">&#39;AbstractEdge&#39;</span><span class="p">,</span>
                  <span class="n">axis</span><span class="p">:</span> <span class="n">Ax</span><span class="p">,</span>
                  <span class="n">node1</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Adds an edge to the specified axis of the node.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        edge : AbstractEdge</span>
<span class="sd">            Edge that will be added.</span>
<span class="sd">        axis : int, str or Axis</span>
<span class="sd">            Axes where the edge will be attached.</span>
<span class="sd">        node1 : bool, optional</span>
<span class="sd">            Boolean indicating whether the node is the `node1` (``True``) or</span>
<span class="sd">            `node2` (``False``) of the edge.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">axis_num</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_axis_num</span><span class="p">(</span><span class="n">axis</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_axes</span><span class="p">[</span><span class="n">axis_num</span><span class="p">]</span><span class="o">.</span><span class="n">_node1</span> <span class="o">=</span> <span class="n">node1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_edges</span><span class="p">[</span><span class="n">axis_num</span><span class="p">]</span> <span class="o">=</span> <span class="n">edge</span>
        
    <span class="k">def</span> <span class="nf">_reattach_edges</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">override</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Substitutes current edges by copies of them that are attached to the node.</span>
<span class="sd">        It can happen that an edge is not attached to the node if it is the result</span>
<span class="sd">        of an :class:`Operation` and, hence, it inherits edges from the operands.</span>
<span class="sd">        In that case, the new copied edges will be attached to the resultant node,</span>
<span class="sd">        replacing each previous `node1` or `node2` with it (according to the `node1`</span>
<span class="sd">        attribute of each axis).</span>
<span class="sd">        </span>
<span class="sd">        Used for inplace operations like :func:`permute_` or :func`split_` and</span>
<span class="sd">        to :meth:`Node.parameterize`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        override: bool</span>
<span class="sd">            Boolean indicating if the new, reattached edges should also replace</span>
<span class="sd">            the corresponding edges in the node&#39;s neighbours (``True``). Otherwise,</span>
<span class="sd">            the neighbours&#39; edges will be pointing to the original nodes from which</span>
<span class="sd">            the current node inherits its edges (``False``).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">edge</span><span class="p">,</span> <span class="n">node1</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_edges</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_node1</span><span class="p">())):</span>
            <span class="n">node</span> <span class="o">=</span> <span class="n">edge</span><span class="o">.</span><span class="n">_nodes</span><span class="p">[</span><span class="mi">1</span> <span class="o">-</span> <span class="n">node1</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">node</span> <span class="o">!=</span> <span class="bp">self</span><span class="p">:</span>
                <span class="c1"># New edges are always a copy, so that the original</span>
                <span class="c1"># nodes have different edges from the current node</span>
                <span class="n">new_edge</span> <span class="o">=</span> <span class="n">edge</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_edges</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_edge</span>

                <span class="n">new_edge</span><span class="o">.</span><span class="n">_nodes</span><span class="p">[</span><span class="mi">1</span> <span class="o">-</span> <span class="n">node1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span>
                <span class="n">new_edge</span><span class="o">.</span><span class="n">_axes</span><span class="p">[</span><span class="mi">1</span> <span class="o">-</span> <span class="n">node1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

                <span class="c1"># Case of trace edges (attached to the node in two axes)</span>
                <span class="n">neighbour</span> <span class="o">=</span> <span class="n">new_edge</span><span class="o">.</span><span class="n">_nodes</span><span class="p">[</span><span class="n">node1</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">neighbour</span> <span class="o">==</span> <span class="n">node</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">other_edge</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_edges</span><span class="p">):</span>
                        <span class="k">if</span> <span class="p">(</span><span class="n">other_edge</span> <span class="o">==</span> <span class="n">edge</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">i</span> <span class="o">!=</span> <span class="n">j</span><span class="p">):</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">_edges</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_edge</span>
                            <span class="n">new_edge</span><span class="o">.</span><span class="n">_nodes</span><span class="p">[</span><span class="n">node1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span>
                            <span class="n">new_edge</span><span class="o">.</span><span class="n">_axes</span><span class="p">[</span><span class="n">node1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_axes</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>

                <span class="k">if</span> <span class="n">override</span><span class="p">:</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">new_edge</span><span class="o">.</span><span class="n">is_dangling</span><span class="p">()</span> <span class="ow">and</span> <span class="p">(</span><span class="n">neighbour</span> <span class="o">!=</span> <span class="n">node</span><span class="p">):</span>
                        <span class="n">neighbour</span><span class="o">.</span><span class="n">_add_edge</span><span class="p">(</span>
                            <span class="n">new_edge</span><span class="p">,</span> <span class="n">new_edge</span><span class="o">.</span><span class="n">_axes</span><span class="p">[</span><span class="n">node1</span><span class="p">],</span> <span class="ow">not</span> <span class="n">node1</span><span class="p">)</span>
        
<div class="viewcode-block" id="AbstractNode.get_edge"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractNode.get_edge">[docs]</a>    <span class="k">def</span> <span class="nf">get_edge</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="n">Ax</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;AbstractEdge&#39;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns :class:`AbstractEdge` given the :class:`Axis` (or its ``name``</span>
<span class="sd">        or ``num``) where it is attached to the node.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">axis_num</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_axis_num</span><span class="p">(</span><span class="n">axis</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edges</span><span class="p">[</span><span class="n">axis_num</span><span class="p">]</span></div>
    
<div class="viewcode-block" id="AbstractNode.in_which_axis"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractNode.in_which_axis">[docs]</a>    <span class="k">def</span> <span class="nf">in_which_axis</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">edge</span><span class="p">:</span> <span class="s1">&#39;AbstractEdge&#39;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Axis</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns :class:`Axis` given the :class:`AbstractEdge` that is attached</span>
<span class="sd">        to the node through it.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">lst</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">ed</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_axes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edges</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">ed</span> <span class="o">==</span> <span class="n">edge</span><span class="p">:</span>
                <span class="n">lst</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lst</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Edge </span><span class="si">{</span><span class="n">edge</span><span class="si">}</span><span class="s1"> not in node </span><span class="si">{</span><span class="bp">self</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">lst</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">lst</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Case of trace edges (attached to the node in two axes)</span>
            <span class="k">return</span> <span class="n">lst</span></div>

<div class="viewcode-block" id="AbstractNode.param_edges"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractNode.param_edges">[docs]</a>    <span class="k">def</span> <span class="nf">param_edges</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                    <span class="n">set_param</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                    <span class="n">sizes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns ``param_edges`` attribute or changes it if ``set_param`` is provided,</span>
<span class="sd">        by parameterizing or de-parameterizing all edges (see also :meth:`Edge.parameterize`</span>
<span class="sd">        or :meth:`ParamEdge.parameterize`).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        set_param : bool, optional</span>
<span class="sd">            Boolean indicating whether edges have to be parameterized (``True``)</span>
<span class="sd">            or de-parameterized (``False``).</span>
<span class="sd">        sizes : list[int] or tuple[int], optional</span>
<span class="sd">            Sizes used to expand or shrink the node&#39;s shape if desired. If edges</span>
<span class="sd">            are parameterized, their dimensions will be :math:`\text{dim} =</span>
<span class="sd">            \min(\text{prev_size}, \text{new_size})`</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        bool or None</span>
<span class="sd">            If ``set_param`` is not provided, returns ``True`` if all edges are</span>
<span class="sd">            :class:`ParamEdges &lt;ParamEdge&gt;` or ``False`` if all edges are</span>
<span class="sd">            :class:`Edges &lt;Edge&gt;`. If there are some of each type, or ``set_param``</span>
<span class="sd">            is provided, returns None.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If ``sizes`` are provided but do not match the number of edges of</span>
<span class="sd">            the node.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">set_param</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">all_edges</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">all_param_edges</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edges</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edge</span><span class="p">,</span> <span class="n">ParamEdge</span><span class="p">):</span>
                    <span class="n">all_edges</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edge</span><span class="p">,</span> <span class="n">Edge</span><span class="p">):</span>
                    <span class="n">all_param_edges</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="k">if</span> <span class="n">all_edges</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">False</span>
            <span class="k">elif</span> <span class="n">all_param_edges</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">True</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">None</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">set_param</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">sizes</span><span class="p">:</span>
                    <span class="n">sizes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span>
                <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_axes</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s1">&#39;`sizes` length should match the number of node</span><span class="se">\&#39;</span><span class="s1">s axes&#39;</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">edge</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_edges</span><span class="p">):</span>
                    <span class="n">edge</span><span class="o">.</span><span class="n">parameterize</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">sizes</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">param_edge</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edges</span><span class="p">:</span>
                    <span class="n">param_edge</span><span class="o">.</span><span class="n">parameterize</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span></div>

<div class="viewcode-block" id="AbstractNode.disconnect"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractNode.disconnect">[docs]</a>    <span class="k">def</span> <span class="nf">disconnect</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Ax</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Disconnects all edges of the node if they were connected to other nodes.</span>
<span class="sd">        If ``axis`` is sepcified, only the corresponding edge is disconnected.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        axis : int, str or Axis, optional</span>
<span class="sd">            Axis whose edge will be disconnected.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">edges</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">[</span><span class="n">axis</span><span class="p">]]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">edges</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edges</span>

        <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">edges</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">edge</span><span class="o">.</span><span class="n">is_attached_to</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">edge</span><span class="o">.</span><span class="n">is_dangling</span><span class="p">():</span>
                    <span class="n">edge</span> <span class="o">|</span> <span class="n">edge</span></div>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_make_copy_tensor</span><span class="p">(</span><span class="n">shape</span><span class="p">:</span> <span class="n">Shape</span><span class="p">,</span>
                          <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">))</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns copy tensor (ones in the &quot;diagonal&quot;, zeros elsewhere).&quot;&quot;&quot;</span>
        <span class="n">copy_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="n">rank</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">shape</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="n">copy_tensor</span><span class="p">[(</span><span class="n">i</span><span class="p">,)</span> <span class="o">*</span> <span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.</span>
        <span class="k">return</span> <span class="n">copy_tensor</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_make_rand_tensor</span><span class="p">(</span><span class="n">shape</span><span class="p">:</span> <span class="n">Shape</span><span class="p">,</span>
                          <span class="n">low</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">,</span>
                          <span class="n">high</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.</span><span class="p">,</span>
                          <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">))</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns tensor whose entries are drawn from the uniform distribution.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">low</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`low` should be float type&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">high</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`high` should be float type&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">low</span> <span class="o">&gt;=</span> <span class="n">high</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;`low` should be strictly smaller than `high`&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">high</span> <span class="o">-</span> <span class="n">low</span><span class="p">)</span> <span class="o">+</span> <span class="n">low</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_make_randn_tensor</span><span class="p">(</span><span class="n">shape</span><span class="p">:</span> <span class="n">Shape</span><span class="p">,</span>
                           <span class="n">mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">,</span>
                           <span class="n">std</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.</span><span class="p">,</span>
                           <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">))</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns tensor whose entries are drawn from the normal distribution.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`mean` should be float type&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">std</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`std` should be float type&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">std</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;`std` should be positive&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="o">*</span> <span class="n">std</span> <span class="o">+</span> <span class="n">mean</span>

<div class="viewcode-block" id="AbstractNode.make_tensor"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractNode.make_tensor">[docs]</a>    <span class="k">def</span> <span class="nf">make_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                    <span class="n">shape</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Shape</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                    <span class="n">init_method</span><span class="p">:</span> <span class="n">Text</span> <span class="o">=</span> <span class="s1">&#39;zeros&#39;</span><span class="p">,</span>
                    <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">),</span>
                    <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a tensor that can be put in the node, and is initialized according</span>
<span class="sd">        to ``init_method``. By default, it has the same shape as the node.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        shape : list[int], tuple[int] or torch.Size, optional</span>
<span class="sd">            Shape of the tensor. If None, node&#39;s shape will be used.</span>
<span class="sd">        init_method : {&quot;zeros&quot;, &quot;ones&quot;, &quot;copy&quot;, &quot;rand&quot;, &quot;randn&quot;}, optional</span>
<span class="sd">            Initialization method.</span>
<span class="sd">        device : torch.device, optional</span>
<span class="sd">            Device where to initialize the tensor.</span>
<span class="sd">        kwargs : float</span>
<span class="sd">            Keyword arguments for the different initialization methods:</span>
<span class="sd">            </span>
<span class="sd">            * ``low``, ``high`` for uniform initialization. See</span>
<span class="sd">              `torch.rand() &lt;https://pytorch.org/docs/stable/generated/torch.rand.html&gt;`_</span>
<span class="sd">            </span>
<span class="sd">            * ``mean``, ``std`` for normal initialization. See</span>
<span class="sd">              `torch.randn() &lt;https://pytorch.org/docs/stable/generated/torch.randn.html&gt;`_</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If ``init_method`` is not one of &quot;zeros&quot;, &quot;ones&quot;, &quot;copy&quot;, &quot;rand&quot;, &quot;randn&quot;.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">shape</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span>
        <span class="k">if</span> <span class="n">init_method</span> <span class="o">==</span> <span class="s1">&#39;zeros&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">init_method</span> <span class="o">==</span> <span class="s1">&#39;ones&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">init_method</span> <span class="o">==</span> <span class="s1">&#39;copy&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_copy_tensor</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">init_method</span> <span class="o">==</span> <span class="s1">&#39;rand&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_rand_tensor</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">init_method</span> <span class="o">==</span> <span class="s1">&#39;randn&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_randn_tensor</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Choose a valid `init_method`: &quot;zeros&quot;, &#39;</span>
                             <span class="s1">&#39;&quot;ones&quot;, &quot;copy&quot;, &quot;rand&quot;, &quot;randn&quot;&#39;</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_compatible_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Checks if tensor&#39;s shape is &quot;compatible&quot; with the node&#39;s shape, meaning</span>
<span class="sd">        that the sizes in all axes must match except for the batch axes, where</span>
<span class="sd">        sizes can be different.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">):</span>
                <span class="n">edge</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_edge</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">edge</span><span class="o">.</span><span class="n">is_batch</span><span class="p">()</span> <span class="ow">and</span> <span class="p">(</span><span class="n">dim</span> <span class="o">!=</span> <span class="n">edge</span><span class="o">.</span><span class="n">size</span><span class="p">()):</span>
                    <span class="k">return</span> <span class="kc">False</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">_crop_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">allow_diff_shape</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Crops the tensor in case its shape is not compatible with the node&#39;s shape.</span>
<span class="sd">        That is, if the tensor has a size that is smaller than the corresponding</span>
<span class="sd">        size of the node for a certain axis, the tensor is cropped in that axis</span>
<span class="sd">        (provided that the axis is not a batch axis). If that size is greater in</span>
<span class="sd">        the tensor that in the node, raises a ``ValueError``.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor : torch.Tensor</span>
<span class="sd">            Tensor to be cropped.</span>
<span class="sd">        allow_diff_shape : bool</span>
<span class="sd">            Boolean indicating whether different sizes are allowed for all axes</span>
<span class="sd">            (``True``), rather than just for batch axes (``Falsee``). If ``True``,</span>
<span class="sd">            any tensor could be set in the node, and the node&#39;s shape would change</span>
<span class="sd">            accordingly.</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">:</span>
            <span class="n">index</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">):</span>
                <span class="n">edge</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_edge</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">edge</span><span class="o">.</span><span class="n">is_batch</span><span class="p">()</span> <span class="ow">or</span> <span class="p">(</span><span class="n">dim</span> <span class="o">==</span> <span class="n">edge</span><span class="o">.</span><span class="n">size</span><span class="p">())</span> <span class="ow">or</span> <span class="n">allow_diff_shape</span><span class="p">:</span>
                    <span class="n">index</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim</span><span class="p">))</span>
                <span class="k">elif</span> <span class="n">dim</span> <span class="o">&gt;</span> <span class="n">edge</span><span class="o">.</span><span class="n">size</span><span class="p">():</span>
                    <span class="n">index</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="n">dim</span> <span class="o">-</span> <span class="n">edge</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">dim</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Cannot crop tensor if its size at axis </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span>
                                     <span class="s1">&#39; is smaller than node</span><span class="se">\&#39;</span><span class="s1">s size&#39;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">tensor</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;`tensor` should have the same number of&#39;</span>
                             <span class="s1">&#39; dimensions as node</span><span class="se">\&#39;</span><span class="s1">s tensor (same rank)&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_unrestricted_set_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                 <span class="n">tensor</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                                 <span class="n">allow_diff_shape</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                                 <span class="n">init_method</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Text</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;zeros&#39;</span><span class="p">,</span>
                                 <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                                 <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets a new node&#39;s tensor or creates one with :meth:`make_tensor` and sets</span>
<span class="sd">        it. Before setting it, it is casted to the correct type, so that a</span>
<span class="sd">        ``torch.Tensor`` can be turned into a ``nn.Parameter`` when setting it</span>
<span class="sd">        in :class:`ParamNodes &lt;ParamNode`. This can be used in any node, even in</span>
<span class="sd">        non-leaf nodes.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor : torch.Tensor, optional</span>
<span class="sd">            Tensor to be set in the node. If None, and `init_method` is provided,</span>
<span class="sd">            the tensor is created with :meth:`make_tensor`. Otherwise, a None is</span>
<span class="sd">            set as node&#39;s tensor.</span>
<span class="sd">        allow_diff_shape : bool, optional</span>
<span class="sd">            Boolean indicating whether different sizes are allowed for all axes</span>
<span class="sd">            (``True``), rather than just for batch axes (``Falsee``). If ``True``,</span>
<span class="sd">            any tensor could be set in the node, and the node&#39;s shape would change</span>
<span class="sd">            accordingly.</span>
<span class="sd">        init_method : {&quot;zeros&quot;, &quot;ones&quot;, &quot;copy&quot;, &quot;rand&quot;, &quot;randn&quot;}, optional</span>
<span class="sd">            Initialization method.</span>
<span class="sd">        device : torch.device, optional</span>
<span class="sd">            Device where to initialize the tensor.</span>
<span class="sd">        kwargs : float</span>
<span class="sd">            Keyword arguments for the different initialization methods. See</span>
<span class="sd">            :meth:`make_tensor`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">tensor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`tensor` should be torch.Tensor type&#39;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;`device` was specified but is being ignored. Provide &#39;</span>
                              <span class="s1">&#39;a tensor that is already in the required device&#39;</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compatible_shape</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
                <span class="n">tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_crop_tensor</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">allow_diff_shape</span><span class="p">)</span>
            <span class="n">correct_format_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_tensor_format</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">init_method</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">node_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">node_tensor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
                <span class="n">device</span> <span class="o">=</span> <span class="n">node_tensor</span><span class="o">.</span><span class="n">device</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_tensor</span><span class="p">(</span>
                <span class="n">init_method</span><span class="o">=</span><span class="n">init_method</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="n">correct_format_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_set_tensor_format</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">correct_format_tensor</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_save_in_network</span><span class="p">(</span><span class="n">correct_format_tensor</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span>

<div class="viewcode-block" id="AbstractNode.set_tensor"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractNode.set_tensor">[docs]</a>    <span class="k">def</span> <span class="nf">set_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                   <span class="n">tensor</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                   <span class="n">init_method</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Text</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;zeros&#39;</span><span class="p">,</span>
                   <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                   <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets a new node&#39;s tensor or creates one with :meth:`make_tensor` and sets</span>
<span class="sd">        it. Before setting it, it is casted to the correct type, so that a</span>
<span class="sd">        ``torch.Tensor`` can be turned into a ``nn.Parameter`` when setting it</span>
<span class="sd">        in :class:`ParamNodes &lt;ParamNode&gt;`.</span>
<span class="sd">        </span>
<span class="sd">        This way of setting tensors is only applicable to ``leaf`` nodes. For</span>
<span class="sd">        ``non-leaf`` nodes, their tensors come from the result of operations on</span>
<span class="sd">        ``leaf`` tensors; hence they should not be modified. For ``data`` nodes,</span>
<span class="sd">        tensors are set into nodes when calling the :meth:`TensorNetwork.forward`</span>
<span class="sd">        method of :class:`tensor networks &lt;TensorNetwork&gt;` with a data tensor or</span>
<span class="sd">        a sequence of tensors.</span>
<span class="sd">        </span>
<span class="sd">        Besides, this can only be used if the :class:`TensorNetwork` is not in</span>
<span class="sd">        :attr:`~TensorNetwork.automemory` mode.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        tensor : torch.Tensor, optional</span>
<span class="sd">            Tensor to be set in the node. If None, and `init_method` is provided,</span>
<span class="sd">            the tensor is created with :meth:`make_tensor`. Otherwise, a None is</span>
<span class="sd">            set as node&#39;s tensor.</span>
<span class="sd">        init_method : {&quot;zeros&quot;, &quot;ones&quot;, &quot;copy&quot;, &quot;rand&quot;, &quot;randn&quot;}, optional</span>
<span class="sd">            Initialization method.</span>
<span class="sd">        device : torch.device, optional</span>
<span class="sd">            Device where to initialize the tensor.</span>
<span class="sd">        kwargs : float</span>
<span class="sd">            Keyword arguments for the different initialization methods. See</span>
<span class="sd">            :meth:`make_tensor`.</span>

<span class="sd">        Raises</span>
<span class="sd">        ------</span>
<span class="sd">        ValueError</span>
<span class="sd">            If the node is not a ``leaf`` node or the tensor network is in</span>
<span class="sd">            ``automemory`` mode.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_leaf</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="o">.</span><span class="n">_automemory</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_unrestricted_set_tensor</span><span class="p">(</span>
                <span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">init_method</span><span class="o">=</span><span class="n">init_method</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">edge</span><span class="p">,</span> <span class="n">size</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_edges</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">):</span>
                <span class="n">edge</span><span class="o">.</span><span class="n">_size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Node</span><span class="se">\&#39;</span><span class="s1">s tensor can only be changed if it is a leaf&#39;</span>
                             <span class="s1">&#39; tensor and the network is not in automemory mode&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="AbstractNode.unset_tensor"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractNode.unset_tensor">[docs]</a>    <span class="k">def</span> <span class="nf">unset_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Replaces node&#39;s tensor with None.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_leaf</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="o">.</span><span class="n">_automemory</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_save_in_network</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_save_in_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Saves new node&#39;s tensor in the network&#39;s memory.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="o">.</span><span class="n">_memory_nodes</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;address&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="n">tensor</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span>
                <span class="s1">&#39;param_&#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;address&#39;</span><span class="p">],</span> <span class="n">tensor</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_record_in_inverse_memory</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Records information of the node in network&#39;s ``inverse memory``. This</span>
<span class="sd">        memory is a dictionary that, for each node used in an :class:`Operation`,</span>
<span class="sd">        keeps track of:</span>
<span class="sd">        </span>
<span class="sd">        * The total amount of times that the node&#39;s tensor is accessed to compute</span>
<span class="sd">          operations (calculated when contracting the network for the first time,</span>
<span class="sd">          in ``tracing`` mode).</span>
<span class="sd">          </span>
<span class="sd">        * The number of accesses to the node&#39;s tensor in the current contraction.</span>
<span class="sd">        </span>
<span class="sd">        * Whether this node&#39;s tensor can be erased after using it for all the</span>
<span class="sd">          operations in which it is involved.</span>
<span class="sd">        </span>
<span class="sd">        When contracting the :class:`TensorNetwork`, if the node&#39;s tensor has been</span>
<span class="sd">        accessed the total amount of times it has to be accessed, and it can be</span>
<span class="sd">        erased, then its tensor is indeed replaced by None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">net</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_network</span>
        <span class="n">address</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;address&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">address</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">node_ref</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;node_ref&#39;</span><span class="p">]</span>
            <span class="n">address</span> <span class="o">=</span> <span class="n">node_ref</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;address&#39;</span><span class="p">]</span>
            <span class="n">check_nodes</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_ref</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">check_nodes</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">]</span>
            
        <span class="c1"># When tracing network, node is recorded in inverse memory</span>
        <span class="k">if</span> <span class="n">net</span><span class="o">.</span><span class="n">_tracing</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">address</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">_inverse_memory</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">net</span><span class="o">.</span><span class="n">_inverse_memory</span><span class="p">[</span><span class="n">address</span><span class="p">][</span><span class="s1">&#39;erase&#39;</span><span class="p">]:</span>
                    <span class="n">net</span><span class="o">.</span><span class="n">_inverse_memory</span><span class="p">[</span><span class="n">address</span><span class="p">][</span><span class="s1">&#39;accessed&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Node can only be erased if both itself and the node from which</span>
                <span class="c1"># it is taking the tensor information (node_ref) are non-leaf or</span>
                <span class="c1"># data nodes (including virtual node that stores stack data tensor)</span>
                <span class="n">erase</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">check_nodes</span><span class="p">:</span>
                    <span class="n">erase</span> <span class="o">&amp;=</span> <span class="n">node</span><span class="o">.</span><span class="n">is_non_leaf</span><span class="p">()</span> <span class="ow">or</span> \
                        <span class="n">node</span><span class="o">.</span><span class="n">is_data</span><span class="p">()</span> <span class="ow">or</span> \
                        <span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">is_virtual</span><span class="p">()</span> <span class="ow">and</span>
                         <span class="n">node</span><span class="o">.</span><span class="n">_name</span> <span class="o">==</span> <span class="s1">&#39;stack_data_memory&#39;</span><span class="p">)</span>

                <span class="n">net</span><span class="o">.</span><span class="n">_inverse_memory</span><span class="p">[</span><span class="n">address</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s1">&#39;accessed&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
                    <span class="s1">&#39;re-accessed&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                    <span class="s1">&#39;erase&#39;</span><span class="p">:</span> <span class="n">erase</span><span class="p">}</span>
                
        <span class="c1"># When contracting network, we keep track of the number of accesses</span>
        <span class="c1"># to &quot;erasable&quot; nodes</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">address</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">_inverse_memory</span><span class="p">:</span>
                <span class="n">net</span><span class="o">.</span><span class="n">_inverse_memory</span><span class="p">[</span><span class="n">address</span><span class="p">][</span><span class="s1">&#39;re-accessed&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">aux_dict</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">_inverse_memory</span><span class="p">[</span><span class="n">address</span><span class="p">]</span>

                <span class="k">if</span> <span class="n">aux_dict</span><span class="p">[</span><span class="s1">&#39;accessed&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">aux_dict</span><span class="p">[</span><span class="s1">&#39;re-accessed&#39;</span><span class="p">]:</span>
                    <span class="k">if</span> <span class="n">aux_dict</span><span class="p">[</span><span class="s1">&#39;erase&#39;</span><span class="p">]:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="o">.</span><span class="n">_memory_nodes</span><span class="p">[</span><span class="n">address</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="n">net</span><span class="o">.</span><span class="n">_inverse_memory</span><span class="p">[</span><span class="n">address</span><span class="p">][</span><span class="s1">&#39;re-accessed&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

<div class="viewcode-block" id="AbstractNode.move_to_network"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractNode.move_to_network">[docs]</a>    <span class="k">def</span> <span class="nf">move_to_network</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                        <span class="n">network</span><span class="p">:</span> <span class="s1">&#39;TensorNetwork&#39;</span><span class="p">,</span>
                        <span class="n">visited</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="s1">&#39;AbstractNode&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Moves node to another network. All other nodes connected to it, or</span>
<span class="sd">        to a node connected to it, etc. are also moved to the new network.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        network : TensorNetwork</span>
<span class="sd">            Tensor Network to which the nodes will be moved.</span>
<span class="sd">        visited : list[AbstractNode], optional</span>
<span class="sd">            List indicating the nodes that have been already moved to the new</span>
<span class="sd">            network, used by this DFS-like algorithm.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">network</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">visited</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">visited</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">if</span> <span class="bp">self</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">visited</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_network</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="o">.</span><span class="n">_remove_node</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
                <span class="n">network</span><span class="o">.</span><span class="n">_add_node</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
                <span class="n">visited</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">neighbour</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">neighbours</span><span class="p">():</span>
                    <span class="n">neighbour</span><span class="o">.</span><span class="n">move_to_network</span><span class="p">(</span><span class="n">network</span><span class="o">=</span><span class="n">network</span><span class="p">,</span> <span class="n">visited</span><span class="o">=</span><span class="n">visited</span><span class="p">)</span></div>

    <span class="nd">@overload</span>
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">slice</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="s1">&#39;AbstractEdge&#39;</span><span class="p">]:</span>
        <span class="k">pass</span>

    <span class="nd">@overload</span>
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="n">Ax</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;AbstractEdge&#39;</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">slice</span><span class="p">,</span> <span class="n">Ax</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="s1">&#39;AbstractEdge&#39;</span><span class="p">],</span>
                                                          <span class="s1">&#39;AbstractEdge&#39;</span><span class="p">]:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">slice</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edges</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_edge</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

    <span class="c1"># -----------------</span>
    <span class="c1"># Tensor operations</span>
    <span class="c1"># -----------------</span>
<div class="viewcode-block" id="AbstractNode.sum"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractNode.sum">[docs]</a>    <span class="k">def</span> <span class="nf">sum</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Ax</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Ax</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the sum of all elements in the node&#39;s tensor. If an ``axis`` is</span>
<span class="sd">        specified, the sum is over that axis. If ``axis`` is a sequence of axes,</span>
<span class="sd">        reduce over all of them.</span>
<span class="sd">        </span>
<span class="sd">        This is not a node :class:`Operation`, hence it returns a ``torch.Tensor``</span>
<span class="sd">        instead of a :class:`Node`.</span>
<span class="sd">        </span>
<span class="sd">        See also `torch.sum() &lt;https://pytorch.org/docs/stable/generated/torch.sum.html&gt;`_.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        axis : int, str, Axis or list[int, str or Axis], optional</span>
<span class="sd">            Axis or sequence of axes over which to reduce.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">axis_num</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axis</span><span class="p">:</span>
                <span class="n">axis_num</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_axis_num</span><span class="p">(</span><span class="n">ax</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="n">axis_num</span><span class="p">)</span></div>

<div class="viewcode-block" id="AbstractNode.mean"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractNode.mean">[docs]</a>    <span class="k">def</span> <span class="nf">mean</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Ax</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Ax</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the mean of all elements in the node&#39;s tensor. If an ``axis`` is</span>
<span class="sd">        specified, the mean is over that axis. If ``axis`` is a sequence of axes,</span>
<span class="sd">        reduce over all of them.</span>
<span class="sd">        </span>
<span class="sd">        This is not a node :class:`Operation`, hence it returns a ``torch.Tensor``</span>
<span class="sd">        instead of a :class:`Node`.</span>
<span class="sd">        </span>
<span class="sd">        See also `torch.mean() &lt;https://pytorch.org/docs/stable/generated/torch.mean.html&gt;`_.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        axis : int, str, Axis or list[int, str or Axis], optional</span>
<span class="sd">            Axis or sequence of axes over which to reduce.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">axis_num</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axis</span><span class="p">:</span>
                <span class="n">axis_num</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_axis_num</span><span class="p">(</span><span class="n">ax</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="n">axis_num</span><span class="p">)</span></div>

<div class="viewcode-block" id="AbstractNode.std"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractNode.std">[docs]</a>    <span class="k">def</span> <span class="nf">std</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Ax</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Ax</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the std of all elements in the node&#39;s tensor. If an ``axis`` is</span>
<span class="sd">        specified, the std is over that axis. If ``axis`` is a sequence of axes,</span>
<span class="sd">        reduce over all of them.</span>
<span class="sd">        </span>
<span class="sd">        This is not a node :class:`Operation`, hence it returns a ``torch.Tensor``</span>
<span class="sd">        instead of a :class:`Node`.</span>
<span class="sd">        </span>
<span class="sd">        See also `torch.std() &lt;https://pytorch.org/docs/stable/generated/torch.std.html&gt;`_.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        axis : int, str, Axis or list[int, str or Axis], optional</span>
<span class="sd">            Axis or sequence of axes over which to reduce.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">axis_num</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axis</span><span class="p">:</span>
                <span class="n">axis_num</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_axis_num</span><span class="p">(</span><span class="n">ax</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="n">axis_num</span><span class="p">)</span></div>

<div class="viewcode-block" id="AbstractNode.norm"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractNode.norm">[docs]</a>    <span class="k">def</span> <span class="nf">norm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">Ax</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the norm of all elements in the node&#39;s tensor. If an ``axis`` is</span>
<span class="sd">        specified, the norm is over that axis. If ``axis`` is a sequence of axes,</span>
<span class="sd">        reduce over all of them.</span>
<span class="sd">        </span>
<span class="sd">        This is not a node :class:`Operation`, hence it returns a ``torch.Tensor``</span>
<span class="sd">        instead of a :class:`Node`.</span>
<span class="sd">        </span>
<span class="sd">        See also `torch.norm() &lt;https://pytorch.org/docs/stable/generated/torch.norm.html&gt;`_.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        p : int, float</span>
<span class="sd">            The order of the norm.</span>
<span class="sd">        axis : int, str, Axis or list[int, str or Axis], optional</span>
<span class="sd">            Axis or sequence of axes over which to reduce.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">axis_num</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axis</span><span class="p">:</span>
                <span class="n">axis_num</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_axis_num</span><span class="p">(</span><span class="n">ax</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">axis_num</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Text</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_name</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Text</span><span class="p">:</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1">(</span><span class="se">\n</span><span class="s1"> &#39;</span> \
               <span class="sa">f</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">name: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_name</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span> \
               <span class="sa">f</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">tensor:</span><span class="se">\n</span><span class="si">{</span><span class="n">tab_string</span><span class="p">(</span><span class="nb">repr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor</span><span class="p">),</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span> \
               <span class="sa">f</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">axes:</span><span class="se">\n</span><span class="si">{</span><span class="n">tab_string</span><span class="p">(</span><span class="n">print_list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">axes_names</span><span class="p">),</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span> \
               <span class="sa">f</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">edges:</span><span class="se">\n</span><span class="si">{</span><span class="n">tab_string</span><span class="p">(</span><span class="n">print_list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_edges</span><span class="p">),</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s1">)&#39;</span></div>


<div class="viewcode-block" id="Node"><a class="viewcode-back" href="../../usage.html#tensorkrowch.Node">[docs]</a><span class="k">class</span> <span class="nc">Node</span><span class="p">(</span><span class="n">AbstractNode</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base class for non-trainable nodes. Should be subclassed by any class of nodes</span>
<span class="sd">    that are not intended to be trained (e.g. :class:`StackNode`).</span>
<span class="sd">    </span>
<span class="sd">    Can be used for fixed nodes of the :class:`TensorNetwork`, or intermediate</span>
<span class="sd">    nodes that are resultant from an :class:`Operation` between nodes.</span>
<span class="sd">    </span>
<span class="sd">    For a complete list of properties and methods, see also :class:`AbstractNode`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    shape : list[int], tuple[int], torch.Size, optional</span>
<span class="sd">        Node&#39;s shape, that is, the shape of its tensor. If ``shape`` and</span>
<span class="sd">        ``init_method`` are provided, a tensor will be made for the node. Otherwise,</span>
<span class="sd">        ``tensor`` would be required.</span>
<span class="sd">    axes_names : list[str], tuple[str], optional</span>
<span class="sd">        Sequence of names for each of the node&#39;s axes. Names are used to access</span>
<span class="sd">        the edge that is attached to the node in a certain axis. Hence they should</span>
<span class="sd">        be all distinct.</span>
<span class="sd">    name : str, optional</span>
<span class="sd">        Node&#39;s name, used to access the node from de :class:`TensorNetwork` where</span>
<span class="sd">        it belongs. It cannot contain blank spaces.</span>
<span class="sd">    network : TensorNetwork, optional</span>
<span class="sd">        Tensor network where the node should belong. If None, a new tensor network,</span>
<span class="sd">        will be created to contain the node.</span>
<span class="sd">    leaf : bool, optional</span>
<span class="sd">        Boolean indicating if the node is a ``leaf`` node. If a node is neither</span>
<span class="sd">        ``leaf`` nor ``data`` nor ``virtual``, it is ``non-leaf``.</span>
<span class="sd">    data : bool, optional</span>
<span class="sd">        Boolean indicating if the node is a ``data`` node.</span>
<span class="sd">    virtual : bool, optional</span>
<span class="sd">        Boolean indicating if the node is a ``virtual`` node.</span>
<span class="sd">    override_node : bool, optional</span>
<span class="sd">        Boolean indicating whether the node should override (``True``) another</span>
<span class="sd">        node in the network that has the same name (e.g. if a node is parameterized,</span>
<span class="sd">        it would be required that a new :class:`ParamNode` replaces the non-parameterized</span>
<span class="sd">        node in the network).</span>
<span class="sd">    param_edges : bool, optional</span>
<span class="sd">        Boolean indicating whether all node&#39;s edges should be :class:`ParamEdges</span>
<span class="sd">        &lt;ParamEdge&gt;` (``True``) or not (``False``).</span>
<span class="sd">    tensor : torch.Tensor, optional</span>
<span class="sd">        Tensor that is to be stored in the node. If None, ``shape`` and ``init_method``</span>
<span class="sd">        will be required.</span>
<span class="sd">    edges : list[AbstractEdge], optional</span>
<span class="sd">        List of edges that are to be attached to the node. This can be used in</span>
<span class="sd">        case the node inherits the edges from other node(s), like in :class:`Operations</span>
<span class="sd">        &lt;Operation&gt;`.</span>
<span class="sd">    override_edges : bool, optional</span>
<span class="sd">        Boolean indicating whether the provided ``edges`` should be overriden</span>
<span class="sd">        (``True``) when reattached (e.g. if a node is parameterized, it would</span>
<span class="sd">        be required that the new :class:`ParamNode`&#39;s edges are indeed connected</span>
<span class="sd">        to it, instead of to the original non-parameterized node).</span>
<span class="sd">    node1_list : list[bool], optional</span>
<span class="sd">        If ``edges`` are provided, the list of ``node1`` attributes of each edge</span>
<span class="sd">        should also be provided.</span>
<span class="sd">    init_method : {&quot;zeros&quot;, &quot;ones&quot;, &quot;copy&quot;, &quot;rand&quot;, &quot;randn&quot;}, optional</span>
<span class="sd">        Initialization method.</span>
<span class="sd">    device : torch.device, optional</span>
<span class="sd">        Device where to initialize the tensor.</span>
<span class="sd">    kwargs : float</span>
<span class="sd">        Keyword arguments for the different initialization methods. See</span>
<span class="sd">        :meth:`AbstractNode.make_tensor`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">shape</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Shape</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">axes_names</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">Text</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Text</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">network</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s1">&#39;TensorNetwork&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">leaf</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                 <span class="n">data</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                 <span class="n">virtual</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                 <span class="n">override_node</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                 <span class="n">param_edges</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                 <span class="n">tensor</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">edges</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="s1">&#39;AbstractEdge&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">override_edges</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                 <span class="n">node1_list</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">bool</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">init_method</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Text</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

        <span class="c1"># shape and tensor</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">shape</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">tensor</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">shape</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;One of `shape` or `tensor` must be provided&#39;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">shape</span><span class="p">:</span>
                <span class="n">shape</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;If both `shape` or `tensor` are given, &#39;</span>
                                 <span class="s1">&#39;`tensor`</span><span class="se">\&#39;</span><span class="s1">s shape should be equal to `shape`&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>
                             <span class="n">axes_names</span><span class="o">=</span><span class="n">axes_names</span><span class="p">,</span>
                             <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
                             <span class="n">network</span><span class="o">=</span><span class="n">network</span><span class="p">,</span>
                             <span class="n">leaf</span><span class="o">=</span><span class="n">leaf</span><span class="p">,</span>
                             <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
                             <span class="n">virtual</span><span class="o">=</span><span class="n">virtual</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                             <span class="n">axes_names</span><span class="o">=</span><span class="n">axes_names</span><span class="p">,</span>
                             <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
                             <span class="n">network</span><span class="o">=</span><span class="n">network</span><span class="p">,</span>
                             <span class="n">leaf</span><span class="o">=</span><span class="n">leaf</span><span class="p">,</span>
                             <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
                             <span class="n">virtual</span><span class="o">=</span><span class="n">virtual</span><span class="p">)</span>

        <span class="c1"># edges</span>
        <span class="k">if</span> <span class="n">edges</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_edges</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_make_edge</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">param_edges</span><span class="p">)</span> <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_axes</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">node1_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s1">&#39;If `edges` are provided, `node1_list` should also be provided&#39;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">axis</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_axes</span><span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">node1_list</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="nb">bool</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`node1_list` should be list[bool] type&#39;</span><span class="p">)</span>
                <span class="n">axis</span><span class="o">.</span><span class="n">_node1</span> <span class="o">=</span> <span class="n">node1_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_edges</span> <span class="o">=</span> <span class="n">edges</span><span class="p">[:]</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_leaf</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="o">.</span><span class="n">_automemory</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_reattach_edges</span><span class="p">(</span><span class="n">override</span><span class="o">=</span><span class="n">override_edges</span><span class="p">)</span>

        <span class="c1"># network</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="o">.</span><span class="n">_add_node</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">override</span><span class="o">=</span><span class="n">override_node</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">init_method</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_unrestricted_set_tensor</span><span class="p">(</span>
                    <span class="n">init_method</span><span class="o">=</span><span class="n">init_method</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_unrestricted_set_tensor</span><span class="p">(</span><span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">)</span>

    <span class="c1"># -------</span>
    <span class="c1"># Methods</span>
    <span class="c1"># -------</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_set_tensor_format</span><span class="p">(</span><span class="n">tensor</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a torch.Tensor if input tensor is given as nn.Parameter.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">tensor</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">tensor</span>
    
    <span class="k">def</span> <span class="nf">_make_edge</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="n">Axis</span><span class="p">,</span> <span class="n">param_edges</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="s1">&#39;Edge&#39;</span><span class="p">,</span> <span class="s1">&#39;ParamEdge&#39;</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Makes Edges or ParamEdges depending on the ``param_edges`` attribute&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">param_edges</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">ParamEdge</span><span class="p">(</span><span class="n">node1</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis1</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Edge</span><span class="p">(</span><span class="n">node1</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis1</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>

<div class="viewcode-block" id="Node.parameterize"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.Node.parameterize">[docs]</a>    <span class="k">def</span> <span class="nf">parameterize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">set_param</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="s1">&#39;Node&#39;</span><span class="p">,</span> <span class="s1">&#39;ParamNode&#39;</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Replaces the node with a parameterized version of it, that is, turns a</span>
<span class="sd">        fixed :class:`Node` into a trainable :class:`ParamNode`.</span>
<span class="sd">        </span>
<span class="sd">        Since the node is `replaced`, it will be completely removed from the network,</span>
<span class="sd">        and its neighbours will point to the new parameterized node.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        set_param : bool</span>
<span class="sd">            Boolean indicating whether the node should be parameterized (``True``).</span>
<span class="sd">            Otherwise (``False``), the non-parameterized node itself will be</span>
<span class="sd">            returned.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Node or ParamNode</span>
<span class="sd">            The original node or a parameterized version of it.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">set_param</span><span class="p">:</span>
            <span class="n">new_node</span> <span class="o">=</span> <span class="n">ParamNode</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                                 <span class="n">axes_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">axes_names</span><span class="p">,</span>
                                 <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_name</span><span class="p">,</span>
                                 <span class="n">network</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="p">,</span>
                                 <span class="n">override_node</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                 <span class="n">param_edges</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">param_edges</span><span class="p">(),</span>
                                 <span class="n">tensor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span>
                                 <span class="n">edges</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_edges</span><span class="p">,</span>
                                 <span class="n">override_edges</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                 <span class="n">node1_list</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">is_node1</span><span class="p">())</span>
            <span class="k">return</span> <span class="n">new_node</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="Node.copy"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.Node.copy">[docs]</a>    <span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;Node&#39;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a copy of the node. That is, returns a node whose tensor is a copy</span>
<span class="sd">        of the original, whose edges are directly inherited (these are not copies,</span>
<span class="sd">        but the exact same edges) and whose name is extended with the prefix ``&quot;copy_&quot;``.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Node</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new_node</span> <span class="o">=</span> <span class="n">Node</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">,</span>
                        <span class="n">axes_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">axes_names</span><span class="p">,</span>
                        <span class="n">name</span><span class="o">=</span><span class="s1">&#39;copy_&#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_name</span><span class="p">,</span>
                        <span class="n">network</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="p">,</span>
                        <span class="n">param_edges</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">param_edges</span><span class="p">(),</span>
                        <span class="n">tensor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span>
                        <span class="n">edges</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_edges</span><span class="p">,</span>
                        <span class="n">node1_list</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">is_node1</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">new_node</span></div></div>


<div class="viewcode-block" id="ParamNode"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.ParamNode">[docs]</a><span class="k">class</span> <span class="nc">ParamNode</span><span class="p">(</span><span class="n">Node</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class for trainable nodes. Should be subclassed by any class of nodes that</span>
<span class="sd">    are intended to be trained (e.g. :class:`ParamStackNode`).</span>
<span class="sd">    </span>
<span class="sd">    Should be used as the initial nodes conforming the :class:`TensorNetwork`,</span>
<span class="sd">    if it is going to be trained. When operating these initial nodes, the resultant</span>
<span class="sd">    nodes will be non-parameterized (e.g. :class:`Node`, :class:`StackNode`).</span>
<span class="sd">    </span>
<span class="sd">    The main difference with :class:`Nodes &lt;Node&gt;` is that ``ParamNodes`` have</span>
<span class="sd">    ``nn.Parameter`` tensors instead of ``torch.Tensor``. Therefore, a ``ParamNode``</span>
<span class="sd">    is a sort of `parameter` that is attached to the :class:`TensorNetwork` (which</span>
<span class="sd">    is itself a ``nn.Module``). That is, the list of parameters of the tensor</span>
<span class="sd">    network module contains the tensors of all ``ParamNodes``. </span>
<span class="sd">    </span>
<span class="sd">    To see how to initialize `` ParamNodes``, see :class:`Node`.</span>
<span class="sd">    </span>
<span class="sd">    For a complete list of properties and methods, see also :class:`AbstractNode`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">shape</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Shape</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">axes_names</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">Text</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Text</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">network</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s1">&#39;TensorNetwork&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">leaf</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                 <span class="n">data</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                 <span class="n">virtual</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                 <span class="n">override_node</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                 <span class="n">param_edges</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                 <span class="n">tensor</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">edges</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="s1">&#39;AbstractEdge&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">override_edges</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                 <span class="n">node1_list</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">bool</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">init_method</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Text</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

        <span class="c1"># data</span>
        <span class="k">if</span> <span class="n">data</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;ParamNode cannot be a data node&#39;</span><span class="p">)</span>

        <span class="c1"># leaf</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">leaf</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s1">&#39;ParamNode is always a leaf node. Cannot set leaf to False&#39;</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>
                         <span class="n">axes_names</span><span class="o">=</span><span class="n">axes_names</span><span class="p">,</span>
                         <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
                         <span class="n">network</span><span class="o">=</span><span class="n">network</span><span class="p">,</span>
                         <span class="n">leaf</span><span class="o">=</span><span class="n">leaf</span><span class="p">,</span>
                         <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
                         <span class="n">virtual</span><span class="o">=</span><span class="n">virtual</span><span class="p">,</span>
                         <span class="n">override_node</span><span class="o">=</span><span class="n">override_node</span><span class="p">,</span>
                         <span class="n">param_edges</span><span class="o">=</span><span class="n">param_edges</span><span class="p">,</span>
                         <span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span>
                         <span class="n">edges</span><span class="o">=</span><span class="n">edges</span><span class="p">,</span>
                         <span class="n">override_edges</span><span class="o">=</span><span class="n">override_edges</span><span class="p">,</span>
                         <span class="n">node1_list</span><span class="o">=</span><span class="n">node1_list</span><span class="p">,</span>
                         <span class="n">init_method</span><span class="o">=</span><span class="n">init_method</span><span class="p">,</span>
                         <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
                         <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="c1"># ----------</span>
    <span class="c1"># Properties</span>
    <span class="c1"># ----------</span>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">grad</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns gradient of the param-node&#39;s tensor.</span>
<span class="sd">        </span>
<span class="sd">        See also `torch.Tensor.grad()</span>
<span class="sd">        &lt;https://pytorch.org/docs/stable/generated/torch.Tensor.grad.html&gt;`_</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor or None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;address&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">aux_node</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;node_ref&#39;</span><span class="p">]</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="n">aux_node</span><span class="o">.</span><span class="n">_network</span><span class="o">.</span><span class="n">_memory_nodes</span><span class="p">[</span><span class="n">aux_node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;address&#39;</span><span class="p">]]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="o">.</span><span class="n">_memory_nodes</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;address&#39;</span><span class="p">]]</span>

        <span class="k">if</span> <span class="n">tensor</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="n">aux_grad</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">grad</span>
        <span class="k">if</span> <span class="n">aux_grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">aux_grad</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;full&#39;</span><span class="p">]:</span>
                <span class="k">return</span> <span class="n">aux_grad</span>
            <span class="k">return</span> <span class="n">aux_grad</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;index&#39;</span><span class="p">]]</span>

    <span class="c1"># -------</span>
    <span class="c1"># Methods</span>
    <span class="c1"># -------</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_set_tensor_format</span><span class="p">(</span><span class="n">tensor</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Parameter</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a nn.Parameter if input tensor is just torch.Tensor.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">tensor</span>
        <span class="k">return</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>

<div class="viewcode-block" id="ParamNode.parameterize"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.ParamNode.parameterize">[docs]</a>    <span class="k">def</span> <span class="nf">parameterize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">set_param</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="s1">&#39;Node&#39;</span><span class="p">,</span> <span class="s1">&#39;ParamNode&#39;</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Replaces the param-node with a de-parameterized version of it, that is,</span>
<span class="sd">        turns a :class:`ParamNode` into a non-trainable, fixed :class:`Node`.</span>
<span class="sd">        </span>
<span class="sd">        Since the param-node is `replaced`, it will be completely removed from</span>
<span class="sd">        the network, and its neighbours will point to the new node.</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        set_param : bool</span>
<span class="sd">            Boolean indicating whether the node should stay parameterized</span>
<span class="sd">            (``True``), thus returning the param-node itself. Otherwise (``False``),</span>
<span class="sd">            the param-node will be de-parameterized.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ParamNode or Node</span>
<span class="sd">            The original node or a de-parameterized version of it.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">set_param</span><span class="p">:</span>
            <span class="n">new_node</span> <span class="o">=</span> <span class="n">Node</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                            <span class="n">axes_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">axes_names</span><span class="p">,</span>
                            <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_name</span><span class="p">,</span>
                            <span class="n">network</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="p">,</span>
                            <span class="n">override_node</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="n">param_edges</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">param_edges</span><span class="p">(),</span>
                            <span class="n">tensor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span>
                            <span class="n">edges</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_edges</span><span class="p">,</span>
                            <span class="n">override_edges</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                            <span class="n">node1_list</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">is_node1</span><span class="p">())</span>
            <span class="k">return</span> <span class="n">new_node</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="ParamNode.copy"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.ParamNode.copy">[docs]</a>    <span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;ParamNode&#39;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a copy of the param-node. That is, returns a param-node whose</span>
<span class="sd">        tensor is a copy of the original, whose edges are directly inherited</span>
<span class="sd">        (these are not copies, but the exact same edges) and whose name is</span>
<span class="sd">        extended with the prefix ``&quot;copy_&quot;``.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        ParamNode</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new_node</span> <span class="o">=</span> <span class="n">ParamNode</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                             <span class="n">axes_names</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">axes_names</span><span class="p">,</span>
                             <span class="n">name</span><span class="o">=</span><span class="s1">&#39;copy_&#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_name</span><span class="p">,</span>
                             <span class="n">network</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_network</span><span class="p">,</span>
                             <span class="n">param_edges</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">param_edges</span><span class="p">(),</span>
                             <span class="n">tensor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span>
                             <span class="n">edges</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_edges</span><span class="p">,</span>
                             <span class="n">node1_list</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">is_node1</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">new_node</span></div></div>


<span class="c1">################################################</span>
<span class="c1">#                   EDGES                      #</span>
<span class="c1">################################################</span>

<div class="viewcode-block" id="AbstractEdge"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractEdge">[docs]</a><span class="k">class</span> <span class="nc">AbstractEdge</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstract class for all types of edges. Defines what an edge is and some of its</span>
<span class="sd">    properties and methods. Since it is an abstract class, cannot be instantiated.</span>

<span class="sd">    An edge is nothing more than an object that wraps references to the nodes it</span>
<span class="sd">    connects. Thus it stores information like the nodes it connects, the corresponding</span>
<span class="sd">    nodes&#39; axes it is attached to, whether it is dangling or batch, its size and</span>
<span class="sd">    dim, etc.</span>
<span class="sd">    </span>
<span class="sd">    Above all, its importance lies in that edges enable to connect nodes, forming</span>
<span class="sd">    any possible graph, and perform easily :class:`Operations &lt;Operation&gt;` like</span>
<span class="sd">    contracting and splitting nodes.</span>
<span class="sd">    </span>
<span class="sd">    Furthermore, edges have specific operations like :meth:`contract_` or :meth:`svd_`</span>
<span class="sd">    (and its variations) that allow inplace modification of the :class:`TensorNetwork`.</span>
<span class="sd">    </span>
<span class="sd">    Refer to the subclasses of ``AbstractEdge`` to see how to instantiate edges:</span>
<span class="sd">    </span>
<span class="sd">    * :class:`Edge`</span>
<span class="sd">    </span>
<span class="sd">    * :class:`ParamEdge`</span>
<span class="sd">    </span>
<span class="sd">    * :class:`StackEdge`</span>
<span class="sd">    </span>
<span class="sd">    * :class:`ParamStackEdge`</span>
<span class="sd">    </span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    node1: first node to which the edge is connected</span>
<span class="sd">    axis1: axis of `node1` where the edge is attached</span>
<span class="sd">    node2: second, optional, node to which the edge is connected</span>
<span class="sd">    axis2: axis of `node2` where the edge is attached</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">    TypeError</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">node1</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span>
                 <span class="n">axis1</span><span class="p">:</span> <span class="n">Ax</span><span class="p">,</span>
                 <span class="n">node2</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">AbstractNode</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">axis2</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Ax</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># check node1 and axis1</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">node1</span><span class="p">,</span> <span class="n">AbstractNode</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`node1` should be AbstractNode type&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis1</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="n">Axis</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`axis1` should be int, str or Axis type&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis1</span><span class="p">,</span> <span class="n">Axis</span><span class="p">):</span>
            <span class="n">axis1</span> <span class="o">=</span> <span class="n">node1</span><span class="o">.</span><span class="n">get_axis</span><span class="p">(</span><span class="n">axis1</span><span class="p">)</span>

        <span class="c1"># check node2 and axis2</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">node2</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="o">!=</span> <span class="p">(</span><span class="n">axis2</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s1">&#39;`node2` and `axis2` must both be None or both not be None&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">node2</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">node2</span><span class="p">,</span> <span class="n">AbstractNode</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`node2` should be AbstractNode type&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis2</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="n">Axis</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`axis2` should be int, str or Axis type&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis2</span><span class="p">,</span> <span class="n">Axis</span><span class="p">):</span>
                <span class="n">axis2</span> <span class="o">=</span> <span class="n">node2</span><span class="o">.</span><span class="n">get_axis</span><span class="p">(</span><span class="n">axis2</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">node1</span><span class="o">.</span><span class="n">_shape</span><span class="p">[</span><span class="n">axis1</span><span class="o">.</span><span class="n">_num</span><span class="p">]</span> <span class="o">!=</span> <span class="n">node2</span><span class="o">.</span><span class="n">_shape</span><span class="p">[</span><span class="n">axis2</span><span class="o">.</span><span class="n">_num</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Sizes of `axis1` and `axis2` should match&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">node2</span> <span class="o">==</span> <span class="n">node1</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">axis2</span> <span class="o">==</span> <span class="n">axis1</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s1">&#39;Cannot connect the same axis of the same node to itself&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_nodes</span> <span class="o">=</span> <span class="p">[</span><span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_axes</span> <span class="o">=</span> <span class="p">[</span><span class="n">axis1</span><span class="p">,</span> <span class="n">axis2</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_size</span> <span class="o">=</span> <span class="n">node1</span><span class="o">.</span><span class="n">_shape</span><span class="p">[</span><span class="n">axis1</span><span class="o">.</span><span class="n">_num</span><span class="p">]</span>

    <span class="c1"># ----------</span>
    <span class="c1"># Properties</span>
    <span class="c1"># ----------</span>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">node1</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AbstractNode</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns `node1` of the edge.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">node2</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AbstractNode</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns `node2` of the edge. If the edge is dangling, it is None.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nodes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">AbstractNode</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a list with `node1` and `node2`.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nodes</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">axis1</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Axis</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns axis where the edge is attached to `node1`.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">axis2</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Axis</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns axis where the edge is attached to `node2`. If the edge is dangling,</span>
<span class="sd">        it is None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">axes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Axis</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a list of axes where the edge is attached to `node1` and `node2`,</span>
<span class="sd">        respectively.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nodes</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">name</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Text</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns edge&#39;s name. It is formed with the corresponding nodes&#39; and axes&#39;</span>
<span class="sd">        names.</span>
<span class="sd">        </span>
<span class="sd">        Example</span>
<span class="sd">        -------</span>
<span class="sd">        &gt;&gt;&gt; nodeA = tk.Node(shape=(2, 3), name=&#39;nodeA&#39;, axes_names=[&#39;left&#39;, &#39;right&#39;])</span>
<span class="sd">        &gt;&gt;&gt; edge = nodeA[&#39;right&#39;]</span>
<span class="sd">        &gt;&gt;&gt; print(edge.name)</span>
<span class="sd">        nodeA[right] &lt;-&gt; None</span>
<span class="sd">        </span>
<span class="sd">        &gt;&gt;&gt; nodeB = tk.Node(shape=(3, 4), name=&#39;nodeB&#39;, axes_names=[&#39;left&#39;, &#39;right&#39;])</span>
<span class="sd">        &gt;&gt;&gt; new_edge = nodeA[&#39;right&#39;] ^ nodeB[&#39;left&#39;]</span>
<span class="sd">        &gt;&gt;&gt; print(new_edge.name)</span>
<span class="sd">        nodeA[right] &lt;-&gt; nodeB[left]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_dangling</span><span class="p">():</span>
            <span class="k">return</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">node1</span><span class="o">.</span><span class="n">_name</span><span class="si">}</span><span class="s1">[</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">axis1</span><span class="o">.</span><span class="n">_name</span><span class="si">}</span><span class="s1">] &lt;-&gt; None&#39;</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">node1</span><span class="o">.</span><span class="n">_name</span><span class="si">}</span><span class="s1">[</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">axis1</span><span class="o">.</span><span class="n">_name</span><span class="si">}</span><span class="s1">] &lt;-&gt; &#39;</span> \
               <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">node2</span><span class="o">.</span><span class="n">_name</span><span class="si">}</span><span class="s1">[</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">axis2</span><span class="o">.</span><span class="n">_name</span><span class="si">}</span><span class="s1">]&#39;</span>

    <span class="c1"># ----------------</span>
    <span class="c1"># Abstract methods</span>
    <span class="c1"># ----------------</span>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">pass</span>

<div class="viewcode-block" id="AbstractEdge.change_size"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractEdge.change_size">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">change_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Change size of edge, thus changing sizes of adjacent nodes (node1 and node2)</span>
<span class="sd">        at axis1 and axis2, respectively</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span></div>

<div class="viewcode-block" id="AbstractEdge.parameterize"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractEdge.parameterize">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">parameterize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                     <span class="n">set_param</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
                     <span class="n">size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;AbstractEdge&#39;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Substitute current edge by a (de-)parameterized version of it</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span></div>

<div class="viewcode-block" id="AbstractEdge.copy"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractEdge.copy">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;AbstractEdge&#39;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a new edge referencing the same nodes at the same axis</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span></div>

<div class="viewcode-block" id="AbstractEdge.connect"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractEdge.connect">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">connect</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="s1">&#39;AbstractEdge&#39;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;AbstractEdge&#39;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Connect two edges</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span></div>

<div class="viewcode-block" id="AbstractEdge.disconnect"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractEdge.disconnect">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">disconnect</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="s1">&#39;AbstractEdge&#39;</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Disconnect one edge (from itself)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span></div>

    <span class="c1"># -------</span>
    <span class="c1"># Methods</span>
    <span class="c1"># -------</span>
<div class="viewcode-block" id="AbstractEdge.is_dangling"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractEdge.is_dangling">[docs]</a>    <span class="k">def</span> <span class="nf">is_dangling</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns boolean indicating whether the edge is a dangling edge.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">node2</span> <span class="ow">is</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="AbstractEdge.is_batch"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractEdge.is_batch">[docs]</a>    <span class="k">def</span> <span class="nf">is_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns boolean indicating whether the edge is a batch edge.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">axis1</span><span class="o">.</span><span class="n">is_batch</span><span class="p">()</span></div>

<div class="viewcode-block" id="AbstractEdge.is_attached_to"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractEdge.is_attached_to">[docs]</a>    <span class="k">def</span> <span class="nf">is_attached_to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns boolean indicating whether the edge is attached to ``node``.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">node1</span> <span class="o">==</span> <span class="n">node</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">node2</span> <span class="o">==</span> <span class="n">node</span><span class="p">)</span></div>

<div class="viewcode-block" id="AbstractEdge.size"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.AbstractEdge.size">[docs]</a>    <span class="k">def</span> <span class="nf">size</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns edge&#39;s size.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_size</span></div>

    <span class="k">def</span> <span class="fm">__xor__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="s1">&#39;AbstractEdge&#39;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;AbstractEdge&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">connect</span><span class="p">(</span><span class="n">other</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__or__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="s1">&#39;AbstractEdge&#39;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="s1">&#39;AbstractEdge&#39;</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">other</span> <span class="o">==</span> <span class="bp">self</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">disconnect</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Cannot disconnect one edge from another, different one. &#39;</span>
                             <span class="s1">&#39;Edge should be disconnected from itself&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Text</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Text</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_batch</span><span class="p">():</span>
            <span class="k">return</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1">( </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1"> )  (Batch Edge)&#39;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_dangling</span><span class="p">():</span>
            <span class="k">return</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1">( </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1"> )  (Dangling Edge)&#39;</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1">( </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1"> )&#39;</span></div>


<div class="viewcode-block" id="Edge"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.Edge">[docs]</a><span class="k">class</span> <span class="nc">Edge</span><span class="p">(</span><span class="n">AbstractEdge</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base class for non-trainable edges. Should be subclassed</span>
<span class="sd">    by any new class of non-trainable edges.</span>

<span class="sd">    Used by default to create a non-trainable node.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># -------</span>
    <span class="c1"># Methods</span>
    <span class="c1"># -------</span>
    <span class="k">def</span> <span class="nf">dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>

<div class="viewcode-block" id="Edge.change_size"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.Edge.change_size">[docs]</a>    <span class="k">def</span> <span class="nf">change_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`size` should be int type&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_dangling</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">node2</span><span class="o">.</span><span class="n">_change_axis_size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">axis2</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">node1</span><span class="o">.</span><span class="n">_change_axis_size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">axis1</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span></div>

<div class="viewcode-block" id="Edge.parameterize"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.Edge.parameterize">[docs]</a>    <span class="k">def</span> <span class="nf">parameterize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                     <span class="n">set_param</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                     <span class="n">size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="s1">&#39;Edge&#39;</span><span class="p">,</span> <span class="s1">&#39;ParamEdge&#39;</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns ``param_edges`` attribute or changes it if ``set_param`` is provided.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Returns True if all edges are parametric edges, False if all edges are</span>
<span class="sd">        non-parametric edges, and None if there are some edges of each type</span>
<span class="sd">        </span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        set_param : bool, optional</span>
<span class="sd">            Boolean indicating whether edges have to be parameterized (``True``)</span>
<span class="sd">            or de-parameterized (``False``).</span>
<span class="sd">        sizes : list[int] or tuple[int], optional</span>
<span class="sd">            Sizes used to expand or shrink the node&#39;s shape if desired. By default,</span>
<span class="sd">            if an :class:`Edge` is parameterized, its corresponding ``size`` will</span>
<span class="sd">            match its ``dim``. However, if ``sizes`` are provided, </span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        _type_</span>
<span class="sd">            _description_</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">set_param</span><span class="p">:</span>
            <span class="n">dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">change_size</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>
            <span class="n">new_edge</span> <span class="o">=</span> <span class="n">ParamEdge</span><span class="p">(</span><span class="n">node1</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">node1</span><span class="p">,</span> <span class="n">axis1</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">axis1</span><span class="p">,</span>
                                 <span class="n">dim</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">()),</span>
                                 <span class="n">node2</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">node2</span><span class="p">,</span> <span class="n">axis2</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">axis2</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_dangling</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">node2</span><span class="o">.</span><span class="n">_add_edge</span><span class="p">(</span><span class="n">new_edge</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">axis2</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">node1</span><span class="o">.</span><span class="n">_add_edge</span><span class="p">(</span><span class="n">new_edge</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">axis1</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">node1</span><span class="o">.</span><span class="n">_network</span><span class="o">.</span><span class="n">_remove_edge</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">node1</span><span class="o">.</span><span class="n">_network</span><span class="o">.</span><span class="n">_add_edge</span><span class="p">(</span><span class="n">new_edge</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">new_edge</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="Edge.copy"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.Edge.copy">[docs]</a>    <span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;Edge&#39;</span><span class="p">:</span>
        <span class="c1"># TODO: cuando copiams edge tenemos que aadirlo a la TN?</span>
        <span class="n">new_edge</span> <span class="o">=</span> <span class="n">Edge</span><span class="p">(</span><span class="n">node1</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">node1</span><span class="p">,</span> <span class="n">axis1</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">axis1</span><span class="p">,</span>
                        <span class="n">node2</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">node2</span><span class="p">,</span> <span class="n">axis2</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">axis2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_edge</span></div>

    <span class="nd">@overload</span>
    <span class="k">def</span> <span class="nf">connect</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="s1">&#39;Edge&#39;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;Edge&#39;</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="nd">@overload</span>
    <span class="k">def</span> <span class="nf">connect</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="s1">&#39;ParamEdge&#39;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;ParamEdge&#39;</span><span class="p">:</span>
        <span class="k">pass</span>

<div class="viewcode-block" id="Edge.connect"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.Edge.connect">[docs]</a>    <span class="k">def</span> <span class="nf">connect</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s1">&#39;Edge&#39;</span><span class="p">,</span> <span class="s1">&#39;ParamEdge&#39;</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="s1">&#39;Edge&#39;</span><span class="p">,</span> <span class="s1">&#39;ParamEdge&#39;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">connect</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">)</span></div>

<div class="viewcode-block" id="Edge.disconnect"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.Edge.disconnect">[docs]</a>    <span class="k">def</span> <span class="nf">disconnect</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="s1">&#39;Edge&#39;</span><span class="p">,</span> <span class="s1">&#39;Edge&#39;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">disconnect</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></div></div>


<span class="n">EdgeParameter</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">]</span>
<span class="n">_DEFAULT_SHIFT</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span>
<span class="n">_DEFAULT_SLOPE</span> <span class="o">=</span> <span class="mf">1.</span>


<div class="viewcode-block" id="ParamEdge"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.ParamEdge">[docs]</a><span class="k">class</span> <span class="nc">ParamEdge</span><span class="p">(</span><span class="n">AbstractEdge</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class for trainable edges. Subclass of PyTorch nn.Module.</span>
<span class="sd">    Should be subclassed by any new class of trainable edges.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">node1</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span>
                 <span class="n">axis1</span><span class="p">:</span> <span class="n">Axis</span><span class="p">,</span>
                 <span class="n">dim</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">shift</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">EdgeParameter</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">slope</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">EdgeParameter</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">node2</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">AbstractNode</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">axis2</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Axis</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

        <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">AbstractEdge</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node1</span><span class="p">,</span> <span class="n">axis1</span><span class="p">,</span> <span class="n">node2</span><span class="p">,</span> <span class="n">axis2</span><span class="p">)</span>

        <span class="n">axis1</span><span class="p">,</span> <span class="n">axis2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_axes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">_axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># check batch</span>
        <span class="k">if</span> <span class="n">axis1</span><span class="o">.</span><span class="n">_batch</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;`axis1` is for a batch index. Batch edges should &#39;</span>
                          <span class="s1">&#39;not be parameterized. De-parameterize it before&#39;</span>
                          <span class="s1">&#39; usage&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">axis2</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">axis2</span><span class="o">.</span><span class="n">_batch</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;`axis2` is for a batch index. Batch edges should &#39;</span>
                              <span class="s1">&#39;not be parameterized. De-parameterize it before&#39;</span>
                              <span class="s1">&#39; usage&#39;</span><span class="p">)</span>

        <span class="c1"># shift and slope</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">shift</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">slope</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">):</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;`shift` and/or `slope` might have been ignored &#39;</span>
                              <span class="s1">&#39;when initializing the edge, since dim was provided&#39;</span><span class="p">)</span>
            <span class="n">shift</span><span class="p">,</span> <span class="n">slope</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_parameters</span><span class="p">(</span><span class="n">node1</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">axis1</span><span class="p">),</span> <span class="n">dim</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">shift</span><span class="p">,</span> <span class="n">slope</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_parameters</span><span class="p">(</span><span class="n">node1</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">axis1</span><span class="p">),</span> <span class="n">node1</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="n">axis1</span><span class="p">))</span>
            
            <span class="c1"># if shift is None:</span>
            <span class="c1">#     shift = _DEFAULT_SHIFT</span>
            <span class="c1"># if slope is None:</span>
            <span class="c1">#     slope = _DEFAULT_SLOPE</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_sigmoid</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_matrix</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dim</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_shift</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_slope</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_parameters</span><span class="p">(</span><span class="n">shift</span><span class="p">,</span> <span class="n">slope</span><span class="p">)</span>

    <span class="c1"># ----------</span>
    <span class="c1"># Properties</span>
    <span class="c1"># ----------</span>
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">shift</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Parameter</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shift</span>

    <span class="nd">@shift</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">shift</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shift</span><span class="p">:</span> <span class="n">EdgeParameter</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_parameters</span><span class="p">(</span><span class="n">shift</span><span class="o">=</span><span class="n">shift</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">slope</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Parameter</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_slope</span>

    <span class="nd">@slope</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">slope</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">slope</span><span class="p">:</span> <span class="n">EdgeParameter</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_parameters</span><span class="p">(</span><span class="n">slope</span><span class="o">=</span><span class="n">slope</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_matrix</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_matrix</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">grad</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">shift</span><span class="o">.</span><span class="n">grad</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">slope</span><span class="o">.</span><span class="n">grad</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">module_name</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Text</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create adapted name to be used when calling it as a submodule of</span>
<span class="sd">        a tensor network</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_dangling</span><span class="p">():</span>
            <span class="k">return</span> <span class="sa">f</span><span class="s1">&#39;edge_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">node1</span><span class="o">.</span><span class="n">_name</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">axis1</span><span class="o">.</span><span class="n">_name</span><span class="si">}</span><span class="s1">&#39;</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s1">&#39;edge_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">node1</span><span class="o">.</span><span class="n">_name</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">axis1</span><span class="o">.</span><span class="n">_name</span><span class="si">}</span><span class="s1">_&#39;</span> \
               <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">node2</span><span class="o">.</span><span class="n">_name</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">axis2</span><span class="o">.</span><span class="n">_name</span><span class="si">}</span><span class="s1">&#39;</span>

    <span class="c1"># -------</span>
    <span class="c1"># Methods</span>
    <span class="c1"># -------</span>
<div class="viewcode-block" id="ParamEdge.compute_parameters"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.ParamEdge.compute_parameters">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">compute_parameters</span><span class="p">(</span><span class="n">size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute shift and slope parameters given a certain size and dimension</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`size` should be int type&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`dim` should be int type&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="o">&gt;</span> <span class="n">size</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;`dim` should be smaller or equal than `size`&#39;</span><span class="p">)</span>
        <span class="c1"># shift = (size - dim) - 0.5</span>
        <span class="n">shift</span> <span class="o">=</span> <span class="n">dim</span> <span class="o">-</span> <span class="mf">0.5</span>
        <span class="n">slope</span> <span class="o">=</span> <span class="n">_DEFAULT_SLOPE</span>
        <span class="k">return</span> <span class="n">shift</span><span class="p">,</span> <span class="n">slope</span></div>

<div class="viewcode-block" id="ParamEdge.set_parameters"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.ParamEdge.set_parameters">[docs]</a>    <span class="k">def</span> <span class="nf">set_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                       <span class="n">shift</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">EdgeParameter</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                       <span class="n">slope</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">EdgeParameter</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set both parameters, update them and set the new matrix</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">device</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">node1</span><span class="o">.</span><span class="n">tensor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">node1</span><span class="o">.</span><span class="n">tensor</span><span class="o">.</span><span class="n">device</span>
        
        <span class="k">if</span> <span class="n">shift</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shift</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
                <span class="n">shift</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">shift</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_shift</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">shift</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_shift</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">shift</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_prev_shift</span> <span class="o">=</span> <span class="n">_DEFAULT_SHIFT</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shift</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_shift</span> <span class="o">=</span> <span class="n">shift</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_prev_shift</span> <span class="o">=</span> <span class="n">shift</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="s1">&#39;`shift` should be int, float or Parameter type&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">slope</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">slope</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">)):</span>
                <span class="n">slope</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">slope</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_slope</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">slope</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_slope</span> <span class="o">=</span> <span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">slope</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_prev_slope</span> <span class="o">=</span> <span class="n">slope</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">slope</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">):</span>
                <span class="c1"># TODO: eligible device</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_slope</span> <span class="o">=</span> <span class="n">slope</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_prev_slope</span> <span class="o">=</span> <span class="n">slope</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="s1">&#39;`slope` should be int, float or Parameter type&#39;</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">set_matrix</span><span class="p">()</span></div>

<div class="viewcode-block" id="ParamEdge.is_updated"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.ParamEdge.is_updated">[docs]</a>    <span class="k">def</span> <span class="nf">is_updated</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>  <span class="c1"># TODO: creo que esto no sirve para nada, lo podemos borrar</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Track if shift and slope have changed during training, in order</span>
<span class="sd">        to set the new corresponding matrix</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_prev_shift</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shift</span><span class="o">.</span><span class="n">item</span><span class="p">())</span> <span class="ow">and</span> \
                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_prev_slope</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_slope</span><span class="o">.</span><span class="n">item</span><span class="p">()):</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="kc">False</span></div>

    <span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<div class="viewcode-block" id="ParamEdge.make_matrix"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.ParamEdge.make_matrix">[docs]</a>    <span class="k">def</span> <span class="nf">make_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create the matrix depending on shift and slope. The matrix is</span>
<span class="sd">        near the identity, although it might have some zeros in the first</span>
<span class="sd">        positions of the diagonal (dimension is equal to number of 1&#39;s, while</span>
<span class="sd">        size is equal to the matrix size)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">()),</span>
                             <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">shift</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">shift</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="c1"># matrix[(i, i)] = self.sigmoid(self.slope * (i - self.shift))</span>
        <span class="n">matrix</span><span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">slope</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shift</span> <span class="o">-</span> <span class="n">i</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">matrix</span></div>

<div class="viewcode-block" id="ParamEdge.set_matrix"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.ParamEdge.set_matrix">[docs]</a>    <span class="k">def</span> <span class="nf">set_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create the matrix and set it, also updating the dimension</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_matrix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_matrix</span><span class="p">()</span>
        <span class="n">signs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_matrix</span><span class="o">.</span><span class="n">diagonal</span><span class="p">()</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">signs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span>
                              <span class="n">signs</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">signs</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s1">&#39;Dimension of edge </span><span class="si">{</span><span class="bp">self</span><span class="si">!r}</span><span class="s1"> is not greater than zero&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dim</span> <span class="o">=</span> <span class="n">dim</span></div>

<div class="viewcode-block" id="ParamEdge.dim"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.ParamEdge.dim">[docs]</a>    <span class="k">def</span> <span class="nf">dim</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Here, `dimension` is not the same as `size`. The ``dim`` and ``size`` in</span>
<span class="sd">        a certain axis can be equal if the edge attached to that axis is not parametric</span>
<span class="sd">        (e.g. :class:`Edge`). In the case of parametric edges (e.g. :class:`ParamEdge`),</span>
<span class="sd">        `bond dimensions` can be learned, meaning that, although the tensor&#39;s shape</span>
<span class="sd">        can be fixed through the whole training process, what is learned is an</span>
<span class="sd">        `effective` dimension</span>
<span class="sd">        </span>
<span class="sd">        Similar to `size`, but if a ParamEdge is attached to an axis,</span>
<span class="sd">        it is returned its dimension (number of 1&#39;s in the diagonal of</span>
<span class="sd">        the matrix) rather than its total size (number of 1&#39;s and 0&#39;s</span>
<span class="sd">        in the diagonal of the matrix)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int</span>
<span class="sd">            _description_</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dim</span></div>

    <span class="k">def</span> <span class="nf">change_dim</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">():</span>
            <span class="n">shift</span><span class="p">,</span> <span class="n">slope</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_parameters</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">dim</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">set_parameters</span><span class="p">(</span><span class="n">shift</span><span class="p">,</span> <span class="n">slope</span><span class="p">)</span>

<div class="viewcode-block" id="ParamEdge.change_size"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.ParamEdge.change_size">[docs]</a>    <span class="k">def</span> <span class="nf">change_size</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`size` should be int type&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_size</span> <span class="o">=</span> <span class="n">size</span>
        <span class="n">shift</span><span class="p">,</span> <span class="n">slope</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_parameters</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">()))</span>
        <span class="n">device</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shift</span><span class="o">.</span><span class="n">device</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">set_parameters</span><span class="p">(</span><span class="n">shift</span><span class="p">,</span> <span class="n">slope</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_dangling</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">node2</span><span class="o">.</span><span class="n">_change_axis_size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">axis2</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">node1</span><span class="o">.</span><span class="n">_change_axis_size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">axis1</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span></div>

<div class="viewcode-block" id="ParamEdge.parameterize"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.ParamEdge.parameterize">[docs]</a>    <span class="k">def</span> <span class="nf">parameterize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                     <span class="n">set_param</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                     <span class="n">size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="s1">&#39;Edge&#39;</span><span class="p">,</span> <span class="s1">&#39;ParamEdge&#39;</span><span class="p">]:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">set_param</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">change_size</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">())</span>
            <span class="n">new_edge</span> <span class="o">=</span> <span class="n">Edge</span><span class="p">(</span><span class="n">node1</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">node1</span><span class="p">,</span> <span class="n">axis1</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">axis1</span><span class="p">,</span>
                            <span class="n">node2</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">node2</span><span class="p">,</span> <span class="n">axis2</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">axis2</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_dangling</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">node2</span><span class="o">.</span><span class="n">_add_edge</span><span class="p">(</span><span class="n">new_edge</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">axis2</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">node1</span><span class="o">.</span><span class="n">_add_edge</span><span class="p">(</span><span class="n">new_edge</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">axis1</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">node1</span><span class="o">.</span><span class="n">_network</span><span class="o">.</span><span class="n">_remove_edge</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">node1</span><span class="o">.</span><span class="n">_network</span><span class="o">.</span><span class="n">_add_edge</span><span class="p">(</span><span class="n">new_edge</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">new_edge</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="ParamEdge.copy"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.ParamEdge.copy">[docs]</a>    <span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;ParamEdge&#39;</span><span class="p">:</span>
        <span class="n">new_edge</span> <span class="o">=</span> <span class="n">ParamEdge</span><span class="p">(</span><span class="n">node1</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">node1</span><span class="p">,</span> <span class="n">axis1</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">axis1</span><span class="p">,</span>
                             <span class="n">shift</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">shift</span><span class="p">,</span> <span class="n">slope</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">slope</span><span class="p">,</span>
                             <span class="n">node2</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">node2</span><span class="p">,</span> <span class="n">axis2</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">axis2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">new_edge</span></div>

    <span class="nd">@overload</span>
    <span class="k">def</span> <span class="nf">connect</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="n">Edge</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;ParamEdge&#39;</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="nd">@overload</span>
    <span class="k">def</span> <span class="nf">connect</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="s1">&#39;ParamEdge&#39;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;ParamEdge&#39;</span><span class="p">:</span>
        <span class="k">pass</span>

<div class="viewcode-block" id="ParamEdge.connect"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.ParamEdge.connect">[docs]</a>    <span class="k">def</span> <span class="nf">connect</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="s1">&#39;Edge&#39;</span><span class="p">,</span> <span class="s1">&#39;ParamEdge&#39;</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="s1">&#39;ParamEdge&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">connect</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">)</span></div>

<div class="viewcode-block" id="ParamEdge.disconnect"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.ParamEdge.disconnect">[docs]</a>    <span class="k">def</span> <span class="nf">disconnect</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="s1">&#39;ParamEdge&#39;</span><span class="p">,</span> <span class="s1">&#39;ParamEdge&#39;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">disconnect</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></div></div>


<span class="c1">################################################</span>
<span class="c1">#                    STACKS                    #</span>
<span class="c1">################################################</span>
<span class="c1"># TODO: hacer privados</span>
<span class="c1"># TODO: queda comprobar stacks</span>
<span class="c1"># TODO: ver si se puede reestructurar, igual un AbstractStackNode que aglutine</span>
<span class="c1">#  ambas clases y luego hacer subclases de Node y Paramnode</span>
<span class="c1"># TODO: aadir unbind como metodo interno</span>
<div class="viewcode-block" id="StackNode"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.StackNode">[docs]</a><span class="k">class</span> <span class="nc">StackNode</span><span class="p">(</span><span class="n">Node</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class for stacked nodes. This is a node that stores the information</span>
<span class="sd">    of a list of nodes that are stacked in order to perform some operation</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">nodes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">AbstractNode</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">axes_names</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">Text</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Text</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">network</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s1">&#39;TensorNetwork&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">override_node</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                 <span class="n">tensor</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">edges</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="s1">&#39;AbstractEdge&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">node1_list</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">bool</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

        <span class="k">if</span> <span class="n">nodes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">nodes</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`nodes` should be a list or tuple of nodes&#39;</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="p">(</span><span class="n">StackNode</span><span class="p">,</span> <span class="n">ParamStackNode</span><span class="p">)):</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                        <span class="s1">&#39;Cannot create a stack using (Param)StackNode</span><span class="se">\&#39;</span><span class="s1">s&#39;</span><span class="p">)</span>

            <span class="c1"># TODO: Y en la misma TN todos</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">nodes</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">nodes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="nb">type</span><span class="p">(</span><span class="n">nodes</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])):</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Cannot stack nodes of different types. Nodes &#39;</span>
                                    <span class="s1">&#39;must be either all Node or all ParamNode type&#39;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">nodes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">rank</span> <span class="o">!=</span> <span class="n">nodes</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">rank</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s1">&#39;Cannot stack nodes with different number of edges&#39;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">nodes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axes_names</span> <span class="o">!=</span> <span class="n">nodes</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axes_names</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s1">&#39;Stacked nodes must have the same name for each axis&#39;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">nodes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">network</span> <span class="o">!=</span> <span class="n">nodes</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">network</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s1">&#39;Stacked nodes must all be in the same network&#39;</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">edge1</span><span class="p">,</span> <span class="n">edge2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">nodes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">edges</span><span class="p">,</span> <span class="n">nodes</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">edges</span><span class="p">):</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edge1</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">edge2</span><span class="p">)):</span>
                        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Cannot stack nodes with edges of different types. &#39;</span>
                                        <span class="s1">&#39;The edges that are attached to the same axis in &#39;</span>
                                        <span class="s1">&#39;each node must be either all Edge or all ParamEdge type&#39;</span><span class="p">)</span>

            <span class="n">edges_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
            <span class="n">node1_lists_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">_axes</span><span class="p">:</span>
                    <span class="n">edge</span> <span class="o">=</span> <span class="n">node</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>
                    <span class="k">if</span> <span class="n">axis</span><span class="o">.</span><span class="n">_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">edges_dict</span><span class="p">:</span>
                        <span class="n">edges_dict</span><span class="p">[</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">edge</span><span class="p">]</span>
                        <span class="n">node1_lists_dict</span><span class="p">[</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">axis</span><span class="o">.</span><span class="n">_node1</span><span class="p">]</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">edges_dict</span><span class="p">[</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">edge</span><span class="p">)</span>
                        <span class="n">node1_lists_dict</span><span class="p">[</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">axis</span><span class="o">.</span><span class="n">_node1</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_edges_dict</span> <span class="o">=</span> <span class="n">edges_dict</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_node1_lists_dict</span> <span class="o">=</span> <span class="n">node1_lists_dict</span>
            <span class="c1"># self.nodes = nodes</span>

            <span class="c1"># stacked_tensor = torch.stack([node.tensor for node in nodes])</span>
            <span class="k">if</span> <span class="n">tensor</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># TODO: not sure if this is necessary</span>
                <span class="n">tensor</span> <span class="o">=</span> <span class="n">stack_unequal_tensors</span><span class="p">([</span><span class="n">node</span><span class="o">.</span><span class="n">tensor</span> <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">])</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">axes_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;stack&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axes_names</span><span class="p">,</span>
                             <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
                             <span class="n">network</span><span class="o">=</span><span class="n">nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_network</span><span class="p">,</span>
                             <span class="n">leaf</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                             <span class="n">override_node</span><span class="o">=</span><span class="n">override_node</span><span class="p">,</span>
                             <span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">axes_names</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s1">&#39;If `nodes` are not provided, `axes_names` must be given&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">network</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s1">&#39;If `nodes` are not provided, `network` must be given&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">tensor</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s1">&#39;If `nodes` are not provided, `tensor` must be given&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">edges</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s1">&#39;If `nodes` are not provided, `edges` must be given&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">node1_list</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s1">&#39;If `nodes` are not provided, `node1_list` must be given&#39;</span><span class="p">)</span>

            <span class="n">edges_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
            <span class="n">node1_lists_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">edge</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes_names</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">edges</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
                <span class="n">edges_dict</span><span class="p">[</span><span class="n">axis_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">edge</span><span class="o">.</span><span class="n">edges</span>
                <span class="n">node1_lists_dict</span><span class="p">[</span><span class="n">axis_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">edge</span><span class="o">.</span><span class="n">node1_lists</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_edges_dict</span> <span class="o">=</span> <span class="n">edges_dict</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_node1_lists_dict</span> <span class="o">=</span> <span class="n">node1_lists_dict</span>
            <span class="c1"># self.nodes = nodes</span>

            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">axes_names</span><span class="o">=</span><span class="n">axes_names</span><span class="p">,</span>
                             <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
                             <span class="n">network</span><span class="o">=</span><span class="n">network</span><span class="p">,</span>
                             <span class="n">leaf</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                             <span class="n">override_node</span><span class="o">=</span><span class="n">override_node</span><span class="p">,</span>
                             <span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span>
                             <span class="n">edges</span><span class="o">=</span><span class="n">edges</span><span class="p">,</span>
                             <span class="n">node1_list</span><span class="o">=</span><span class="n">node1_list</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">edges_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Text</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">AbstractEdge</span><span class="p">]]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edges_dict</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">node1_lists_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Text</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">bool</span><span class="p">]]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_node1_lists_dict</span>

    <span class="k">def</span> <span class="nf">_make_edge</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="n">Axis</span><span class="p">,</span> <span class="n">param_edges</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="s1">&#39;Edge&#39;</span><span class="p">,</span> <span class="s1">&#39;ParamEdge&#39;</span><span class="p">]:</span>
        <span class="c1"># TODO: param_edges not used here</span>
        <span class="k">if</span> <span class="n">axis</span><span class="o">.</span><span class="n">num</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Stack axis</span>
            <span class="k">return</span> <span class="n">Edge</span><span class="p">(</span><span class="n">node1</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis1</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_edges_dict</span><span class="p">[</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">Edge</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">StackEdge</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_edges_dict</span><span class="p">[</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span><span class="p">],</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">_node1_lists_dict</span><span class="p">[</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span><span class="p">],</span>
                             <span class="n">node1</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis1</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_edges_dict</span><span class="p">[</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">ParamEdge</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">ParamStackEdge</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_edges_dict</span><span class="p">[</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span><span class="p">],</span>
                                  <span class="bp">self</span><span class="o">.</span><span class="n">_node1_lists_dict</span><span class="p">[</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span><span class="p">],</span>
                                  <span class="n">node1</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
                                  <span class="n">axis1</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span></div>


<div class="viewcode-block" id="ParamStackNode"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.ParamStackNode">[docs]</a><span class="k">class</span> <span class="nc">ParamStackNode</span><span class="p">(</span><span class="n">ParamNode</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class for parametric stacked nodes. This is a node that stores the information</span>
<span class="sd">    of a list of parametric nodes that are stacked in order to perform some operation</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">nodes</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">AbstractNode</span><span class="p">],</span>
                 <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Text</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">virtual</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                 <span class="n">override_node</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                 <span class="n">tensor</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">nodes</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`nodes` should be a list or tuple of nodes&#39;</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="p">(</span><span class="n">StackNode</span><span class="p">,</span> <span class="n">ParamStackNode</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="s1">&#39;Cannot create a stack using (Param)StackNode</span><span class="se">\&#39;</span><span class="s1">s&#39;</span><span class="p">)</span>

        <span class="c1"># TODO: Y en la misma TN todos</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">nodes</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">nodes</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="nb">type</span><span class="p">(</span><span class="n">nodes</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Cannot stack nodes of different types. Nodes &#39;</span>
                                <span class="s1">&#39;must be either all Node or all ParamNode type&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">nodes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">rank</span> <span class="o">!=</span> <span class="n">nodes</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">rank</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s1">&#39;Cannot stack nodes with different number of edges&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">nodes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">axes_names</span> <span class="o">!=</span> <span class="n">nodes</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axes_names</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s1">&#39;Stacked nodes must have the same name for each axis&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">nodes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">network</span> <span class="o">!=</span> <span class="n">nodes</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">network</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s1">&#39;Stacked nodes must all be in the same network&#39;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">edge1</span><span class="p">,</span> <span class="n">edge2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">nodes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">edges</span><span class="p">,</span> <span class="n">nodes</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">edges</span><span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edge1</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">edge2</span><span class="p">)):</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Cannot stack nodes with edges of different types. &#39;</span>
                                    <span class="s1">&#39;The edges that are attached to the same axis in &#39;</span>
                                    <span class="s1">&#39;each node must be either all Edge or all ParamEdge type&#39;</span><span class="p">)</span>

        <span class="n">edges_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="n">node1_lists_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">_axes</span><span class="p">:</span>
                <span class="n">edge</span> <span class="o">=</span> <span class="n">node</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">axis</span><span class="o">.</span><span class="n">_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">edges_dict</span><span class="p">:</span>
                    <span class="n">edges_dict</span><span class="p">[</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">edge</span><span class="p">]</span>
                    <span class="n">node1_lists_dict</span><span class="p">[</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">axis</span><span class="o">.</span><span class="n">_node1</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">edges_dict</span><span class="p">[</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">edge</span><span class="p">)</span>
                    <span class="n">node1_lists_dict</span><span class="p">[</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">axis</span><span class="o">.</span><span class="n">_node1</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_edges_dict</span> <span class="o">=</span> <span class="n">edges_dict</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_node1_lists_dict</span> <span class="o">=</span> <span class="n">node1_lists_dict</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nodes</span> <span class="o">=</span> <span class="n">nodes</span>

        <span class="c1"># stacked_tensor = torch.stack([node.tensor for node in nodes])</span>
        <span class="k">if</span> <span class="n">tensor</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tensor</span> <span class="o">=</span> <span class="n">stack_unequal_tensors</span><span class="p">([</span><span class="n">node</span><span class="o">.</span><span class="n">tensor</span> <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">])</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">axes_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;stack&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">axes_names</span><span class="p">,</span>
                         <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
                         <span class="n">network</span><span class="o">=</span><span class="n">nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_network</span><span class="p">,</span>
                         <span class="n">virtual</span><span class="o">=</span><span class="n">virtual</span><span class="p">,</span>
                         <span class="c1">#  leaf=False,</span>
                         <span class="n">override_node</span><span class="o">=</span><span class="n">override_node</span><span class="p">,</span>
                         <span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">edges_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Text</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">AbstractEdge</span><span class="p">]]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edges_dict</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">node1_lists_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Text</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">bool</span><span class="p">]]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_node1_lists_dict</span>

    <span class="k">def</span> <span class="nf">_make_edge</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="n">Axis</span><span class="p">,</span> <span class="n">param_edges</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="s1">&#39;Edge&#39;</span><span class="p">,</span> <span class="s1">&#39;ParamEdge&#39;</span><span class="p">]:</span>
        <span class="c1"># TODO: param_edges not used here</span>
        <span class="k">if</span> <span class="n">axis</span><span class="o">.</span><span class="n">num</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Stack axis</span>
            <span class="k">return</span> <span class="n">Edge</span><span class="p">(</span><span class="n">node1</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis1</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_edges_dict</span><span class="p">[</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">Edge</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">StackEdge</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_edges_dict</span><span class="p">[</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span><span class="p">],</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">_node1_lists_dict</span><span class="p">[</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span><span class="p">],</span>
                             <span class="n">node1</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis1</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_edges_dict</span><span class="p">[</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">ParamEdge</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">ParamStackEdge</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_edges_dict</span><span class="p">[</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span><span class="p">],</span>
                                  <span class="bp">self</span><span class="o">.</span><span class="n">_node1_lists_dict</span><span class="p">[</span><span class="n">axis</span><span class="o">.</span><span class="n">_name</span><span class="p">],</span>
                                  <span class="n">node1</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
                                  <span class="n">axis1</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span></div>


<span class="n">AbstractStackNode</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span><span class="n">StackNode</span><span class="p">,</span> <span class="n">ParamStackNode</span><span class="p">]</span>


<span class="k">class</span> <span class="nc">AbstractStackEdge</span><span class="p">(</span><span class="n">AbstractEdge</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Abstract class for stack edges</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">edges</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">AbstractEdge</span><span class="p">]:</span>
        <span class="k">pass</span>


<div class="viewcode-block" id="StackEdge"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.StackEdge">[docs]</a><span class="k">class</span> <span class="nc">StackEdge</span><span class="p">(</span><span class="n">AbstractStackEdge</span><span class="p">,</span> <span class="n">Edge</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base class for stacks of non-trainable edges.</span>
<span class="sd">    Used for stacked contractions</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">edges</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Edge</span><span class="p">],</span>
                 <span class="n">node1_lists</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">bool</span><span class="p">],</span>
                 <span class="n">node1</span><span class="p">:</span> <span class="n">AbstractStackNode</span><span class="p">,</span>
                 <span class="n">axis1</span><span class="p">:</span> <span class="n">Axis</span><span class="p">,</span>
                 <span class="n">node2</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">AbstractStackNode</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">axis2</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Axis</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_edges</span> <span class="o">=</span> <span class="n">edges</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_node1_lists</span> <span class="o">=</span> <span class="n">node1_lists</span>
        <span class="n">Edge</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                      <span class="n">node1</span><span class="o">=</span><span class="n">node1</span><span class="p">,</span> <span class="n">axis1</span><span class="o">=</span><span class="n">axis1</span><span class="p">,</span>
                      <span class="n">node2</span><span class="o">=</span><span class="n">node2</span><span class="p">,</span> <span class="n">axis2</span><span class="o">=</span><span class="n">axis2</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">edges</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Edge</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edges</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">node1_lists</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">bool</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_node1_lists</span>

    <span class="k">def</span> <span class="fm">__xor__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="s1">&#39;StackEdge&#39;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Edge</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">connect_stack</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">)</span></div>


<div class="viewcode-block" id="ParamStackEdge"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.ParamStackEdge">[docs]</a><span class="k">class</span> <span class="nc">ParamStackEdge</span><span class="p">(</span><span class="n">AbstractStackEdge</span><span class="p">,</span> <span class="n">ParamEdge</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base class for stacks of trainable edges.</span>
<span class="sd">    Used for stacked contractions</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">edges</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">ParamEdge</span><span class="p">],</span>
                 <span class="n">node1_lists</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">bool</span><span class="p">],</span>
                 <span class="n">node1</span><span class="p">:</span> <span class="n">AbstractStackNode</span><span class="p">,</span>
                 <span class="n">axis1</span><span class="p">:</span> <span class="n">Axis</span><span class="p">,</span>
                 <span class="n">node2</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">AbstractStackNode</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">axis2</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Axis</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_edges</span> <span class="o">=</span> <span class="n">edges</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_node1_lists</span> <span class="o">=</span> <span class="n">node1_lists</span>
        <span class="n">ParamEdge</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                           <span class="n">node1</span><span class="o">=</span><span class="n">node1</span><span class="p">,</span> <span class="n">axis1</span><span class="o">=</span><span class="n">axis1</span><span class="p">,</span>
                           <span class="c1">#    shift=self._edges[0].shift,</span>
                           <span class="c1">#    slope=self._edges[0].slope,</span>
                           <span class="n">node2</span><span class="o">=</span><span class="n">node2</span><span class="p">,</span> <span class="n">axis2</span><span class="o">=</span><span class="n">axis2</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">edges</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">ParamEdge</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edges</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">node1_lists</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">bool</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_node1_lists</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="n">mats</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">edges</span><span class="p">:</span>
            <span class="n">mats</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">edge</span><span class="o">.</span><span class="n">matrix</span><span class="p">)</span>
        <span class="n">stacked_mats</span> <span class="o">=</span> <span class="n">stack_unequal_tensors</span><span class="p">(</span><span class="n">mats</span><span class="p">)</span>

        <span class="c1"># When stacking nodes that were previously stacked, and the memory of</span>
        <span class="c1"># the current stack makes reference to the previous one with, possibly,</span>
        <span class="c1"># a different size, the stacked_mats could have a size that is smaller</span>
        <span class="c1"># from the current stack</span>
        <span class="k">if</span> <span class="n">stacked_mats</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]</span> <span class="o">!=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_size</span><span class="p">):</span>
            <span class="n">pad</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_size</span> <span class="o">-</span> <span class="n">stacked_mats</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span>
                   <span class="bp">self</span><span class="o">.</span><span class="n">_size</span> <span class="o">-</span> <span class="n">stacked_mats</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="mi">0</span><span class="p">]</span>
            <span class="n">stacked_mats</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">stacked_mats</span><span class="p">,</span> <span class="n">pad</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">stacked_mats</span>

    <span class="k">def</span> <span class="fm">__xor__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="s1">&#39;ParamStackEdge&#39;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ParamEdge</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">connect_stack</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">)</span></div>

    <span class="c1"># TODO: Cual es la dimension de este edge si apilo las matrices??</span>


<span class="c1">################################################</span>
<span class="c1">#                TENSOR NETWORK                #</span>
<span class="c1">################################################</span>
<div class="viewcode-block" id="Successor"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.Successor">[docs]</a><span class="k">class</span> <span class="nc">Successor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Class for successors. Object that stores information about</span>
<span class="sd">    the already computed operations in the network, in order to</span>
<span class="sd">    compute them faster next time.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    kwargs: keyword arguments used in the operation</span>
<span class="sd">    child: node resultant from the operation</span>
<span class="sd">    hints: hints created the first time the computation was</span>
<span class="sd">        performed, so that next times we can avoid calculating</span>
<span class="sd">        auxiliary information needed for the computation</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">kwargs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Text</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
                 <span class="n">child</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">AbstractNode</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">AbstractNode</span><span class="p">]],</span>
                 <span class="n">contracting</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">hints</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kwargs</span> <span class="o">=</span> <span class="n">kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">child</span> <span class="o">=</span> <span class="n">child</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hints</span> <span class="o">=</span> <span class="n">hints</span></div>


<div class="viewcode-block" id="TensorNetwork"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.TensorNetwork">[docs]</a><span class="k">class</span> <span class="nc">TensorNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    General class for Tensor Networks. Subclass of PyTorch nn.Module.</span>
<span class="sd">    Should be subclassed to implement custom initialization and contraction</span>
<span class="sd">    methods that suit the particular topology of each type of Tensor</span>
<span class="sd">    Network.</span>

<span class="sd">    TensorNetwork can be instantiated to build network structures of nodes,</span>
<span class="sd">    and perform site-wise contractions, even though network contraction</span>
<span class="sd">    methods are not implemented. Useful for experimentation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">operations</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Text</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>

        <span class="c1"># self._nodes = dict()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_leaf_nodes</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_data_nodes</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_virtual_nodes</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_non_leaf_nodes</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_repeated_nodes_names</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_memory_nodes</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>   <span class="c1"># address -&gt; memory</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_inverse_memory</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>  <span class="c1"># address -&gt; nodes using that memory</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_data_nodes</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="c1"># self._memory_data_nodes = None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_edges</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># TODO: poder pasar esto como parametros</span>
        <span class="c1"># Flag to indicate whether the TN has optimized memory to perform contraction</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_automemory</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_unbind_mode</span> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># True if training, False if not training</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_tracing</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_list_ops</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Text</span><span class="p">,</span> <span class="n">AbstractNode</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        All the nodes belonging to the network (including data nodes)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">all_nodes</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="n">all_nodes</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_leaf_nodes</span><span class="p">)</span>
        <span class="n">all_nodes</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data_nodes</span><span class="p">)</span>
        <span class="n">all_nodes</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_virtual_nodes</span><span class="p">)</span>
        <span class="n">all_nodes</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_non_leaf_nodes</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">all_nodes</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">nodes_names</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Text</span><span class="p">]:</span>
        <span class="n">all_nodes_names</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">al_nodes_names</span> <span class="o">+=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_leaf_nodes</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">al_nodes_names</span> <span class="o">+=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data_nodes</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">al_nodes_names</span> <span class="o">+=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_virtual_nodes</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">al_nodes_names</span> <span class="o">+=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_non_leaf_nodes</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">all_nodes_names</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">leaf_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Text</span><span class="p">,</span> <span class="n">AbstractNode</span><span class="p">]:</span>
        <span class="c1"># TODO: cuanto sentido tiene proteger listas, dicts, etc.</span>
        <span class="c1"># O devuelvo copias para protegerlos de verdad o no lo protejo</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Data nodes created to feed the tensor network with input data</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_leaf_nodes</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">data_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Text</span><span class="p">,</span> <span class="n">AbstractNode</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Data nodes created to feed the tensor network with input data</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_nodes</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">virtual_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Text</span><span class="p">,</span> <span class="n">AbstractNode</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Data nodes created to feed the tensor network with input data</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_virtual_nodes</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">non_leaf_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Text</span><span class="p">,</span> <span class="n">AbstractNode</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Data nodes created to feed the tensor network with input data</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_leaf_nodes</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">edges</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">AbstractEdge</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        List of dangling, non-batch edges of the network</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edges</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">automemory</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_automemory</span>

    <span class="nd">@automemory</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">automemory</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">automem</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># TODO: necesito rehacer todo?</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_automemory</span> <span class="o">=</span> <span class="n">automem</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">unbind_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unbind_mode</span>

    <span class="nd">@unbind_mode</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">unbind_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">unbind</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># TODO: necesito rehacer todo?</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_unbind_mode</span> <span class="o">=</span> <span class="n">unbind</span>

<div class="viewcode-block" id="TensorNetwork.trace"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.TensorNetwork.trace">[docs]</a>    <span class="k">def</span> <span class="nf">trace</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">example</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Trace TensorNetwork contraction.&quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_tracing</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="bp">self</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_tracing</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="bp">self</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>
        <span class="c1"># self._tracing = False</span>

    <span class="k">def</span> <span class="nf">_add_node</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span> <span class="n">override</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add node to the network, adding its parameters (parametric tensor and/or edges)</span>
<span class="sd">        to the network parameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        node: node to be added</span>
<span class="sd">        override: if the node that is to be added has the same name that other node</span>
<span class="sd">            that already belongs to the network, override indicates if the first node</span>
<span class="sd">            have to override the second one. If not, the names are changed to avoid</span>
<span class="sd">            conflicts</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">override</span><span class="p">:</span>
            <span class="n">prev_node</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_remove_node</span><span class="p">(</span><span class="n">prev_node</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_assign_node_name</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

    <span class="c1"># TODO: not used</span>
    <span class="k">def</span> <span class="nf">add_nodes_from</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nodes_list</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">AbstractNode</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nodes_list</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_add_node</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_add_edge</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">edge</span><span class="p">:</span> <span class="n">AbstractEdge</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># TODO: evitar aadir los edges de los stacks a la TN</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edge</span><span class="p">,</span> <span class="n">AbstractStackEdge</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edge</span><span class="p">,</span> <span class="n">ParamEdge</span><span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">edge</span><span class="o">.</span><span class="n">module_name</span><span class="p">):</span>
                    <span class="c1"># If ParamEdge is already a submodule, it is the case in which we are</span>
                    <span class="c1"># adding a node that &quot;inherits&quot; edges from previous nodes</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="n">edge</span><span class="o">.</span><span class="n">module_name</span><span class="p">,</span> <span class="n">edge</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">edge</span><span class="o">.</span><span class="n">is_dangling</span><span class="p">()</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">edge</span><span class="o">.</span><span class="n">is_batch</span><span class="p">()</span> <span class="ow">and</span> <span class="p">(</span><span class="n">edge</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edges</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_edges</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">edge</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_remove_edge</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">edge</span><span class="p">:</span> <span class="n">AbstractEdge</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># TODO: evitar aadir los edges de los stacks a la TN</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edge</span><span class="p">,</span> <span class="n">AbstractStackEdge</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edge</span><span class="p">,</span> <span class="n">ParamEdge</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">edge</span><span class="o">.</span><span class="n">module_name</span><span class="p">):</span>
                    <span class="nb">delattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">edge</span><span class="o">.</span><span class="n">module_name</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">edge</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edges</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_edges</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">edge</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_which_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="n">Text</span><span class="p">,</span> <span class="n">AbstractNode</span><span class="p">]]:</span>
        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">_leaf</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_leaf_nodes</span>
        <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">_data</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_nodes</span>
        <span class="k">elif</span> <span class="n">node</span><span class="o">.</span><span class="n">_virtual</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_virtual_nodes</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_leaf_nodes</span>

    <span class="k">def</span> <span class="nf">_remove_node</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span> <span class="n">move_names</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function only removes the reference to the node, and the reference</span>
<span class="sd">        to the TN that is kept by the node. To completely get rid of the node,</span>
<span class="sd">        it should be disconnected from any other node of the TN and removed from</span>
<span class="sd">        the TN.</span>

<span class="sd">        Args</span>
<span class="sd">        ----</span>
<span class="sd">        move_nodes: indicates whether the rest of the names should be</span>
<span class="sd">            changed to maintain a correct enumeration. Used when we want</span>
<span class="sd">            to delete many nodes quickly (and we know there will be no</span>
<span class="sd">            problems with remaining names)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">node</span><span class="o">.</span><span class="n">_temp_tensor</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">tensor</span>
        <span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">node</span><span class="o">.</span><span class="n">_network</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_unassign_node_name</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">move_names</span><span class="p">)</span>

        <span class="n">nodes_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_which_dict</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">_name</span> <span class="ow">in</span> <span class="n">nodes_dict</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">nodes_dict</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">_name</span><span class="p">]</span> <span class="o">==</span> <span class="n">node</span><span class="p">:</span>
                <span class="k">del</span> <span class="n">nodes_dict</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">_name</span><span class="p">]</span>

                <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_memory_nodes</span><span class="p">:</span>  <span class="c1"># NOTE: puede que no est&#39;e si usaba memory de otro nodo</span>
                    <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_memory_nodes</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">_name</span><span class="p">]</span>

<div class="viewcode-block" id="TensorNetwork.delete_node"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.TensorNetwork.delete_node">[docs]</a>    <span class="k">def</span> <span class="nf">delete_node</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span> <span class="n">move_names</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This function disconnects the node from its neighbours and</span>
<span class="sd">        removes it from the TN</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">node</span><span class="o">.</span><span class="n">disconnect</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_remove_node</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">move_names</span><span class="p">)</span></div>
        <span class="c1"># TODO: del node</span>

<div class="viewcode-block" id="TensorNetwork.clear"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.TensorNetwork.clear">[docs]</a>    <span class="k">def</span> <span class="nf">clear</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Elimina todos los non leaf y vuelve a poner a cada nodo leaf su propia memoria</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO: tarda mogoll&#39;on, tengo que arreglarlo</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_list_ops</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_inverse_memory</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_leaf_nodes</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_virtual_nodes</span><span class="p">:</span>
            <span class="c1"># TODO: pensar esto, igual no hace falta siempre cambiar los leaf nodes</span>
            <span class="c1"># TODO: solo poner memoria a s mismos si su memoria estaba en un nodo non_leaf</span>
            <span class="c1"># (node_ref era nodo non_leaf), as&#39;i podemos hacer Uniform TN guardando siempre</span>
            <span class="c1"># tensor en nodos virtuales</span>
            <span class="n">aux_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
            <span class="n">aux_dict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_leaf_nodes</span><span class="p">)</span>
            <span class="n">aux_dict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_non_leaf_nodes</span><span class="p">)</span>
            <span class="n">aux_dict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_virtual_nodes</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">aux_dict</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">is_virtual</span><span class="p">()</span> <span class="ow">and</span> <span class="p">(</span><span class="s1">&#39;virtual_stack&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
                    <span class="k">continue</span>

                <span class="n">node</span><span class="o">.</span><span class="n">_successors</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

                <span class="n">node_ref</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;node_ref&#39;</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">node_ref</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">node_ref</span><span class="o">.</span><span class="n">is_virtual</span><span class="p">()</span> <span class="ow">and</span> <span class="p">(</span><span class="s1">&#39;virtual_uniform&#39;</span> <span class="ow">in</span> <span class="n">node_ref</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
                        <span class="k">continue</span>

                <span class="n">node</span><span class="o">.</span><span class="n">_temp_tensor</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">tensor</span>
                <span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;address&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span>
                <span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;node_ref&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;full&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;index&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">_temp_tensor</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">):</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;param_&#39;</span> <span class="o">+</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
                        <span class="nb">delattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;param_&#39;</span> <span class="o">+</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_memory_nodes</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_memory_nodes</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

                <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">_temp_tensor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="c1"># TODO: why i need this?</span>
                    <span class="n">node</span><span class="o">.</span><span class="n">_unrestricted_set_tensor</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">_temp_tensor</span><span class="p">)</span>
                    <span class="n">node</span><span class="o">.</span><span class="n">_temp_tensor</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_data_nodes</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
                <span class="n">node</span><span class="o">.</span><span class="n">_successors</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

            <span class="n">aux_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
            <span class="n">aux_dict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_non_leaf_nodes</span><span class="p">)</span>
            <span class="n">aux_dict</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_virtual_nodes</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">aux_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
                <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">is_virtual</span><span class="p">()</span> <span class="ow">and</span> <span class="p">(</span><span class="s1">&#39;virtual_stack&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
                    <span class="k">continue</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">delete_node</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_add_param</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">param</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ParamNode</span><span class="p">,</span> <span class="n">ParamEdge</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add parameters of ParamNode or ParamEdge to the TN</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">ParamNode</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">param</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Nodes names are never repeated, so it is likely that this case will never occur</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s1">&#39;Network already has attribute named </span><span class="si">{</span><span class="n">param</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">ParamEdge</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">param</span><span class="o">.</span><span class="n">module_name</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">module_name</span><span class="p">,</span> <span class="n">param</span><span class="p">)</span>
            <span class="c1"># If ParamEdge is already a submodule, it is the case in which we are</span>
            <span class="c1"># adding a node that &quot;inherits&quot; edges from previous nodes</span>

    <span class="k">def</span> <span class="nf">_update_node_info</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span> <span class="n">new_name</span><span class="p">:</span> <span class="n">Text</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">prev_name</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">_name</span>
        <span class="n">nodes_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_which_dict</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">new_name</span> <span class="ow">in</span> <span class="n">nodes_dict</span><span class="p">:</span>
            <span class="n">aux_node</span> <span class="o">=</span> <span class="n">nodes_dict</span><span class="p">[</span><span class="n">new_name</span><span class="p">]</span>
            <span class="n">aux_node</span><span class="o">.</span><span class="n">_temp_tensor</span> <span class="o">=</span> <span class="n">aux_node</span><span class="o">.</span><span class="n">tensor</span>

        <span class="k">if</span> <span class="n">nodes_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">prev_name</span><span class="p">)</span> <span class="o">==</span> <span class="n">node</span><span class="p">:</span>
            <span class="n">nodes_dict</span><span class="p">[</span><span class="n">new_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">nodes_dict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">prev_name</span><span class="p">)</span>
            <span class="c1"># TODO: A lo mejor esto solo si address is not None</span>
            <span class="c1"># TODO: caso se est&#39;a usando la memoria de otro nodo</span>
            <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;address&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_memory_nodes</span><span class="p">[</span><span class="n">new_name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_memory_nodes</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span>
                    <span class="n">prev_name</span><span class="p">)</span>
                <span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;address&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_name</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_tracing</span> <span class="ow">and</span> <span class="p">(</span><span class="n">prev_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inverse_memory</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_inverse_memory</span><span class="p">[</span><span class="n">new_name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_inverse_memory</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span>
                        <span class="n">prev_name</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>  <span class="c1"># NOTE: Case change node name</span>
            <span class="n">nodes_dict</span><span class="p">[</span><span class="n">new_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">node</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_memory_nodes</span><span class="p">[</span><span class="n">new_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">_temp_tensor</span>
            <span class="n">node</span><span class="o">.</span><span class="n">_temp_tensor</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;address&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_name</span>

            <span class="c1"># TODO: in tracing mode i do not change names, this does not happen</span>
            <span class="c1"># if self._tracing and (prev_name in self._inverse_memory):</span>
            <span class="c1">#     self._inverse_memory[new_name] = self._inverse_memory[prev_name]</span>

    <span class="k">def</span> <span class="nf">_update_node_name</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span> <span class="n">new_name</span><span class="p">:</span> <span class="n">Text</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">):</span>
            <span class="nb">delattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;param_&#39;</span> <span class="o">+</span> <span class="n">node</span><span class="o">.</span><span class="n">_name</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">edges</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">edge</span><span class="o">.</span><span class="n">is_attached_to</span><span class="p">(</span><span class="n">node</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_remove_edge</span><span class="p">(</span><span class="n">edge</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_update_node_info</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">new_name</span><span class="p">)</span>
        <span class="n">node</span><span class="o">.</span><span class="n">_name</span> <span class="o">=</span> <span class="n">new_name</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;param_&#39;</span> <span class="o">+</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span>
                    <span class="s1">&#39;param_&#39;</span> <span class="o">+</span> <span class="n">node</span><span class="o">.</span><span class="n">_name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_memory_nodes</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">_name</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Nodes names are never repeated, so it is likely that this case will never occur</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s1">&#39;Network already has attribute named </span><span class="si">{</span><span class="n">node</span><span class="o">.</span><span class="n">_name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">edges</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_add_edge</span><span class="p">(</span><span class="n">edge</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_assign_node_name</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="n">Text</span><span class="p">,</span> <span class="n">first_time</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Used to assign a new name to a node in the network</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">non_enum_prev_name</span> <span class="o">=</span> <span class="n">erase_enum</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">node</span><span class="o">.</span><span class="n">is_non_leaf</span><span class="p">()</span> <span class="ow">and</span> <span class="p">(</span><span class="n">non_enum_prev_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">operations</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Node</span><span class="se">\&#39;</span><span class="s1">s name cannot be an operation name &#39;</span>
                             <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">operations</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">non_enum_prev_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repeated_nodes_names</span><span class="p">:</span>
            <span class="n">count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repeated_nodes_names</span><span class="p">[</span><span class="n">non_enum_prev_name</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">count</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">aux_node</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">non_enum_prev_name</span><span class="p">]</span>
                <span class="n">aux_new_name</span> <span class="o">=</span> <span class="n">non_enum_prev_name</span> <span class="o">+</span> <span class="s1">&#39;_0&#39;</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_update_node_name</span><span class="p">(</span><span class="n">aux_node</span><span class="p">,</span> <span class="n">aux_new_name</span><span class="p">)</span>
            <span class="n">new_name</span> <span class="o">=</span> <span class="n">non_enum_prev_name</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">count</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">new_name</span> <span class="o">=</span> <span class="n">non_enum_prev_name</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_repeated_nodes_names</span><span class="p">[</span><span class="n">non_enum_prev_name</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_repeated_nodes_names</span><span class="p">[</span><span class="n">non_enum_prev_name</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">edges</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">edge</span><span class="o">.</span><span class="n">is_attached_to</span><span class="p">(</span><span class="n">node</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_remove_edge</span><span class="p">(</span><span class="n">edge</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">first_time</span><span class="p">:</span>
            <span class="n">nodes_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_which_dict</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
            <span class="n">nodes_dict</span><span class="p">[</span><span class="n">new_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">node</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_memory_nodes</span><span class="p">[</span><span class="n">new_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">_temp_tensor</span>
            <span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;address&#39;</span><span class="p">:</span> <span class="n">new_name</span><span class="p">,</span>
                                 <span class="s1">&#39;node_ref&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">,</span>
                                 <span class="s1">&#39;full&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                                 <span class="s1">&#39;index&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">}</span>
            <span class="n">node</span><span class="o">.</span><span class="n">_temp_tensor</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">node</span><span class="o">.</span><span class="n">_network</span> <span class="o">=</span> <span class="bp">self</span>
            <span class="n">node</span><span class="o">.</span><span class="n">_name</span> <span class="o">=</span> <span class="n">new_name</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_update_node_info</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">new_name</span><span class="p">)</span>
            <span class="n">node</span><span class="o">.</span><span class="n">_name</span> <span class="o">=</span> <span class="n">new_name</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;param_&#39;</span> <span class="o">+</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span>
                    <span class="s1">&#39;param_&#39;</span> <span class="o">+</span> <span class="n">node</span><span class="o">.</span><span class="n">_name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_memory_nodes</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">_name</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># TODO: Nodes names are never repeated, so it is likely that this case will never occur</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s1">&#39;Network already has attribute named </span><span class="si">{</span><span class="n">node</span><span class="o">.</span><span class="n">_name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">edges</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_add_edge</span><span class="p">(</span><span class="n">edge</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_unassign_node_name</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span> <span class="n">move_names</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Modify remaining nodes names when we remove one node</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">):</span>
            <span class="nb">delattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;param_&#39;</span> <span class="o">+</span> <span class="n">node</span><span class="o">.</span><span class="n">_name</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">edges</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">edge</span><span class="o">.</span><span class="n">is_attached_to</span><span class="p">(</span><span class="n">node</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_remove_edge</span><span class="p">(</span><span class="n">edge</span><span class="p">)</span>

        <span class="n">non_enum_prev_name</span> <span class="o">=</span> <span class="n">erase_enum</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
        <span class="n">count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repeated_nodes_names</span><span class="p">[</span><span class="n">non_enum_prev_name</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">move_names</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">count</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">enum</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">enum</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">count</span><span class="p">):</span>
                    <span class="n">aux_prev_name</span> <span class="o">=</span> <span class="n">non_enum_prev_name</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                    <span class="n">aux_new_name</span> <span class="o">=</span> <span class="n">non_enum_prev_name</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
                    <span class="n">aux_node</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">aux_prev_name</span><span class="p">]</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_update_node_name</span><span class="p">(</span><span class="n">aux_node</span><span class="p">,</span> <span class="n">aux_new_name</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_repeated_nodes_names</span><span class="p">[</span><span class="n">non_enum_prev_name</span><span class="p">]</span> <span class="o">-=</span> <span class="mi">1</span>
        <span class="n">count</span> <span class="o">-=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">count</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_repeated_nodes_names</span><span class="p">[</span><span class="n">non_enum_prev_name</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">count</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">move_names</span><span class="p">:</span>
                <span class="n">aux_prev_name</span> <span class="o">=</span> <span class="n">non_enum_prev_name</span> <span class="o">+</span> <span class="s1">&#39;_0&#39;</span>
                <span class="n">aux_new_name</span> <span class="o">=</span> <span class="n">non_enum_prev_name</span>
                <span class="n">aux_node</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">aux_prev_name</span><span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_update_node_name</span><span class="p">(</span><span class="n">aux_node</span><span class="p">,</span> <span class="n">aux_new_name</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_change_node_name</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="n">Text</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Used to change the name of a node. If a node belongs to a network,</span>
<span class="sd">        we have to take care of repeated names in the network. This entails</span>
<span class="sd">        assigning a new name to the node, and removing the previous name</span>
<span class="sd">        (with subsequent changes)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO: Esto no pasa, est&#39;a protegida, solo la llamo cuando quiero</span>
        <span class="c1"># TODO: a lo mejor no deberiamos dejar llamar a nodos como data_...</span>
        <span class="c1"># si no son data nodes</span>
        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">network</span> <span class="o">!=</span> <span class="bp">self</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Cannot change the name of a node that does &#39;</span>
                             <span class="s1">&#39;not belong to the network&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">erase_enum</span><span class="p">(</span><span class="n">name</span><span class="p">)</span> <span class="o">!=</span> <span class="n">erase_enum</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_unassign_node_name</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_assign_node_name</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_change_node_type</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node</span><span class="p">:</span> <span class="n">AbstractNode</span><span class="p">,</span> <span class="nb">type</span><span class="p">:</span> <span class="n">Text</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Used to change node from leaf, non_leaf, data or virtual</span>
<span class="sd">        types to another</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;leaf&#39;</span><span class="p">,</span> <span class="s1">&#39;non_leaf&#39;</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="s1">&#39;virtual&#39;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;`type` can only be </span><span class="se">\&#39;</span><span class="s1">leaf</span><span class="se">\&#39;</span><span class="s1">, </span><span class="se">\&#39;</span><span class="s1">non_leaf</span><span class="se">\&#39;</span><span class="s1">, &#39;</span>
                             <span class="s1">&#39;</span><span class="se">\&#39;</span><span class="s1">data</span><span class="se">\&#39;</span><span class="s1"> or </span><span class="se">\&#39;</span><span class="s1">virtual</span><span class="se">\&#39;</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="n">prev_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_which_dict</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">type</span> <span class="o">==</span> <span class="s1">&#39;leaf&#39;</span><span class="p">:</span>
            <span class="n">new_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_leaf_nodes</span>
            <span class="n">node</span><span class="o">.</span><span class="n">_leaf</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">node</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">node</span><span class="o">.</span><span class="n">_virtual</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">elif</span> <span class="nb">type</span> <span class="o">==</span> <span class="s1">&#39;data&#39;</span><span class="p">:</span>
            <span class="n">new_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_data_nodes</span>
            <span class="n">node</span><span class="o">.</span><span class="n">_leaf</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">node</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">node</span><span class="o">.</span><span class="n">_virtual</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">elif</span> <span class="nb">type</span> <span class="o">==</span> <span class="s1">&#39;virtual&#39;</span><span class="p">:</span>
            <span class="n">new_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_virtual_nodes</span>
            <span class="n">node</span><span class="o">.</span><span class="n">_leaf</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">node</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">node</span><span class="o">.</span><span class="n">_virtual</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="nb">type</span> <span class="o">==</span> <span class="s1">&#39;non_leaf&#39;</span><span class="p">:</span>
            <span class="n">new_dict</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_leaf_nodes</span>
            <span class="n">node</span><span class="o">.</span><span class="n">_leaf</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">node</span><span class="o">.</span><span class="n">_data</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">node</span><span class="o">.</span><span class="n">_virtual</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">del</span> <span class="n">prev_dict</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>
        <span class="n">new_dict</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">node</span>

    <span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;TensorNetwork&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

<div class="viewcode-block" id="TensorNetwork.parameterize"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.TensorNetwork.parameterize">[docs]</a>    <span class="k">def</span> <span class="nf">parameterize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                     <span class="n">set_param</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                     <span class="n">override</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s1">&#39;TensorNetwork&#39;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameterize all nodes and edges of the network.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        set_param: boolean indicating whether the Tn has to be</span>
<span class="sd">                   parameterized (True) or de-parameterized (False)</span>
<span class="sd">        override: boolean indicating if the TN must be copied before</span>
<span class="sd">                  parameterized (False) or not (True)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">override</span><span class="p">:</span>
            <span class="n">net</span> <span class="o">=</span> <span class="bp">self</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">net</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">non_leaf_nodes</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;Non-leaf nodes will be removed before parameterizing &#39;</span>
                          <span class="s1">&#39;the TN&#39;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">leaf_nodes</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
            <span class="n">param_node</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">parameterize</span><span class="p">(</span><span class="n">set_param</span><span class="p">)</span>
            <span class="n">param_node</span><span class="o">.</span><span class="n">param_edges</span><span class="p">(</span><span class="n">set_param</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">net</span></div>

<div class="viewcode-block" id="TensorNetwork.initialize"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.TensorNetwork.initialize">[docs]</a>    <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize all nodes&#39; tensors in the network</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Initialization methods depend on the topology of the network. Number of nodes,</span>
        <span class="c1"># edges and its dimensions might be relevant when specifying the initial distribution</span>
        <span class="c1"># (e.g. mean, std) of each node</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s1">&#39;Initialization methods not implemented for generic TensorNetwork class&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="TensorNetwork.set_data_nodes"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.TensorNetwork.set_data_nodes">[docs]</a>    <span class="k">def</span> <span class="nf">set_data_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                       <span class="n">input_edges</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">AbstractEdge</span><span class="p">]],</span>
                       <span class="n">num_batch_edges</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                       <span class="n">names_batch_edges</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">Text</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create data nodes and connect them to the list of specified edges of the TN.</span>
<span class="sd">        `set_data_nodes` should be executed after instantiating a TN, before</span>
<span class="sd">        computing forward.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        input_edges: list of edges in the same order as they are expected to be</span>
<span class="sd">            contracted with each feature node of the input data_nodes</span>
<span class="sd">        num_batch_edges: number of batch edges in the input data</span>
<span class="sd">        names_batch_edges: sequence of names for the batch edges</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">input_edges</span> <span class="o">==</span> <span class="p">[]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s1">&#39;`input_edges` is empty. Cannot set data nodes if no edges are provided&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_nodes</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s1">&#39;Tensor network data nodes should be unset in order to set new ones&#39;</span><span class="p">)</span>

        <span class="c1"># Only make stack_data_memory if all the input edges have the same dimension</span>
        <span class="n">same_dim</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_edges</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">input_edges</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="o">!=</span> <span class="n">input_edges</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">():</span>
                <span class="n">same_dim</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">break</span>

        <span class="c1"># num_batch_edges = len(names_batch_edges)</span>

        <span class="k">if</span> <span class="n">same_dim</span><span class="p">:</span>
            <span class="k">if</span> <span class="s1">&#39;stack_data_memory&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_virtual_nodes</span><span class="p">:</span>
                <span class="c1"># TODO: Stack data node donde se guardan los datos, se supone que todas las features tienen la misma dim</span>
                <span class="n">stack_node</span> <span class="o">=</span> <span class="n">Node</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_edges</span><span class="p">),</span> <span class="o">*</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">num_batch_edges</span><span class="p">),</span> <span class="n">input_edges</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">size</span><span class="p">()),</span>  <span class="c1"># TODO: supongo edge es AbstractEdge</span>
                                  <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;n_features&#39;</span><span class="p">,</span>
                                              <span class="o">*</span><span class="p">([</span><span class="s1">&#39;batch&#39;</span><span class="p">]</span><span class="o">*</span><span class="n">num_batch_edges</span><span class="p">),</span>
                                              <span class="s1">&#39;feature&#39;</span><span class="p">),</span>
                                  <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;stack_data_memory&#39;</span><span class="p">,</span>  <span class="c1"># TODO: guardo aqui la memory, no uso memory_data_nodes</span>
                                  <span class="n">network</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
                                  <span class="n">virtual</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">n_features_node</span> <span class="o">=</span> <span class="n">Node</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">stack_node</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],),</span>
                                       <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;n_features&#39;</span><span class="p">,),</span>
                                       <span class="n">name</span><span class="o">=</span><span class="s1">&#39;virtual_n_features&#39;</span><span class="p">,</span>
                                       <span class="n">network</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
                                       <span class="n">virtual</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">feature_node</span> <span class="o">=</span> <span class="n">Node</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">stack_node</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],),</span>
                                    <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;feature&#39;</span><span class="p">,),</span>
                                    <span class="n">name</span><span class="o">=</span><span class="s1">&#39;virtual_feature&#39;</span><span class="p">,</span>
                                    <span class="n">network</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
                                    <span class="n">virtual</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">stack_node</span><span class="p">[</span><span class="s1">&#39;n_features&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">n_features_node</span><span class="p">[</span><span class="s1">&#39;n_features&#39;</span><span class="p">]</span>
                <span class="n">stack_node</span><span class="p">[</span><span class="s1">&#39;feature&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">feature_node</span><span class="p">[</span><span class="s1">&#39;feature&#39;</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">stack_node</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_virtual_nodes</span><span class="p">[</span><span class="s1">&#39;stack_data_memory&#39;</span><span class="p">]</span>

        <span class="c1"># if names_batch_edges is not None:</span>
        <span class="c1">#     if len(names_batch_edges) != num_batch_edges:</span>
        <span class="c1">#         raise ValueError(f&#39;`names_batch_edges` should have exactly &#39;</span>
        <span class="c1">#                          f&#39;{num_batch_edges} names&#39;)</span>
        <span class="c1"># else:</span>
        <span class="c1">#     names_batch_edges = [f&#39;batch_{j}&#39; for j in range(num_batch_edges)]</span>

        <span class="n">data_nodes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">edge</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">input_edges</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edge</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="n">edge</span> <span class="o">=</span> <span class="bp">self</span><span class="p">[</span><span class="n">edge</span><span class="p">]</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edge</span><span class="p">,</span> <span class="n">AbstractEdge</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">edge</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">edges</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s1">&#39;Edge </span><span class="si">{</span><span class="n">edge</span><span class="si">!r}</span><span class="s1"> should be a dangling edge of the Tensor Network&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="s1">&#39;`input_edges` should be List[int] or List[AbstractEdge] type&#39;</span><span class="p">)</span>
            <span class="n">node</span> <span class="o">=</span> <span class="n">Node</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="o">*</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">num_batch_edges</span><span class="p">),</span> <span class="n">edge</span><span class="o">.</span><span class="n">size</span><span class="p">()),</span>
                        <span class="n">axes_names</span><span class="o">=</span><span class="p">(</span><span class="o">*</span><span class="p">([</span><span class="s1">&#39;batch&#39;</span><span class="p">]</span><span class="o">*</span><span class="n">num_batch_edges</span><span class="p">),</span>
                                    <span class="s1">&#39;feature&#39;</span><span class="p">),</span>
                        <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;data_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
                        <span class="n">network</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
                        <span class="n">data</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">node</span><span class="p">[</span><span class="s1">&#39;feature&#39;</span><span class="p">]</span> <span class="o">^</span> <span class="n">edge</span>
            <span class="n">data_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">same_dim</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">node</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_nodes</span><span class="p">):</span>
                <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_memory_nodes</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;address&#39;</span><span class="p">]]</span>
                <span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;address&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;node_ref&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">stack_node</span>
                <span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;full&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">node</span><span class="o">.</span><span class="n">_tensor_info</span><span class="p">[</span><span class="s1">&#39;index&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span></div>

    <span class="k">def</span> <span class="nf">unset_data_nodes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_nodes</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_nodes</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">delete_node</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_data_nodes</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

            <span class="k">if</span> <span class="s1">&#39;stack_data_memory&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">virtual_nodes</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">delete_node</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">virtual_nodes</span><span class="p">[</span><span class="s1">&#39;stack_data_memory&#39;</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">delete_node</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">virtual_nodes</span><span class="p">[</span><span class="s1">&#39;virtual_n_features&#39;</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">delete_node</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">virtual_nodes</span><span class="p">[</span><span class="s1">&#39;virtual_feature&#39;</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_add_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Add data to data nodes, that is, change their tensors by new data tensors given a new data set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data: data tensor, of dimensions</span>
<span class="sd">            n_features x batch_size_{0} x ... x batch_size_{n} x feature_size</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">stack_node</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">virtual_nodes</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;stack_data_memory&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">stack_node</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">stack_node</span><span class="o">.</span><span class="n">_unrestricted_set_tensor</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_nodes</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data_node</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_nodes</span><span class="o">.</span><span class="n">values</span><span class="p">())):</span>
                <span class="n">data_node</span><span class="o">.</span><span class="n">_unrestricted_set_tensor</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Cannot add data if no data nodes are set&#39;</span><span class="p">)</span>

<div class="viewcode-block" id="TensorNetwork.contract"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.TensorNetwork.contract">[docs]</a>    <span class="k">def</span> <span class="nf">contract</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Contract tensor network</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Custom, optimized contraction methods should be defined for each new subclass of TensorNetwork</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="s1">&#39;Contraction methods not implemented for generic TensorNetwork class&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="TensorNetwork.forward"><a class="viewcode-back" href="../../network_components.html#tensorkrowch.TensorNetwork.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                <span class="n">data</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Contract Tensor Network with input data with shape batch x n_features x feature.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># NOTE: solo hay que definir de antemano set_data_nodes y contract</span>
        <span class="k">if</span> <span class="n">data</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_nodes</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">set_data_nodes</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_add_data</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">non_leaf_nodes</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">contract</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_seq_ops</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_list_ops</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_seq_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">op</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">op</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_successors</span><span class="p">[</span><span class="n">op</span><span class="p">[</span><span class="mi">1</span><span class="p">]][</span><span class="n">op</span><span class="p">[</span><span class="mi">2</span><span class="p">]]</span><span class="o">.</span><span class="n">kwargs</span><span class="p">))</span>

            <span class="k">return</span> <span class="n">output</span><span class="o">.</span><span class="n">tensor</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># output = self.contract(*args, **kwargs)</span>

            <span class="c1"># total = time.time()</span>
            <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_seq_ops</span><span class="p">:</span>
                <span class="c1"># start = time.time()</span>
                <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">operations</span><span class="p">[</span><span class="n">op</span><span class="p">[</span><span class="mi">0</span><span class="p">]](</span><span class="o">**</span><span class="n">op</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
                <span class="c1"># print(f&#39;Time {op[0]}: {time.time() - start:.4f}&#39;)</span>
            <span class="c1"># print(f&#39;Total time: {time.time() - total:.4f}&#39;)</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">Node</span><span class="p">):</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">op</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;unbind&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
                    <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The last operation should be the one &#39;</span>
                                     <span class="s1">&#39;returning a single resulting node&#39;</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">output</span><span class="o">.</span><span class="n">tensor</span></div>

        <span class="c1"># TODO: algo as&#39;i, en la primera epoca se meten datos con batch 1, solo</span>
        <span class="c1">#  para ir creando todos los nodos intermedios necesarios r&#39;apidamente,</span>
        <span class="c1">#  luego ya se contrae la red haciendo operaciones de tensores</span>
        <span class="c1"># if not self.is_contracting():</span>
        <span class="c1">#     # First contraction</span>
        <span class="c1">#     aux_data = torch.zeros([1] * (len(data.shape) - 1) + [data.shape[-1]])</span>
        <span class="c1">#     self._add_data(aux_data)</span>
        <span class="c1">#     self.is_contracting(True)</span>
        <span class="c1">#     self.contract()</span>

        <span class="c1"># self._add_data(data)</span>
        <span class="c1"># self.contract()</span>
        <span class="c1"># raise NotImplementedError(&#39;Forward method not implemented for generic TensorNetwork class&#39;)</span>

    <span class="c1"># TODO: add_data, wrap(contract), where we only define the way in which data is fed to the TN and TN</span>
    <span class="c1">#  is contracted; `wrap` is used to manage memory and creation of nodes in the first epoch, feeding</span>
    <span class="c1">#  data (zeros only batch_size=1) with torch.no_grad()</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Text</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">AbstractEdge</span><span class="p">,</span> <span class="n">AbstractNode</span><span class="p">]:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_edges</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">Text</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
            <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s1">&#39;Tensor network </span><span class="si">{</span><span class="bp">self</span><span class="si">!s}</span><span class="s1"> does not have any node with name </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;`key` should be int or str type&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Text</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Text</span><span class="p">:</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s1">(</span><span class="se">\n</span><span class="s1"> &#39;</span> \
               <span class="sa">f</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">name: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span> \
               <span class="sa">f</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">nodes: </span><span class="se">\n</span><span class="si">{</span><span class="n">tab_string</span><span class="p">(</span><span class="n">print_list</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nodes</span><span class="o">.</span><span class="n">keys</span><span class="p">())),</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s1">&#39;</span> \
               <span class="sa">f</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">edges:</span><span class="se">\n</span><span class="si">{</span><span class="n">tab_string</span><span class="p">(</span><span class="n">print_list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">edges</span><span class="p">),</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span><span class="si">}</span><span class="s1">)&#39;</span></div>

    <span class="c1"># TODO: Function to build instructions and reallocate memory, optimized for a function</span>
    <span class="c1">#  (se deben reasignar los par&#39;ametros)</span>
    <span class="c1"># TODO: Function to allocate one memory tensor for each node, like old mode</span>


<span class="c1">################################################</span>
<span class="c1">#               EDGE OPERATIONS                #</span>
<span class="c1">################################################</span>
<span class="k">def</span> <span class="nf">connect</span><span class="p">(</span><span class="n">edge1</span><span class="p">:</span> <span class="n">AbstractEdge</span><span class="p">,</span> <span class="n">edge2</span><span class="p">:</span> <span class="n">AbstractEdge</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Edge</span><span class="p">,</span> <span class="n">ParamEdge</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Connect two dangling, non-batch edges.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: no puedo capar el conectar nodos no-leaf, pero no tiene el resultado esperado,</span>
    <span class="c1">#  en realidad ests conectando los nodos originales (leaf)</span>
    <span class="k">if</span> <span class="n">edge1</span> <span class="o">==</span> <span class="n">edge2</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">edge1</span>

    <span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="p">[</span><span class="n">edge1</span><span class="p">,</span> <span class="n">edge2</span><span class="p">]:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">edge</span><span class="o">.</span><span class="n">is_dangling</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Edge </span><span class="si">{</span><span class="n">edge</span><span class="si">!s}</span><span class="s1"> is not a dangling edge. &#39;</span>
                             <span class="sa">f</span><span class="s1">&#39;This edge points to nodes: </span><span class="si">{</span><span class="n">edge</span><span class="o">.</span><span class="n">node1</span><span class="si">!s}</span><span class="s1"> and </span><span class="si">{</span><span class="n">edge</span><span class="o">.</span><span class="n">node2</span><span class="si">!s}</span><span class="s1">&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">edge</span><span class="o">.</span><span class="n">is_batch</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Edge </span><span class="si">{</span><span class="n">edge</span><span class="si">!s}</span><span class="s1"> is a batch edge&#39;</span><span class="p">)</span>
    <span class="c1"># if edge1 == edge2:</span>
    <span class="c1">#     raise ValueError(f&#39;Cannot connect edge {edge1!s} to itself&#39;)</span>
    <span class="k">if</span> <span class="n">edge1</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">!=</span> <span class="n">edge2</span><span class="o">.</span><span class="n">dim</span><span class="p">():</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Cannot connect edges of unequal dimension. &#39;</span>
                         <span class="sa">f</span><span class="s1">&#39;Dimension of edge </span><span class="si">{</span><span class="n">edge1</span><span class="si">!s}</span><span class="s1">: </span><span class="si">{</span><span class="n">edge1</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span><span class="si">}</span><span class="s1">. &#39;</span>
                         <span class="sa">f</span><span class="s1">&#39;Dimension of edge </span><span class="si">{</span><span class="n">edge2</span><span class="si">!s}</span><span class="s1">: </span><span class="si">{</span><span class="n">edge2</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">edge1</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="o">!=</span> <span class="n">edge2</span><span class="o">.</span><span class="n">size</span><span class="p">():</span>
        <span class="c1"># Keep the minimum size</span>
        <span class="k">if</span> <span class="n">edge1</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">edge2</span><span class="o">.</span><span class="n">size</span><span class="p">():</span>
            <span class="n">edge2</span><span class="o">.</span><span class="n">change_size</span><span class="p">(</span><span class="n">edge1</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
        <span class="k">elif</span> <span class="n">edge1</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">edge2</span><span class="o">.</span><span class="n">size</span><span class="p">():</span>
            <span class="n">edge1</span><span class="o">.</span><span class="n">change_size</span><span class="p">(</span><span class="n">edge2</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

    <span class="n">node1</span><span class="p">,</span> <span class="n">axis1</span> <span class="o">=</span> <span class="n">edge1</span><span class="o">.</span><span class="n">node1</span><span class="p">,</span> <span class="n">edge1</span><span class="o">.</span><span class="n">axis1</span>
    <span class="n">node2</span><span class="p">,</span> <span class="n">axis2</span> <span class="o">=</span> <span class="n">edge2</span><span class="o">.</span><span class="n">node1</span><span class="p">,</span> <span class="n">edge2</span><span class="o">.</span><span class="n">axis1</span>
    <span class="n">net1</span><span class="p">,</span> <span class="n">net2</span> <span class="o">=</span> <span class="n">node1</span><span class="o">.</span><span class="n">_network</span><span class="p">,</span> <span class="n">node2</span><span class="o">.</span><span class="n">_network</span>

    <span class="k">if</span> <span class="n">net1</span> <span class="o">!=</span> <span class="n">net2</span><span class="p">:</span>
        <span class="n">node2</span><span class="o">.</span><span class="n">move_to_network</span><span class="p">(</span><span class="n">net1</span><span class="p">)</span>
    <span class="n">net1</span><span class="o">.</span><span class="n">_remove_edge</span><span class="p">(</span><span class="n">edge1</span><span class="p">)</span>
    <span class="n">net1</span><span class="o">.</span><span class="n">_remove_edge</span><span class="p">(</span><span class="n">edge2</span><span class="p">)</span>
    <span class="n">net</span> <span class="o">=</span> <span class="n">net1</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edge1</span><span class="p">,</span> <span class="n">ParamEdge</span><span class="p">)</span> <span class="o">==</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edge2</span><span class="p">,</span> <span class="n">ParamEdge</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edge1</span><span class="p">,</span> <span class="n">ParamEdge</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edge1</span><span class="p">,</span> <span class="n">ParamStackEdge</span><span class="p">):</span>
                <span class="n">new_edge</span> <span class="o">=</span> <span class="n">ParamStackEdge</span><span class="p">(</span><span class="n">edges</span><span class="o">=</span><span class="n">edge1</span><span class="o">.</span><span class="n">edges</span><span class="p">,</span> <span class="n">node1_lists</span><span class="o">=</span><span class="n">edge1</span><span class="o">.</span><span class="n">node1_lists</span><span class="p">,</span>
                                          <span class="n">node1</span><span class="o">=</span><span class="n">node1</span><span class="p">,</span> <span class="n">axis1</span><span class="o">=</span><span class="n">axis1</span><span class="p">,</span>
                                          <span class="n">node2</span><span class="o">=</span><span class="n">node2</span><span class="p">,</span> <span class="n">axis2</span><span class="o">=</span><span class="n">axis2</span><span class="p">)</span>
                <span class="c1"># net._add_edge(new_edge)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">shift</span> <span class="o">=</span> <span class="n">edge1</span><span class="o">.</span><span class="n">shift</span>
                <span class="n">slope</span> <span class="o">=</span> <span class="n">edge1</span><span class="o">.</span><span class="n">slope</span>
                <span class="n">new_edge</span> <span class="o">=</span> <span class="n">ParamEdge</span><span class="p">(</span><span class="n">node1</span><span class="o">=</span><span class="n">node1</span><span class="p">,</span> <span class="n">axis1</span><span class="o">=</span><span class="n">axis1</span><span class="p">,</span>
                                     <span class="n">shift</span><span class="o">=</span><span class="n">shift</span><span class="p">,</span> <span class="n">slope</span><span class="o">=</span><span class="n">slope</span><span class="p">,</span>
                                     <span class="n">node2</span><span class="o">=</span><span class="n">node2</span><span class="p">,</span> <span class="n">axis2</span><span class="o">=</span><span class="n">axis2</span><span class="p">)</span>
                <span class="n">net</span><span class="o">.</span><span class="n">_add_edge</span><span class="p">(</span><span class="n">new_edge</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edge1</span><span class="p">,</span> <span class="n">StackEdge</span><span class="p">):</span>
                <span class="n">new_edge</span> <span class="o">=</span> <span class="n">StackEdge</span><span class="p">(</span><span class="n">edges</span><span class="o">=</span><span class="n">edge1</span><span class="o">.</span><span class="n">edges</span><span class="p">,</span> <span class="n">node1_lists</span><span class="o">=</span><span class="n">edge1</span><span class="o">.</span><span class="n">node1_lists</span><span class="p">,</span>
                                     <span class="n">node1</span><span class="o">=</span><span class="n">node1</span><span class="p">,</span> <span class="n">axis1</span><span class="o">=</span><span class="n">axis1</span><span class="p">,</span>
                                     <span class="n">node2</span><span class="o">=</span><span class="n">node2</span><span class="p">,</span> <span class="n">axis2</span><span class="o">=</span><span class="n">axis2</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">new_edge</span> <span class="o">=</span> <span class="n">Edge</span><span class="p">(</span><span class="n">node1</span><span class="o">=</span><span class="n">node1</span><span class="p">,</span> <span class="n">axis1</span><span class="o">=</span><span class="n">axis1</span><span class="p">,</span>
                                <span class="n">node2</span><span class="o">=</span><span class="n">node2</span><span class="p">,</span> <span class="n">axis2</span><span class="o">=</span><span class="n">axis2</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edge1</span><span class="p">,</span> <span class="n">ParamEdge</span><span class="p">):</span>
            <span class="n">shift</span> <span class="o">=</span> <span class="n">edge1</span><span class="o">.</span><span class="n">shift</span>
            <span class="n">slope</span> <span class="o">=</span> <span class="n">edge1</span><span class="o">.</span><span class="n">slope</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">shift</span> <span class="o">=</span> <span class="n">edge2</span><span class="o">.</span><span class="n">shift</span>
            <span class="n">slope</span> <span class="o">=</span> <span class="n">edge2</span><span class="o">.</span><span class="n">slope</span>
        <span class="n">new_edge</span> <span class="o">=</span> <span class="n">ParamEdge</span><span class="p">(</span><span class="n">node1</span><span class="o">=</span><span class="n">node1</span><span class="p">,</span> <span class="n">axis1</span><span class="o">=</span><span class="n">axis1</span><span class="p">,</span>
                             <span class="n">shift</span><span class="o">=</span><span class="n">shift</span><span class="p">,</span> <span class="n">slope</span><span class="o">=</span><span class="n">slope</span><span class="p">,</span>
                             <span class="n">node2</span><span class="o">=</span><span class="n">node2</span><span class="p">,</span> <span class="n">axis2</span><span class="o">=</span><span class="n">axis2</span><span class="p">)</span>
        <span class="n">net</span><span class="o">.</span><span class="n">_add_edge</span><span class="p">(</span><span class="n">new_edge</span><span class="p">)</span>

    <span class="n">node1</span><span class="o">.</span><span class="n">_add_edge</span><span class="p">(</span><span class="n">new_edge</span><span class="p">,</span> <span class="n">axis1</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
    <span class="n">node2</span><span class="o">.</span><span class="n">_add_edge</span><span class="p">(</span><span class="n">new_edge</span><span class="p">,</span> <span class="n">axis2</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">new_edge</span>


<span class="k">def</span> <span class="nf">connect_stack</span><span class="p">(</span><span class="n">edge1</span><span class="p">:</span> <span class="n">AbstractStackEdge</span><span class="p">,</span> <span class="n">edge2</span><span class="p">:</span> <span class="n">AbstractStackEdge</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Connect stack edges only if their lists of edges are the same</span>
<span class="sd">    (coming from already connected edges)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edge1</span><span class="p">,</span> <span class="n">AbstractStackEdge</span><span class="p">)</span> <span class="ow">or</span> \
            <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edge2</span><span class="p">,</span> <span class="n">AbstractStackEdge</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Both edges should be (Param)StackEdge</span><span class="se">\&#39;</span><span class="s1">s&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">edge1</span><span class="o">.</span><span class="n">edges</span> <span class="o">!=</span> <span class="n">edge2</span><span class="o">.</span><span class="n">edges</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Cannot connect stack edges whose lists of&#39;</span>
                         <span class="s1">&#39; edges are not the same. They will be the &#39;</span>
                         <span class="s1">&#39;same when both lists contain edges connecting&#39;</span>
                         <span class="s1">&#39; the nodes that formed the stack nodes.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">connect</span><span class="p">(</span><span class="n">edge1</span><span class="o">=</span><span class="n">edge1</span><span class="p">,</span> <span class="n">edge2</span><span class="o">=</span><span class="n">edge2</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">disconnect</span><span class="p">(</span><span class="n">edge</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Edge</span><span class="p">,</span> <span class="n">ParamEdge</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Edge</span><span class="p">,</span> <span class="n">ParamEdge</span><span class="p">],</span>
                                                      <span class="n">Union</span><span class="p">[</span><span class="n">Edge</span><span class="p">,</span> <span class="n">ParamEdge</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Disconnect an edge, returning a couple of dangling edges</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">edge</span><span class="o">.</span><span class="n">is_dangling</span><span class="p">():</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Cannot disconnect a dangling edge&#39;</span><span class="p">)</span>

    <span class="n">nodes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">axes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">axis</span><span class="p">,</span> <span class="n">node</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">edge</span><span class="o">.</span><span class="n">_axes</span><span class="p">,</span> <span class="n">edge</span><span class="o">.</span><span class="n">_nodes</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">_edges</span><span class="p">:</span>
            <span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
            <span class="n">axes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">axis</span><span class="p">)</span>

    <span class="n">new_edges</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">first</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">for</span> <span class="n">axis</span><span class="p">,</span> <span class="n">node</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="n">nodes</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edge</span><span class="p">,</span> <span class="n">Edge</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edge</span><span class="p">,</span> <span class="n">StackEdge</span><span class="p">):</span>
                <span class="n">new_edge</span> <span class="o">=</span> <span class="n">StackEdge</span><span class="p">(</span><span class="n">edges</span><span class="o">=</span><span class="n">edge</span><span class="o">.</span><span class="n">edges</span><span class="p">,</span>
                                     <span class="n">node1_lists</span><span class="o">=</span><span class="n">edge</span><span class="o">.</span><span class="n">node1_lists</span><span class="p">,</span>
                                     <span class="n">node1</span><span class="o">=</span><span class="n">node</span><span class="p">,</span>
                                     <span class="n">axis1</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
                <span class="n">new_edges</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_edge</span><span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">new_edge</span> <span class="o">=</span> <span class="n">Edge</span><span class="p">(</span><span class="n">node1</span><span class="o">=</span><span class="n">node</span><span class="p">,</span> <span class="n">axis1</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
                <span class="n">new_edges</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_edge</span><span class="p">)</span>

                <span class="n">net</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">_network</span>
                <span class="n">net</span><span class="o">.</span><span class="n">_add_edge</span><span class="p">(</span><span class="n">new_edge</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">edge</span><span class="p">,</span> <span class="n">ParamStackEdge</span><span class="p">):</span>
                <span class="n">new_edge</span> <span class="o">=</span> <span class="n">ParamStackEdge</span><span class="p">(</span><span class="n">edges</span><span class="o">=</span><span class="n">edge</span><span class="o">.</span><span class="n">edges</span><span class="p">,</span>
                                          <span class="n">node1_lists</span><span class="o">=</span><span class="n">edge</span><span class="o">.</span><span class="n">node1_lists</span><span class="p">,</span>
                                          <span class="n">node1</span><span class="o">=</span><span class="n">node</span><span class="p">,</span>
                                          <span class="n">axis1</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
                <span class="n">new_edges</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_edge</span><span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">shift</span> <span class="o">=</span> <span class="n">edge</span><span class="o">.</span><span class="n">shift</span>
                <span class="n">slope</span> <span class="o">=</span> <span class="n">edge</span><span class="o">.</span><span class="n">slope</span>
                <span class="n">new_edge</span> <span class="o">=</span> <span class="n">ParamEdge</span><span class="p">(</span><span class="n">node1</span><span class="o">=</span><span class="n">node</span><span class="p">,</span> <span class="n">axis1</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span>
                                     <span class="n">shift</span><span class="o">=</span><span class="n">shift</span><span class="p">,</span> <span class="n">slope</span><span class="o">=</span><span class="n">slope</span><span class="p">)</span>
                <span class="n">new_edges</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_edge</span><span class="p">)</span>

                <span class="n">net</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">_network</span>
                <span class="k">if</span> <span class="n">first</span><span class="p">:</span>
                    <span class="n">net</span><span class="o">.</span><span class="n">_remove_edge</span><span class="p">(</span><span class="n">edge</span><span class="p">)</span>
                    <span class="n">first</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="n">net</span><span class="o">.</span><span class="n">_add_edge</span><span class="p">(</span><span class="n">new_edge</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">axis</span><span class="p">,</span> <span class="n">node</span><span class="p">,</span> <span class="n">new_edge</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="n">nodes</span><span class="p">,</span> <span class="n">new_edges</span><span class="p">):</span>
        <span class="n">node</span><span class="o">.</span><span class="n">_add_edge</span><span class="p">(</span><span class="n">new_edge</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

    <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">new_edges</span><span class="p">)</span>
</pre></div>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Jos R. Pareja Monturiol<br/>
  
      &copy; Copyright 2023, Jos R. Pareja Monturiol.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>